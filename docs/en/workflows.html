<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <link rel="shortcut icon" href="https://avatars0.githubusercontent.com/u/26362587?s=200&amp;v=4"></link>
  <link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
  <link rel="stylesheet" href="/assets/bulma.css"></link>
  <link rel="stylesheet" href="/assets/syntax-highlight.css"></link>
  <link rel="stylesheet" href="/assets/ocrd.css"></link>
</head>
<body><nav class="navbar is-transparent is-fixed-top">

  <div class="navbar-brand">
    <a class="navbar-item" href="/">
      <img src="/assets/ocrd-logo-small.png" height="28"/>
    </a>
    <div class="navbar-burger burger" data-target="ocrd-navbar-menu">
      <span></span>
      <span></span>
      <span></span>
    </div>
  </div>

  <div id="ocrd-navbar-menu" class="navbar-menu">
    <div class="navbar-start">
      
      
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link" href="/en/">About</a>
        <div class="navbar-dropdown">
          

          
          

            
            <a class="navbar-item" href="/de/phase3">OCR-D Phase III</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/about">The OCR-D-project</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/contact">Get in touch!</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/blog">Blog</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/publications">Publications and Presentations</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/module-projects">Module Projects</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/data">Data</a>

          

          

          
          
            
            
              
              <a class="navbar-item" href="/en/initial-tests">Initial tests</a>
            

          

          

          
          

            
            <a class="navbar-item" href="/en/user_survey">User Survey</a>

          

          

          
          
            
            
              
              <a class="navbar-item" href="/en/imprint">Imprint</a>
            

          

          
        </div>
      </div>
      
      
      
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link" href="/en/dev">Developers</a>
        <div class="navbar-dropdown">
          

          
          

            
            <a class="navbar-item" href="/en/gt-guidelines/trans">Ground Truth Guidelines</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/gt-guidelines/trans/trPage">PAGE-XML format documentation</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/dev-best-practice">OCR-D development best practices</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/spec">Specifications</a>

          

          

          
          

            
            <a class="navbar-item" href="/core">OCR-D/core API Documentation</a>

          

          
        </div>
      </div>
      
      
      
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link" href="/en/use">Users</a>
        <div class="navbar-dropdown">
          

          
          
            
            
              
              <a class="navbar-item" href="/en/setup">Setup Guide</a>
            

          

          

          
          

            
            <a class="navbar-item" href="/en/user_guide">User Guide</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/workflows">Workflows</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/models">Models</a>

          

          

          
          

            
            <a class="navbar-item" href="/en/spec/glossary">Glossary</a>

          

          
        </div>
      </div>
      
      
      
        <a class="navbar-item" href="/en/faq">FAQ</a>
      
      

    </div>

    <div class="navbar-end">

      <span class="navbar-item">
         
           
      </span>

    </div> </div> </nav>
<div class="columns">
      
      <aside id="toc-sidebar-content" class="column is-one-third menu is-hidden-mobile">
        <ul class="menu-list column is-one-third">
  <li><a href="#workflows">Workflows</a>
    <ul>
      <li><a href="#image-optimization-page-level">Image Optimization (Page Level)</a>
        <ul>
          <li><a href="#step-0-image-enhancement-page-level-optional">Step 0: Image Enhancement (Page Level, optional)</a>
            <ul>
              <li><a href="#available-processors">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-1-binarization-page-level">Step 1: Binarization (Page Level)</a>
            <ul>
              <li><a href="#available-processors-1">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-2-cropping-page-level">Step 2: Cropping (Page Level)</a>
            <ul>
              <li><a href="#available-processors-2">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-3-binarization-page-level">Step 3: Binarization (Page Level)</a>
            <ul>
              <li><a href="#available-processors-3">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-4-denoising-page-level">Step 4: Denoising (Page Level)</a>
            <ul>
              <li><a href="#available-processors-4">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-5-deskewing-page-level">Step 5: Deskewing (Page Level)</a>
            <ul>
              <li><a href="#available-processors-5">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-6-dewarping-page-level">Step 6: Dewarping (Page Level)</a>
            <ul>
              <li><a href="#available-processors-6">Available processors</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#layout-analysis">Layout Analysis</a>
        <ul>
          <li><a href="#step-7-region-segmentation">Step 7: Region segmentation</a>
            <ul>
              <li><a href="#available-processors-7">Available processors</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#image-optimization-region-level">Image Optimization (Region Level)</a>
        <ul>
          <li><a href="#step-8--binarization-region-level">Step 8:  Binarization (Region Level)</a>
            <ul>
              <li><a href="#available-processors-8">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-9--deskewing-region-level">Step 9:  Deskewing (Region Level)</a>
            <ul>
              <li><a href="#available-processors-9">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-10--clipping-region-level">Step 10:  Clipping (Region Level)</a>
            <ul>
              <li><a href="#available-processors-10">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-11-line-segmentation">Step 11: Line segmentation</a>
            <ul>
              <li><a href="#available-processors-11">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-12-resegmentation-line-level">Step 12: Resegmentation (Line Level)</a>
            <ul>
              <li><a href="#available-processors-12">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-13-dewarping-line-level">Step 13: Dewarping (Line Level)</a>
            <ul>
              <li><a href="#available-processors-13">Available processors</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#text-recognition">Text Recognition</a>
        <ul>
          <li><a href="#step-14-text-recognition">Step 14: Text recognition</a>
            <ul>
              <li><a href="#available-processors-14">Available processors</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#post-correction-optional">Post Correction (Optional)</a>
        <ul>
          <li><a href="#step-15-text-alignment">Step 15: Text alignment</a>
            <ul>
              <li><a href="#available-processors-15">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-16-post-correction">Step 16: Post-correction</a>
            <ul>
              <li><a href="#available-processors-16">Available processors</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#evaluation-optional">Evaluation (Optional)</a>
        <ul>
          <li><a href="#step-17-ocr-evaluation">Step 17: OCR Evaluation</a>
            <ul>
              <li><a href="#available-processors-17">Available processors</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#generic-data-management-optional">Generic Data Management (Optional)</a>
        <ul>
          <li><a href="#step-18-adaptation-of-coordinates">Step 18: Adaptation of Coordinates</a>
            <ul>
              <li><a href="#available-processors-18">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-19-format-conversion">Step 19: Format Conversion</a>
            <ul>
              <li><a href="#available-processors-19">Available processors</a></li>
            </ul>
          </li>
          <li><a href="#step-20-dummy-processing">Step 20: Dummy Processing</a>
            <ul>
              <li><a href="#available-processors-20">Available processors</a></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#recommendations">Recommendations</a>
    <ul>
      <li><a href="#best-results-for-selected-pages">Best results for selected pages</a>
        <ul>
          <li><a href="#example-with-ocrd-process">Example with ocrd-process</a></li>
        </ul>
      </li>
      <li><a href="#good-results-for-slower-processors">Good results for slower processors</a>
        <ul>
          <li><a href="#example-with-ocrd-process-1">Example with ocrd-process</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

      </aside>
      <div id="toc-sidebar-toggle">&lt;&gt;</div>
      

      <main class="container content column is-two-thirds" aria-label="Content">
        <h1 id="workflows">Workflows</h1>
<p>There are several steps necessary to get the fulltext of a scanned print. The whole OCR process is shown in the following figure:</p>

<p><img src="/assets/Funktionsmodell.png" alt="" /></p>

<p>The following instructions describe all steps of an OCR workflow. Depending on your particular print (or rather images), not all of those
steps might be necessary to obtain good results. Whether a step is required or optional is indicated in the description of each step.
This guide provides an overview of the available OCR-D processors and their required parameters. For more complex workflows and recommendations
see the <a href="https://github.com/OCR-D/ocrd-website/wiki">OCR-D-Website-Wiki</a>. Feel free to add your own experiences and recommendations in the Wiki!
We will regularly amend this guide with valuable contributions from the Wiki.</p>

<p><strong>Note:</strong> In order to be able to run the workflows described in this guide, you need to have prepared your images in an <a href="https://ocr-d.de/en/user_guide#preparing-a-workspace">OCR-D-workspace</a>. 
We expect that you are familiar with the <a href="https://ocr-d.de/en/user_guide">OCR-D-user guide</a> which explains all preparatory steps, syntax and different
solutions for executing whole workflows.</p>

<h2 id="image-optimization-page-level">Image Optimization (Page Level)</h2>
<p>At first, the image should be prepared for OCR.</p>

<h3 id="step-0-image-enhancement-page-level-optional">Step 0: Image Enhancement (Page Level, optional)</h3>
<p>Optionally, you can start off your workflow by enhancing your images, which can be vital for the following binarization. In this processing step,
the raw image is taken and enhanced by e.g. grayscale conversion, brightness normalization, noise filtering, etc.</p>

<p><strong>Note:</strong> <code class="highlighter-rouge">ocrd-preprocess-image</code> can be used to run arbitrary shell commands for preprocessing (original or derived) images, and can be seen as a generic OCR-D wrapper for many of the following workflow steps, provided a matching external tool exists. (The only restriction is that the tool must not change image size or the position/coordinates of its content.)</p>

<h4 id="available-processors">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remark</th>
      <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-im6convert</td>
      <td>
      <p><code><pre>
{
  "output-format": "image/tiff" # or "image/jp2", "image/png"...
}
      </pre></code></p>
      </td>
      <td>for <code>output-options</code> see <a href="https://imagemagick.org/script/command-line-options.php">IM Documentation</a></td>
      <td><code>ocrd-im6convert -I OCR-D-IMG -O OCR-D-ENH -P output-format image/tiff</code></td>
    </tr>
    <tr>
      <td>ocrd-preprocess-image</td>
      <td>
      <p><code><pre>{
  "input_feature_filter": "binarized",
  "output_feature_added": "binarized",
  "command": "scribo-cli sauvola-ms-split '@INFILE' '@OUTFILE' --enable-negate-output"
  }</pre></code></p>
	  </td>
      <td>
	  for parameters and command examples (presets) see [the Readme](https://github.com/bertsky/ocrd_wrap#ocr-d-processor-interface-ocrd-preprocess-image)
	  </td>
      <td><code>
	  ocrd-preprocess-image -I OCR-D-IMG -O OCR-D-PREP -P output_feature_added binarized -P command "scribo-cli sauvola-ms-split @INFILE @OUTFILE --enable-negate-output"
	  </code></td>
    </tr>
    <tr>
      <td>ocrd-skimage-normalize</td>
      <td>
	  </td>
      <td>
	  </td>
      <td><code>
	  ocrd-skimage-normalize -I OCR-D-IMG -O OCR-D-NORM
	  </code></td>
    </tr>
	<tr>
      <td>ocrd-skimage-denoise-raw</td>
      <td>
	  </td>
      <td>
	  </td>
      <td><code>
	  ocrd-skimage-denoise-raw -I OCR-D-IMG -O OCR-D-DENOISE
	  </code></td>
    </tr>
  </tbody>
</table>

<h3 id="step-1-binarization-page-level">Step 1: Binarization (Page Level)</h3>

<p>All the images should be binarized right at the beginning of your workflow.
Many of the following processors require binarized images. Some implementations
(for deskewing, segmentation or recognition) may produce better results using
the original image. But these can always retrieve the raw image instead of the
binarized version automatically.</p>

<p>In this processing step, a scanned colored /gray scale document image is taken
as input and a black and white binarized image is produced. This step should
separate the background from the foreground.</p>

<p><strong>Note:</strong> Binarization tools usually provide a threshold parameter which allows
you to increase or decrease the weight of the foreground. This is optional and
can be especially useful for images which have not been enhanced.</p>

<table class="before-after">
  <tbody>
    <tr>
      <td>
        <a href="/assets/workflow/Original.png"><img src="/assets/workflow/Original.png" /></a>
      </td>
      <td>
        <a href="/assets/workflow/OCR-D-BIN_0001-BIN_sauvola.png"><img src="/assets/workflow/OCR-D-BIN_0001-BIN_sauvola.png" /></a>
      </td>
    </tr>
  </tbody>
</table>

<h4 id="available-processors-1">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remark</th>
      <th>Call</th>
	</tr>
  </thead>
  <tbody>   
    <tr>
      <td>ocrd-olena-binarize</td>
      <td>
      <p><code>
      {"k": float}
      </code></p>
      </td>
      <td>Recommended</td>
      <td><code>ocrd-olena-binarize -I OCR-D-IMG -O OCR-D-BIN</code></td>
    </tr>
	<tr>
      <td>ocrd-cis-ocropy-binarize</td>
      <td>
	  <p><code>
{"threshold": float}
      </code></p>	  
	  </td>
      <td></td>
      <td><code>ocrd-cis-ocropy-binarize -I OCR-D-IMG -O OCR-D-BIN</code></td>
    </tr>
	<tr>
      <td>ocrd-skimage-binarize</td>
      <td>
	  </td>
      <td>
	  </td>  
      <td><code>ocrd-skimage-binarize -I OCR-D-IMG -O OCR-D-BIN</code></td>
	</tr>	
	  <td>ocrd-anybaseocr-binarize</td>
      <td>
	  <p><code>
{"threshold": float}
      </code></p>
	  </td>
      <td>Fast</td>
      <td><code>ocrd-anybaseocr-binarize -I OCR-D-IMG -O OCR-D-BIN</code></td>
    &lt;/tr&gt;
  </tbody>
</table>

<h3 id="step-2-cropping-page-level">Step 2: Cropping (Page Level)</h3>

<p>In this processing step, a document image is taken as input and the page
is cropped to the content area only (i.e. without noise at the margins or facing pages) by marking the coordinates of the page frame.</p>

<table class="before-after">
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        <a href="/assets/workflow/denoise.png"><img src="/assets/workflow/denoise.png" alt="" /></a>
      </td>
      <td>
        <a href="/assets/workflow/OCR-D-IMG-CROP_0001.png"><img src="/assets/workflow/OCR-D-IMG-CROP_0001.png" alt="" /></a>
      </td>
    </tr>
  </tbody>
</table>

<h4 id="available-processors-2">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-anybaseocr-crop</td>
      <td>&nbsp;</td>
      <td>The input image has to be binarized and <br />should be deskewed for the module to work.</td>
	  <td><code>ocrd-anybaseocr-crop -I OCR-D-BIN -O OCR-D-CROP</code></td>
    </tr>
    <tr>
      <td>ocrd-tesserocr-crop</td>
      <td>&nbsp;</td>
      <td></td>
	  <td><code>ocrd-tesserocr-crop -I OCR-D-BIN -O OCR-D-CROP</code></td>
    </tr>
  </tbody>
</table>

<h3 id="step-3-binarization-page-level">Step 3: Binarization (Page Level)</h3>

<p>For better results, the cropped images can be binarized again at this point or later on (on region level).</p>

<h4 id="available-processors-3">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remark</th>
      <th>Call</th>
	</tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-olena-binarize</td>
      <td>
      </td>
      <td>Recommended</td>
      <td><code>ocrd-olena-binarize -I OCR-D-CROP -O OCR-D-BIN2</code></td>
    </tr>
	<tr>
      <td>ocrd-skimage-binarize</td>
      <td>
	  </td>
      <td>
	  </td>
      <td><code>ocrd-skimage-binarize -I OCR-D-CROP -O OCR-D-BIN2</code></td>
    </tr>
	<tr>
      <td>ocrd-cis-ocropy-binarize</td>
      <td></td>
      <td></td>
      <td><code>ocrd-cis-ocropy-binarize -I OCR-D-CROP -O OCR-D-BIN2</code></td>
    </tr>
  </tbody>
</table>

<h3 id="step-4-denoising-page-level">Step 4: Denoising (Page Level)</h3>

<p>In this processing step, artifacts like little specks (both in foreground or background) are removed from the binarized image.</p>

<p>This may not be necessary for all prints, and depends heavily on the selected binarization algorithm.</p>

<table class="before-after">
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        <a href="/assets/workflow/OCR-D-BIN_0001-BIN_sauvola.png"><img src="/assets/workflow/OCR-D-IMG-CROP-ALTERNATE_0009.png" alt="" /></a>
      </td>
      <td>
        <a href="/assets/workflow/denoise.PNG"><img src="/assets/workflow/OCR-D-IMG-DENOISE-ALTERNATE_0009.png" alt="" /></a>
        </td>
    </tr>
  </tbody>
</table>

<h4 id="available-processors-4">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-cis-ocropy-denoise</td>
      <td><code></code></td>
      <td>&nbsp;</td>
	  <td><code>ocrd-cis-ocropy-denoise -I OCR-D-BIN2 -O OCR-D-DENOISE</code></td>
    </tr>
	<tr>
      <td>ocrd-skimage-denoise</td>
      <td></td>
      <td>&nbsp;</td>
	  <td><code>ocrd-skimage-denoise -I OCR-D-BIN2 -O OCR-D-DENOISE</code></td>
    </tr>
  </tbody>
</table>

<h3 id="step-5-deskewing-page-level">Step 5: Deskewing (Page Level)</h3>

<p>In this processing step, a document image is taken as input and the skew of
that page is corrected by annotating the detected angle (-45° .. 45°) and rotating the image. Optionally, also the orientation is corrected by annotating the detected angle (multiples of 90°) and transposing the image.
The input images have to be binarized for this module to work.</p>

<table class="before-after">
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        <a href="/assets/workflow/OCR-D-IMG-DESPECK_0001.png"><img src="/assets/workflow/OCR-D-IMG-DESPECK_0001.png" alt="" /></a>
      </td>
      <td>
        <a href="/assets/workflow/OCR-D-IMG-DESKEW_0001.png"><img src="/assets/workflow/OCR-D-IMG-DESKEW_0001.png" alt="" /></a>
      </td>
    </tr>
  </tbody>
</table>

<h4 id="available-processors-5">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
   <tr>
      <td>ocrd-cis-ocropy-deskew</td>
      <td><code>{"level-of-operation": "page"}</code></td>
      <td>Recommended</td>
	  <td><code>ocrd-cis-ocropy-deskew -I OCR-D-DENOISE -O OCR-D-DESKEW-PAGE -P level-of-operation page</code></td>
    </tr>    
	<tr>
      <td>ocrd-tesserocr-deskew</td>
      <td><code>{"operation_level”:”page”}</code></td>
      <td>Fast, also performs a decent orientation correction</td>
	  <td><code>ocrd-tesserocr-deskew -I OCR-D-DENOISE -O OCR-D-DESKEW-PAGE -P operation_level page</code></td>
    </tr>
    <tr>
      <td>ocrd-anybaseocr-deskew</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
	  <td><code>ocrd-anybaseocr-deskew -I OCR-D-DENOISE -O OCR-D-DESKEW-PAGE</code></td>
    </tr>	
  </tbody>
</table>

<h3 id="step-6-dewarping-page-level">Step 6: Dewarping (Page Level)</h3>

<p>In this processing step, a document image is taken as input and the text lines are straightened or stretched
if they are curved. The input image has to be binarized for the module to work.</p>

<table class="before-after">
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
      <a href="/assets/workflow/OCR-D-IMG-TO-DEWARP_0005.png"><img src="/assets/workflow/OCR-D-IMG-TO-DEWARP_0005.png" alt="" /></a>
      </td>
      <td>
      <a href="/assets/workflow/OCR-D-IMG-DEWARPEP_0005.png"><img src="/assets/workflow/OCR-D-IMG-DEWARPEP_0005.png" alt="" /></a>
      </td>
    </tr>
  </tbody>
</table>

<h4 id="available-processors-6">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
      <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-anybaseocr-dewarp</td>
      <td>
      <code>
      <pre>
{
  "pix2pixHD":"/path/to/pix2pixHD/",
  "model_name":"/path/to/pix2pixHD/models"
}
      </pre>
      </code>
      </td>
      <td>For available models take a look at this <a href="https://github.com/mjenckel/ocrd_anybaseocr/tree/master/ocrd_anybaseocr/models">site</a> <br /> Parameter <code>model_name</code> is misleading. Given directory has to contain a file named ‘latest_net_G.pth’ <br /> <strong>GPU required!</strong></td>
      <td>
        <code>ocrd-anybaseocr-dewarp -I OCR-D-DESKEW-PAGE -O OCR-D-DEWARP-PAGE -p '{\"pix2pixHD\":\"/path/to/pix2pixHD/\",\"model_name\":\"/path/to/pix2pixHD/models\"}'</code>
      </td>
    </tr>
  </tbody>
</table>

<h2 id="layout-analysis">Layout Analysis</h2>

<p>By now the image should be well prepared for segmentation.</p>

<h3 id="step-7-region-segmentation">Step 7: Region segmentation</h3>

<p>In this processing step, an (optimized) document image is taken as an input and the
image is segmented into the various regions, including columns.
Segments are also classified, either coarse (text, separator, image, table, …) or fine-grained (paragraph, marginalia, heading, …).</p>

<p><strong>Note:</strong> If you use <code class="highlighter-rouge">ocrd-tesserocr-segment-region</code>, which uses only bounding boxes instead of polygon coordinates, 
then you should post-process via <code class="highlighter-rouge">ocrd-segment-repair</code> with <code class="highlighter-rouge">plausibilize=True</code> to obtain better results without large overlaps.</p>

<p><strong>Note:</strong> The <code class="highlighter-rouge">ocrd-sbb-textline-detector</code> and <code class="highlighter-rouge">ocrd-cis-ocropy-segment</code> processors do not only segment the page, but also the text lines within
the detected text regions in one step. Therefore with those (and only with those!) processors you don’t
need to segment into lines in an extra step.</p>

<table class="before-after">
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        <a href="/assets/workflow/OCR-D-IMG-CROP_0001.png"><img src="/assets/workflow/OCR-D-IMG-CROP_0001.png" alt="" /></a>
      </td>
      <td>
        <a href="/assets/workflow/seg-page.PNG"><img src="/assets/workflow/seg-page.PNG" alt="" /></a>
      </td>
    </tr>
  </tbody>
</table>

<h4 id="available-processors-7">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-tesserocr-segment-region</td>
      <td>&nbsp;</td>
      <td>Recommended</td>
	  <td><code>ocrd-tesserocr-segment-region -I OCR-D-DEWARP-PAGE -O OCR-D-SEG-REG</code></td>
    </tr>
	<tr>
      <td>ocrd-segment-repair</td>
      <td><code>{"plausibilize":true}</code></td>
      <td>Only to be used after `ocrd-tesserocr-segment-region`</td>
	  <td><code>ocrd-segment-repair -I OCR-D-SEG-REG -O OCR-D-SEG-REPAIR -P plausibilize true</code></td>
    </tr>
    <tr>
      <td>ocrd-sbb-textline-detector</td>
      <td>{"model": /path/to/model"}</td>
      <td>Models can be found [here](https://qurator-data.de/sbb_textline_detector/); you need to **pass your local path to the model on your hard drive**
	  as parameter value for this processor to work!</td>
	  <td><code>ocrd-sbb-textline-detector -I OCR-D-DEWARP-PAGE -O OCR-D-SEG-LINE -P model /path/to/model</code></td>
    </tr>
	<tr>
      <td>ocrd-cis-ocropy-segment</td>
      <td><code>{"level-of-operation":"page"}</code></td>
      <td>&nbsp;</td>
	  <td><code>ocrd-cis-ocropy-segment -I OCR-D-DEWARP-PAGE -O OCR-D-SEG-LINE -P level-of-operation page</code></td>
    </tr>
	<tr>
      <td>ocrd-anybaseocr-block-segmentation</td>
      <td><pre>
{
  "block_segmentation_model": "/path/to/mrcnn",
  "block_segmentation_weights": "/path/to/model/block_segmentation_weights.h5"
}
      </pre>
      </td>
      <td>For available models take a look at this &lt;a href="https://github.com/OCR-D/ocrd_anybaseocr/tree/master/ocrd_anybaseocr/models"; you need to **pass your local path to the model on your hard drive**
	  as parameter value for this processor to work!&gt;site&lt;/a&gt;</td>
	  <td><code>ocrd-anybaseocr-block-segmentation -I OCR-D-DEWARP-PAGE -O OCR-D-SEG-REG -P block_segmentation_model /path/to/mrcnn -P block_segmentation_weights /path/to/model/block_segmentation_weights.h5</code></td>
    </tr>
	<tr>
      <td>ocrd-pc-segmentation</td>
      <td>
      </td>
      <td>
	  </td>
	  <td><code>ocrd-pc-segmentation -I OCR-D-DEWARP-PAGE -O OCR-D-SEG-REG</code></td>
    </tr>
  </tbody>
</table>

<h2 id="image-optimization-region-level">Image Optimization (Region Level)</h2>

<p>In the following steps, the text regions should be optimized for OCR.</p>

<h3 id="step-8--binarization-region-level">Step 8:  Binarization (Region Level)</h3>

<p>In this processing step, a scanned colored /gray scale document image is taken as input and a black
and white binarized image is produced. This step should separate the background from the foreground.</p>

<p>The binarization should be at least executed once (on page or region level). If you already binarized
your image twice on page level, and have no large images, you can probably skip this step.</p>

<h4 id="available-processors-8">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-skimage-binarize</td>
      <td>
	  <p><code>
{"level-of-operation": "region"}
      </code></p>	
	  </td>
      <td>
	  </td>
	  <td><code>ocrd-skimage-binarize -I OCR-D-SEG-REG -O OCR-D-BIN-REG -P level-of-operation region</code></td>
    </tr>    
	<tr>
      <td>ocrd-preprocess-image</td>
      <td><code>{"level-of-operation":"region","output_feature_added": "binarized","command": "scribo-cli sauvola-ms-split '@INFILE' '@OUTFILE' --enable-negate-output"}</code></td>
      <td>&nbsp;</td>
	  <td><code>
	  ocrd-preprocess-image -I OCR-D-SEG-REG -O OCR-D-BIN-REG -P level-of-operation region -P output_feature_added binarized -P command "scribo-cli sauvola-ms-split @INFILE @OUTFILE --enable-negate-output"
	  </code></td>
	  &lt;/td&gt;
    </tr>
    <tr>
      <td>ocrd-cis-ocropy-binarize</td>
      <td>
	  <p><code>
{"level-of-operation": "region", "noise_maxsize": float}
      </code></p>	  
	  </td>
      <td></td>
      <td><code>ocrd-cis-ocropy-binarize -I OCR-D-SEG-REG -O OCR-D-BIN-REG -P level-of-operation region</code></td>
    </tr>
  </tbody>
</table>

<h3 id="step-9--deskewing-region-level">Step 9:  Deskewing (Region Level)</h3>

<p>In this processing step, text region images are taken as input and their skew is corrected by annotating the detected angle (-45° .. 45°) and rotating the image. Optionally, also the orientation is corrected by annotating the detected angle (multiples of 90°) and transposing the image.</p>

<table class="before-after">
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
      <a href="/assets/workflow/seg-page.PNG"><img src="/assets/workflow/seg-page.PNG" alt="" /></a>
      </td>
      <td>
      <a href="/assets/workflow/OCR-D-IMG-DESKEW_0001_region0002.png"><img src="/assets/workflow/OCR-D-IMG-DESKEW_0001_region0002.png" alt="" /></a>
      </td>
    </tr>
  </tbody>
</table>

<h4 id="available-processors-9">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-cis-ocropy-deskew</td>
      <td><code>{"level-of-operation":"region"}</code></td>
      <td>&nbsp;</td>
	  <td><code>ocrd-cis-ocropy-deskew -I OCR-D-BIN-REG -O OCR-D-DESKEW-REG -P level-of-operation region</code></td>
    </tr>
    <tr>
      <td>ocrd-tesserocr-deskew</td>
      <td>&nbsp;</td>
      <td>Fast, also performs a decent orientation correction</td>
	  <td><code>ocrd-tesserocr-deskew -I OCR-D-BIN-REG -O OCR-D-DESKEW-REG</code></td>
    </tr>	
  </tbody>
</table>

<h3 id="step-10--clipping-region-level">Step 10:  Clipping (Region Level)</h3>

<p>In this processing step, intrusions of neighbouring non-text (e.g. separator) or text segments (e.g. ascenders/descenders) into
text regions of a page can be removed. A connected component analysis is run on every text region,
as well as its overlapping neighbours. Now for each conflicting binary object,
a rule based on majority and proper containment determines whether it belongs to the neighbour, and can therefore
be clipped to the background.</p>

<p>This basic text-nontext segmentation ensures that for each text region there is a clean image without interference from separators and neighbouring texts. (Cleaning via coordinates would be impossible in many common cases.)</p>

<p>TODO: add images</p>

<h4 id="available-processors-10">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-cis-ocropy-clip</td>
      <td><code>{"level-of-operation":"region"}</code></td>
      <td>&nbsp;</td>
	  <td><code>ocrd-cis-ocropy-clip -I OCR-D-DESKEW-REG -O OCR-D-CLIP-REG -P level-of-operation region</code></td>
    </tr>
  </tbody>
</table>

<h3 id="step-11-line-segmentation">Step 11: Line segmentation</h3>

<p>In this processing step, text regions are segmented into text lines. 
A line detection algorithm is run on every text region of every PAGE in the
input file group, and a TextLine element with the resulting polygon
outline is added to the annotation of the output PAGE.</p>

<p><strong>Note:</strong> If you use <code class="highlighter-rouge">ocrd-tesserocr-segment-line</code>, which uses only bounding boxes instead of polygon coordinates, 
then you should post-process with the processors described in <a href="#step-12-resegmentation-line-level">Step 12</a>. 
If you use <code class="highlighter-rouge">ocrd-cis-ocropy-segment</code>, you can directly go on with <a href="#step-13-dewarping-on-line-level">Step 13</a>.</p>

<p><strong>Note:</strong> As described in <a href="#step-7-page-segmentation">Step 7</a>, <code class="highlighter-rouge">ocrd-sbb-textline-detector</code> and <code class="highlighter-rouge">ocrd-cis-ocropy-segment</code> do not only segment 
the page, but also the text lines within the detected text regions in one step. Therefore with those (and only with those!) processors you don’t
need to segment into lines in an extra step.</p>

<table class="">
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
      <a href="/assets/workflow/OCR-D-IMG-DESKEW_0001_region0002.png"><img src="/assets/workflow/OCR-D-IMG-DESKEW_0001_region0002.png" alt="" /></a>
      </td>
      <td>
      <a href="/assets/workflow/OCR-D-IMG-DEWARP_0001_region0002_region0002_line0005.png"><img src="/assets/workflow/OCR-D-IMG-DEWARP_0001_region0002_region0002_line0005.png" alt="" /></a>
      </td>
    </tr>
  </tbody>
</table>

<h4 id="available-processors-11">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-cis-ocropy-segment</td>
      <td><code>{"level-of-operation":"region"}</code></td>
      <td>&nbsp;</td>
	  <td><code>ocrd-cis-ocropy-segment -I OCR-D-CLIP-REG -O OCR-D-SEG-LINE -P level-of-operation region</code></td>
    </tr>
    <tr>
      <td>ocrd-tesserocr-segment-line</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
	  <td><code>ocrd-tesserocr-segment-line -I OCR-D-CLIP-REG -O OCR-D-SEG-LINE</code></td>
    </tr>
  </tbody>
</table>

<h3 id="step-12-resegmentation-line-level">Step 12: Resegmentation (Line Level)</h3>

<p>In this processing step the segmented lines can be corrected.</p>

<p>TODO: add images</p>

<h4 id="available-processors-12">Available processors</h4>
<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-cis-ocropy-clip</td>
      <td><code>{"level-of-operation":"line"}</code></td>
      <td>&nbsp;</td>
	  <td><code>ocrd-cis-ocropy-clip -I OCR-D-SEG-LINE -O OCR-D-CLIP-LINE -P level-of-operation line</code></td>
    </tr>
    <tr>
      <td>ocrd-cis-ocropy-resegment</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
	  <td><code>ocrd-cis-ocropy-resegment -I OCR-D-SEG-LINE -O OCR-D-RESEG</code></td>
    </tr>
  </tbody>
</table>

<h3 id="step-13-dewarping-line-level">Step 13: Dewarping (Line Level)</h3>

<p>In this processing step, the text line images get vertically aligned if they are curved.</p>

<table class="">
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
      <a href="/assets/workflow/OCR-D-IMG-DEWARP_0001_region0002_region0002_line0005.png"><img src="/assets/workflow/OCR-D-IMG-DEWARP_0001_region0002_region0002_line0005.png" alt="" /></a>
      </td>
      <td>
      <a href="/assets/workflow/OCR-D-IMG-DEWARP_0001_region0002_region0002_line0005.png"><img src="/assets/workflow/OCR-D-IMG-DEWARP_0001_region0002_region0002_line0005.png" alt="" /></a>
      </td>
    </tr>
  </tbody>
</table>

<h4 id="available-processors-13">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-cis-ocropy-dewarp</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
	  <td><code>ocrd-cis-ocropy-dewarp -I OCR-D-CLIP-LINE -O OCR-D-DEWARP-LINE</code></td>
    </tr>
  </tbody>
</table>

<h2 id="text-recognition">Text Recognition</h2>

<h3 id="step-14-text-recognition">Step 14: Text recognition</h3>

<p>This processor recognizes text in segmented lines.</p>

<p>An overview on the existing model repositories and short descriptions on the most important models can be found <a href="https://ocr-d.de/en/models">here</a>.</p>

<h4 id="available-processors-14">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-tesserocr-recognize</td>
      <td>
      <p>
      <code>
      {"model": "Fraktur"}
      </code>
      </p>
      <p>
      <code>
      {"model": "GT4HistOCR_50000000.997_191951"}
      </code>
      </p>
      </td>
      <td>Recommended <br /> Model can be found <a href="https://ub-backup.bib.uni-mannheim.de/~stweil/ocrd-train/data/Fraktur_5000000/">here</a><br />/tessdata_best/GT4HistOCR_50000000.997_191951.traineddata)</td>
	  <td><code>ocrd-tesserocr-recognize -I OCR-D-DEWARP-LINE -O OCR-D-OCR -P model Fraktur</code></td>
    </tr>
    <tr>
      <td>ocrd-calamari-recognize</td>
      <td>
        <code>
{"checkpoint":"/path/to/models/\*.ckpt.json"}
        </code>
      </td>
      <td>
        Recommended<br />Model can be found <a href="https://ocr-d-repo.scc.kit.edu/models/calamari/GT4HistOCR/model.tar.xz">here</a>; you need 
		to **pass your local path to the model on your hard drive** as parameter value for this processor to work! 
      </td>
	  <td><code>ocrd-calamari-recognize -I OCR-D-DEWARP-LINE -O OCR-D-OCR -P checkpoint /path/to/models/\*.ckpt.json</code></td>
    </tr>
  </tbody>
</table>

<p><strong>Note:</strong> For <code class="highlighter-rouge">ocrd-tesserocr</code> the environment variable <code class="highlighter-rouge">TESSDATA_PREFIX</code> has
to be set to point to the directory where the used models are stored. (The
directory should at least contain the following models: <code class="highlighter-rouge">deu.traineddata</code>,
<code class="highlighter-rouge">eng.taineddata</code>, <code class="highlighter-rouge">osd.traineddata</code>)</p>

<p><strong>Note:</strong> If you want to go on with the optional post correction, you should also set the <code class="highlighter-rouge">textequiv_level</code> to <code class="highlighter-rouge">glyph</code> or in the case of 
<code class="highlighter-rouge">ocrd-calamari-recognize</code> at least <code class="highlighter-rouge">word</code> (which is already the default for <code class="highlighter-rouge">ocrd-tesserocr-recognize</code>).</p>

<h2 id="post-correction-optional">Post Correction (Optional)</h2>

<h3 id="step-15-text-alignment">Step 15: Text alignment</h3>

<p>In this processing step, text results from multiple OCR engines (in different annotations sharing the same line segmentation) are aligned 
into one annotation with <code class="highlighter-rouge">TextEquiv</code> alternatives.</p>

<p><strong>Note:</strong> This step is only required if you want to do post-correction afterwards,
feeding alternative character hypotheses from several OCR-engines to improve the search space.
The previous recognition step must be run on glyph or at least on word level.</p>

<h4 id="available-processors-15">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-cis-align</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
	  <td><code>ocrd-cis-align -I OCR-D-OCR1,OCR-D-OCR2 -O OCR-D-ALIGN</code></td>
    </tr>
  </tbody>
</table>

<h3 id="step-16-post-correction">Step 16: Post-correction</h3>

<p>In this processing step, the recognized text is corrected by statistical error modelling, language modelling, and word modelling (dictionaries, 
morphology and orthography).</p>

<p><strong>Note:</strong> Most tools benefit strongly from input which includes alternative OCR hypotheses. Currently, models for <code class="highlighter-rouge">ocrd-cor-asv-ann-process</code>
are optimised for input from single OCR engines, whereas <code class="highlighter-rouge">ocrd-cis-postcorrect</code> expects input from multi-OCR alignment.</p>

<h4 id="available-processors-16">Available processors</h4>
<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-cor-asv-ann-process</td>
      <td><code>{"textequiv_level":"word","model_file":"/path/to/model/model.h5"}</code></td>
      <td>Models can be found <a href="https://github.com/ASVLeipzig/cor-asv-ann-models">here</a>; you need to **pass your local path to the model on your hard drive**
	  as parameter value for this processor to work!</td>
	  <td><code>ocrd-cor-asv-ann-process -I OCR-D-OCR -O OCR-D-PROCESS -P textequiv_level word -P model_file /path/to/model/model.h5</code></td>
    </tr>
    <tr>
      <td>ocrd-cis-postcorrect</td>
      <td><code>
	  {"profilerPath": "/path/to/profiler.bash","profilerConfig": str,"nOCR": int,"model": "/path/to/model/model.zip"}
	  </code></td>
      <td>
	  The various parameters should be specified in a JSON file. If you don't want to use a profiler, you can set the value for "profilerConfig" to 
	  "ignored". In this case, your profiler.bash should look like this: 
	  `#!/bin/bash
	  cat &gt; /dev/null
	  echo '{}'`
	  you need to **pass your local path to the model on your hard drive** as parameter value for this processor to work!
	  </td>
	  <td><code>ocrd-cis-postcorrect -I OCR-D-ALIGN -O OCR-D-CORRECT -p postcorrect.json</code></td>
    </tr>
  </tbody>
</table>

<h2 id="evaluation-optional">Evaluation (Optional)</h2>

<p>If Ground Truth data is available, the OCR can be evaluated.</p>

<h3 id="step-17-ocr-evaluation">Step 17: OCR Evaluation</h3>

<p>In this processing step, the text output of the OCR or post-correction can be evaluated by aligning with ground truth text and measuring the error rates.</p>

<h4 id="available-processors-17">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-dinglehopper</td>
      <td>&nbsp;</td>
      <td>First input group should point to the ground truth.</td>
	  <td><code>ocrd-dinglehopper -I OCR-D-GT,OCR-D-OCR -O OCR-D-EVAL</code></td>
    </tr>
	<tr>
      <td>ocrd-cor-asv-ann-evaluate</td>
      <td>
      <p>
      <code>
      {"metric": "Levenshtein" (default), "NFC", "NFKC", "historic-latin"}
      </code>
      <code>
      {"confusion": integer}
      </code>
      </p>	  
	  </td>
      <td>First input group should point to the ground truth. There is no output file group, it only uses logging. If you want to save the evaluation findings in a file, you could e.g. add `2&gt; eval.txt` at the end of your command</td>
	  <td><code>ocrd-cor-asv-ann-evaluate -I OCR-D-GT,OCR-D-OCR</code></td>
    </tr>
  </tbody>
</table>

<h2 id="generic-data-management-optional">Generic Data Management (Optional)</h2>

<p>OCR-D produces PAGE XML files which contain the recognized text as well as detailed
information on the structure of the processed pages, the coordinates of the recognized
elements etc. Optionally, the output can be converted to other formats, or copied verbatim (re-generating PAGE-XML)</p>

<h3 id="step-18-adaptation-of-coordinates">Step 18: Adaptation of Coordinates</h3>

<p>All OCR-D processors are required to relate coordinates to the original image for each page, and to keep the original image reference (<code class="highlighter-rouge">Page/@imageFilename</code>). However, sometimes it may be necessary to deviate from that strict requirement in order to get the overall workflow to work.</p>

<p>For example, if you have a page-level dewarping step, it is currently impossible to correctly relate to the original image’s coordinates for any segments annotated after that, because there is no descriptive annotation of the underlying coordinate transform in PAGE-XML. Therefore, it is better to <em>replace the original image</em> of the output PAGE-XML by the dewarped image before proceeding with the workflow. If the dewarped image has also been cropped or deskewed, then of course all existing coordinates are re-calculated accordingly as well.</p>

<p>Another use case is exporting PAGE-XML for tools that cannot apply cropping or deskewing, like <a href="https://github.com/OCR4all/LAREX">LAREX</a> or Transkribus.</p>

<h4 id="available-processors-18">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-segment-replace-original</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
	  <td><code>ocrd-segment-replace-original -I OCR-D-SEG-LINE -O OCR-D-SUBST</code></td>
    </tr>
  </tbody>
</table>

<h3 id="step-19-format-conversion">Step 19: Format Conversion</h3>

<p>In this processing step the produced PAGE XML files can be converted to ALTO,
PDF, hOCR or text files. Note that ALTO and hOCR can also be converted into
different formats whereas the PDF version of PAGE XML OCR results is a widely
accessible format that can be used as-is by expert and layman alike.</p>

<h4 id="available-processors-19">Available processors</h4>

<table class="processor-table">
<thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
      <th>Call</th>
    </tr>

</thead>
<tbody>
    <tr>
      <td>ocrd-fileformat-transform</td>
      <td><code><pre>
        {"from-to": "alto2.0 alto3.0"} 
        # or {from-to: "alto2.0 alto3.1"}
        # or {from-to: "alto2.0 hocr"}
        # or {from-to: "alto2.1 alto3.0"}
        # or {from-to: "alto2.1 alto3.1"}
        # or {from-to: "alto2.1 hocr"}
        # or {from-to: "alto page"}
        # or {from-to: "alto text"}
        # or {from-to: "gcv hocr"}
        # or {from-to: "hocr alto2.0"}
        # or {from-to: "hocr alto2.1"}
        # or {from-to: "hocr text"}
        # or {from-to: "page alto"}
        # or {from-to: "page hocr"}
        # or {from-to: "page text"}
      </pre></code>
      </td>
      <td>&nbsp;</td>
      <td><code>ocrd-fileformat-transform -I OCR-D-OCR -O OCR-D-ALTO</code></td>
    </tr>
    <tr>
      <td>ocrd-pagetopdf</td>
      <td><code><pre>
      {
        # fix (invalid) negative coordinates
        "negative2zero": true,
        # create a single "fat" PDF
        "multipage": "name_of_pdf",
        # render text on this level
        "textequiv_level": "word",
        # draw polygon outlines in the PDF
        "outlines": "line"
      }
      </pre></code>
      </td>
      <td>&nbsp;</td>
      <td><code>ocrd-pagetopdf -I PAGE-FILEGRP -O PDF-FILEGRP -P textequiv_level word</code></td>
    </tr>

</tbody>
</table>

<h3 id="step-20-dummy-processing">Step 20: Dummy Processing</h3>
<p>Sometimes it can be useful to have a dummy processor, which takes the files in an Input fileGrp and
copies them the a new Output fileGrp, re-generating the PAGE XML from the current namespace schema/model.</p>

<h4 id="available-processors-20">Available processors</h4>

<table class="processor-table">
  <thead>
    <tr>
      <th>Processor</th>
      <th>Parameter</th>
      <th>Remarks</th>
	  <th>Call</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ocrd-dummy</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
	  <td><code>ocrd-dummy -I OCR-D-FILEGRP -O OCR-D-DUMMY</code></td>
    </tr>
  </tbody>
</table>

<h1 id="recommendations">Recommendations</h1>

<p>All processors, with the exception of those for post-correction, were tested on
selected pages of some prints from the 17th and 18th century.</p>

<p>The results vary quite a lot from page to page. In most cases, segmentation is a problem.</p>

<p>These recommendations may also work well for other prints of those centuries.</p>

<p>Note that for our test pages, not all steps described above werde needed to obtain the best results.
Depending on your particular images, you might want to include those processors again for better results.</p>

<h2 id="best-results-for-selected-pages">Best results for selected pages</h2>

<p>The following workflow has produced best results for ‘simple’ pages (e.g. <a href="https://ocr-d-repo.scc.kit.edu/api/v1/dataresources/dda89351-7596-46eb-9736-593a5e9593d3/data/bagit/data/OCR-D-IMG/OCR-D-IMG_0004.tif">this
page</a>)  (CER ~1%).</p>

<table class="processor-table">
  <thead>
    <tr>
      <th>Step</th>
      <th>Processor</th>
      <th>Parameter</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>ocrd-olena-binarize</td>
      <td>{"impl": "sauvola"}</td>
    </tr>
	<tr>
      <td>2</td>
      <td>ocrd-anybaseocr-crop</td>
      <td></td>
    </tr>
    <tr>
      <td>3</td>
      <td>ocrd-olena-binarize</td>
      <td>{"impl": "kim"}</td>
    </tr>
    <tr>
      <td>4</td>
      <td>ocrd-cis-ocropy-denoise</td>
      <td>{"level-of-operation":"page"}</td>
    </tr>
    <tr>
      <td>5</td>
      <td>ocrd-cis-ocropy-deskew</td>
      <td>{"level-of-operation":"page"}</td>
    </tr>
    <tr>
      <td>7</td>
      <td>ocrd-tesserocr-segment-region</td>
      <td></td>
    </tr>
    <tr>  
	  <td>7a</td>
      <td>ocrd-segment-repair</td>
      <td>{"plausibilize": true}</td>
    </tr>
    <tr>
      <td>9</td>
      <td>ocrd-cis-ocropy-deskew</td>
      <td>{"level-of-operation":"region"}</td>
    </tr>
    <tr>
      <td>10</td>
      <td>ocrd-cis-ocropy-clip</td>
      <td>{"level-of-operation":"region"}</td>
    </tr>
    <tr>
      <td>11</td>
      <td>ocrd-cis-ocropy-segment</td>
      <td>{"level-of-operation":"region"}</td>
    </tr>
    <tr>  
	  <td>11a</td>
      <td>ocrd-segment-repair</td>
      <td>{"sanitize": true}</td>
    </tr>
    <tr>
      <td>13</td>
      <td>ocrd-cis-ocropy-dewarp</td>
      <td></td>
    </tr>
    <tr>
      <td>14</td>
      <td>ocrd-calamari-recognize</td>
      <td>{"checkpoint":"/path/to/models/\*.ckpt.json"}</td>
    </tr>
  </tbody> 
</table>

<h3 id="example-with-ocrd-process">Example with ocrd-process</h3>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ocrd process <span class="se">\</span>
  <span class="s2">"olena-binarize -I OCR-D-IMG -O OCR-D-BIN -P impl sauvola"</span> <span class="se">\</span>
  <span class="s2">"anybaseocr-crop -I OCR-D-BIN -O OCR-D-CROP"</span> <span class="se">\</span>
  <span class="s2">"olena-binarize -I OCR-D-CROP -O OCR-D-BIN2 -P impl kim"</span> <span class="se">\</span>
  <span class="s2">"cis-ocropy-denoise -I OCR-D-BIN2 -O OCR-D-BIN-DENOISE -P level-of-operation page"</span> <span class="se">\</span>
  <span class="s2">"cis-ocropy-deskew -I OCR-D-BIN-DENOISE -O OCR-D-BIN-DENOISE-DESKEW -P level-of-operation page"</span> <span class="se">\</span>
  <span class="s2">"tesserocr-segment-region -I OCR-D-BIN-DENOISE-DESKEW -O OCR-D-SEG-REG"</span> <span class="se">\</span>
  <span class="s2">"segment-repair -I OCR-D-SEG-REG -O OCR-D-SEG-REPAIR -P plausibilize true"</span> <span class="se">\</span>
  <span class="s2">"cis-ocropy-deskew -I OCR-D-SEG-REPAIR -O OCR-D-SEG-REG-DESKEW -P level-of-operation region"</span> <span class="se">\</span>
  <span class="s2">"cis-ocropy-clip -I OCR-D-SEG-REG-DESKEW -O OCR-D-SEG-REG-DESKEW-CLIP -P level-of-operation region"</span> <span class="se">\</span>
  <span class="s2">"cis-ocropy-segment -I OCR-D-SEG-REG-DESKEW-CLIP -O OCR-D-SEG-LINE -P level-of-operation region"</span> <span class="se">\</span>
  <span class="s2">"segment-repair -I OCR-D-SEG-LINE -O OCR-D-SEG-REPAIR-LINE -P sanitize true"</span> <span class="se">\</span>
  <span class="s2">"cis-ocropy-dewarp -I OCR-D-SEG-REPAIR-LINE -O OCR-D-SEG-LINE-RESEG-DEWARP"</span> <span class="se">\</span>
  <span class="s2">"calamari-recognize -I OCR-D-SEG-LINE-RESEG-DEWARP -O OCR-D-OCR -P checkpoint /path/to/models/</span><span class="se">\*</span><span class="s2">.ckpt.json"</span>
</code></pre></div></div>

<p><strong>Note:</strong> 
(1) This workflow expects your images to be stored in a folder called <code class="highlighter-rouge">OCR-D-IMG</code>. If your images are saved in a different folder,
you need to adjust <code class="highlighter-rouge">-I OCR-D-IMG</code> in the second line of the call above with the name of your folder, e.g. <code class="highlighter-rouge">-I MAX</code>
(2) For the last processor in this workflow, <code class="highlighter-rouge">ocrd-calamari-recognize</code>, you need to specify your local path to the model on your hard drive
as parameter value! The last line of the <code class="highlighter-rouge">ocrd-process</code> call above could e.g. look like this:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="s2">"calamari-recognize -I OCR-D-SEG-LINE-RESEG-DEWARP -O OCR-D-OCR -P checkpoint /test/data/calamari_models/</span><span class="se">\*</span><span class="s2">.ckpt.json"</span>
</code></pre></div></div>
<p>All the other lines can just be copied and pasted.</p>

<h2 id="good-results-for-slower-processors">Good results for slower processors</h2>

<p>If your computer is not that powerful you may try this workflow. It works fine for simple pages and produces also good results in shorter time.</p>

<table class="processor-table">
  <thead>
    <tr>
      <th>Step</th>
      <th>Processor</th>
      <th>Parameter</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>ocrd-olena-binarize</td>
      <td>{"impl": "sauvola"}</td>
    </tr>
	<tr>
      <td>2</td>
      <td>ocrd-anybaseocr-crop</td>
      <td></td>
    </tr>
    <tr>
      <td>3</td>
      <td>ocrd-olena-binarize</td>
      <td>{"impl": "kim"}</td>
    </tr>
    <tr>
      <td>4</td>
      <td>ocrd-cis-ocropy-denoise</td>
      <td>{"level-of-operation":"page"}</td>
    </tr>
    <tr>
      <td>5</td>
      <td>ocrd-tesserocr-deskew</td>
      <td>{"operation_level":"page"}</td>
    </tr>
    <tr>
      <td>7</td>
      <td>ocrd-tesserocr-segment-region</td>
      <td></td>
    </tr>
    <tr>  
	  <td>7a</td>
      <td>ocrd-segment-repair</td>
      <td>{"plausibilize": true}</td>
    </tr>
    <tr>
      <td>9</td>
      <td>ocrd-cis-ocropy-deskew</td>
      <td>{"level-of-operation":"region"}</td>
    </tr>
    <tr>
      <td>10</td>
      <td>ocrd-cis-ocropy-clip</td>
      <td>{"level-of-operation":"region"}</td>
    </tr>
    <tr>
      <td>11</td>
      <td>ocrd-tesserocr-segment-line</td>
      <td></td>
    </tr>
    <tr>  
	  <td>11a</td>
      <td>ocrd-segment-repair</td>
      <td>{"sanitize": true}</td>
    </tr>
    <tr>
      <td>13</td>
      <td>ocrd-cis-ocropy-dewarp</td>
      <td></td>
    </tr>
    <tr>
      <td>14</td>
      <td>ocrd-calamari-recognize</td>
      <td>{"checkpoint":"/path/to/models/\*.ckpt.json"}</td>
    </tr>
  </tbody> 
</table>

<h3 id="example-with-ocrd-process-1">Example with ocrd-process</h3>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ocrd process <span class="se">\</span>
  <span class="s2">"olena-binarize -I OCR-D-IMG -O OCR-D-BIN -P impl sauvola"</span> <span class="se">\</span>
  <span class="s2">"anybaseocr-crop -I OCR-D-BIN -O OCR-D-CROP"</span> <span class="se">\</span>
  <span class="s2">"olena-binarize -I OCR-D-CROP -O OCR-D-BIN2 -P impl kim"</span> <span class="se">\</span>
  <span class="s2">"cis-ocropy-denoise -I OCR-D-BIN2 -O OCR-D-BIN-DENOISE -P level-of-operation page"</span> <span class="se">\</span>
  <span class="s2">"tesserocr-deskew -I OCR-D-BIN-DENOISE -O OCR-D-BIN-DENOISE-DESKEW -P operation_level page"</span> <span class="se">\</span>
  <span class="s2">"tesserocr-segment-region -I OCR-D-BIN-DENOISE-DESKEW -O OCR-D-SEG-REG"</span> <span class="se">\</span>
  <span class="s2">"segment-repair -I OCR-D-SEG-REG -O OCR-D-SEG-REPAIR -P plausibilize true"</span> <span class="se">\</span>
  <span class="s2">"cis-ocropy-deskew -I OCR-D-SEG-REPAIR -O OCR-D-SEG-REG-DESKEW -P level-of-operation region"</span> <span class="se">\</span>
  <span class="s2">"cis-ocropy-clip -I OCR-D-SEG-REG-DESKEW -O OCR-D-SEG-REG-DESKEW-CLIP -P level-of-operation region"</span> <span class="se">\</span>
  <span class="s2">"tesserocr-segment-line -I OCR-D-SEG-REG-DESKEW-CLIP -O OCR-D-SEG-LINE"</span> <span class="se">\</span>
  <span class="s2">"segment-repair -I OCR-D-SEG-LINE -O OCR-D-SEG-REPAIR-LINE -P sanitize true"</span> <span class="se">\</span>
  <span class="s2">"cis-ocropy-dewarp -I OCR-D-SEG-REPAIR-LINE -O OCR-D-SEG-LINE-RESEG-DEWARP"</span> <span class="se">\</span>
  <span class="s2">"calamari-recognize -I OCR-D-SEG-LINE-RESEG-DEWARP -O OCR-D-OCR -P checkpoint /path/to/models/</span><span class="se">\*</span><span class="s2">.ckpt.json"</span>
</code></pre></div></div>

<p><strong>Note:</strong> 
(1) This workflow expects your images to be stored in a folder called <code class="highlighter-rouge">OCR-D-IMG</code>. If your images are saved in a different folder,
you need to adjust <code class="highlighter-rouge">-I OCR-D-IMG</code> in the second line of the call above with the name of your folder, e.g. <code class="highlighter-rouge">-I my_images</code>
(2) For the last processor in this workflow, <code class="highlighter-rouge">ocrd-calamari-recognize</code>, you need to specify your local path to the model on your hard drive 
as parameter value! The last line of the <code class="highlighter-rouge">ocrd-process</code> call above could e.g. look like this:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="s2">"calamari-recognize -I OCR-D-SEG-LINE-RESEG-DEWARP -O OCR-D-OCR -P checkpoint /test/data/calamari_models/</span><span class="se">\*</span><span class="s2">.ckpt.json"</span>
</code></pre></div></div>
<p>All the other lines can just be copied and pasted.</p>

      </main>
    </div><footer class="footer" style="padding: 1rem">
    <div class="content has-text-centered">
      <img class="footer-logo" src="/assets/dfg_logo_eng.jpg" alt="DFG logo"/>
    </div>
    <!-- <div class="content has-text-centered"> -->
    <!--   <img class="footer-logo" src="/assets/logo-bbaw.png" alt="BBAW logo"/> -->
    <!--   <img class="footer-logo" src="/assets/logo-hab.gif" alt="HAB logo"/> -->
    <!--   <img class="footer-logo" src="/assets/logo-kit.png" alt="KIT logo"/> -->
    <!--   <img class="footer-logo" src="/assets/logo-sbb.png" alt="SBB logo"/> -->
    <!-- </div> -->
    <div class="content has-text-centered">
      <a href="https://github.com/OCR-D">GitHub</a>
      |
      <a href="https://gitter.im/OCR-D/Lobby">gitter</a>
      |
      <a href="https://github.com/OCR-D/ocrd-website/wiki">Wiki</a>
      |
      <a href="https://hub.docker.com/u/ocrd">Docker Hub</a>
      |
      <a href="https://www.zotero.org/groups/418719/ocr-d">Technology Watch</a>
      |
      <a href="/sitemap.xml">sitemap.xml</a>
    </div>

<script src="/assets/script.js"></script>
</footer>
</body>

</html>
