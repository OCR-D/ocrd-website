{
    "ocrd-anybaseocr-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Binarizes images with the algorithm from ocropy and outputs it as an AlternativeImage.",
        "executable": "ocrd-anybaseocr-binarize",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-IMG-BIN"
        ],
        "parameters": {
            "bignore": {
                "default": 0.1,
                "description": "ignore this much of the border for threshold estimation",
                "format": "float",
                "type": "number"
            },
            "debug": {
                "default": 0,
                "description": "display intermediate results",
                "format": "integer",
                "type": "number"
            },
            "escale": {
                "default": 1.0,
                "description": "scale for estimating a mask over the text region",
                "format": "float",
                "type": "number"
            },
            "gray": {
                "default": false,
                "description": "force grayscale processing even if image seems binary",
                "type": "boolean"
            },
            "hi": {
                "default": 90,
                "description": "percentile for white estimation",
                "format": "float",
                "type": "number"
            },
            "lo": {
                "default": 5,
                "description": "percentile for black estimation",
                "format": "float",
                "type": "number"
            },
            "nocheck": {
                "default": false,
                "description": "disable error checking on inputs",
                "type": "boolean"
            },
            "operation_level": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "perc": {
                "default": 80,
                "description": "percentage for filters",
                "format": "float",
                "type": "number"
            },
            "range": {
                "default": 20,
                "description": "range for filters",
                "format": "integer",
                "type": "number"
            },
            "raw_copy": {
                "default": false,
                "description": "also copy the raw image",
                "type": "boolean"
            },
            "show": {
                "default": false,
                "description": "display final results",
                "type": "boolean"
            },
            "threshold": {
                "default": 0.5,
                "description": "threshold, determines lightness",
                "format": "float",
                "type": "number"
            },
            "zoom": {
                "default": 0.5,
                "description": "zoom for page background estimation, smaller=faster",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-anybaseocr-block-segmentation": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segments and classifies document segments in a single page and outputs the the region polygons and classes.",
        "executable": "ocrd-anybaseocr-block-segmentation",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-BLOCK-SEGMENT"
        ],
        "parameters": {
            "DETECTION_MIN_CONFIDENCE": {
                "default": 0.9,
                "description": "Confidence value for a model to detect bounding box",
                "type": "number"
            },
            "block_segmentation_model": {
                "default": "mrcnn/",
                "description": "Path to block segmentation Model",
                "required": false,
                "type": "string"
            },
            "block_segmentation_weights": {
                "default": "models/block_segmentation_weights.h5",
                "description": "Path to model weights",
                "required": false,
                "type": "string"
            },
            "operation_level": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page"
                ],
                "type": "string"
            },
            "overwrite": {
                "default": false,
                "description": "check whether to overwrite existing text lines",
                "type": "boolean"
            },
            "th": {
                "default": 15,
                "description": "num of pixels to include in the area region",
                "type": "integer"
            }
        },
        "steps": [
            "layout/segmentation/text-image"
        ]
    },
    "ocrd-anybaseocr-crop": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Crops the input image to the page frame using non-linear processing and outputs a border polygon",
        "executable": "ocrd-anybaseocr-crop",
        "input_file_grp": [
            "OCR-D-IMG-DESKEW"
        ],
        "output_file_grp": [
            "OCR-D-IMG-CROP"
        ],
        "parameters": {
            "colSeparator": {
                "default": 0.04,
                "description": "consider space between column. 25% of width",
                "format": "float",
                "type": "number"
            },
            "maxRularArea": {
                "default": 0.3,
                "description": "Consider maximum rular area",
                "format": "float",
                "type": "number"
            },
            "minArea": {
                "default": 0.05,
                "description": "rular position in below",
                "format": "float",
                "type": "number"
            },
            "minRularArea": {
                "default": 0.01,
                "description": "Consider minimum rular area",
                "format": "float",
                "type": "number"
            },
            "padding": {
                "default": 10,
                "description": "extend resulting border by this many px in each direction",
                "format": "integer",
                "type": "number"
            },
            "positionBelow": {
                "default": 0.75,
                "description": "rular position in below",
                "format": "float",
                "type": "number"
            },
            "positionLeft": {
                "default": 0.4,
                "description": "rular position in left",
                "format": "float",
                "type": "number"
            },
            "positionRight": {
                "default": 0.6,
                "description": "rular position in right",
                "format": "float",
                "type": "number"
            },
            "rularRatioMax": {
                "default": 10.0,
                "description": "rular position in below",
                "format": "float",
                "type": "number"
            },
            "rularRatioMin": {
                "default": 3.0,
                "description": "rular position in below",
                "format": "float",
                "type": "number"
            },
            "rularWidth": {
                "default": 0.95,
                "description": "maximum rular width",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/cropping"
        ]
    },
    "ocrd-anybaseocr-deskew": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Deskews images with the algorithm from ocropy and outputs a deskew angle.",
        "executable": "ocrd-anybaseocr-deskew",
        "input_file_grp": [
            "OCR-D-IMG-BIN"
        ],
        "output_file_grp": [
            "OCR-D-IMG-DESKEW"
        ],
        "parameters": {
            "bignore": {
                "default": 0.1,
                "description": "ignore this much of the border for threshold estimation",
                "format": "float",
                "type": "number"
            },
            "debug": {
                "default": 0,
                "description": "display intermediate results",
                "format": "integer",
                "type": "number"
            },
            "escale": {
                "default": 1.0,
                "description": "scale for estimating a mask over the text region",
                "format": "float",
                "type": "number"
            },
            "hi": {
                "default": 90,
                "description": "percentile for white estimation",
                "format": "integer",
                "type": "number"
            },
            "lo": {
                "default": 5,
                "description": "percentile for black estimation",
                "format": "integer",
                "type": "number"
            },
            "maxskew": {
                "default": 1.0,
                "description": "skew angle estimation parameters (degrees)",
                "format": "float",
                "type": "number"
            },
            "operation_level": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "parallel": {
                "default": 0,
                "description": "???",
                "format": "integer",
                "type": "number"
            },
            "skewsteps": {
                "default": 8,
                "description": "steps for skew angle estimation (per degree)",
                "format": "integer",
                "type": "number"
            },
            "threshold": {
                "default": 0.5,
                "description": "threshold, determines lightness",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/deskewing"
        ]
    },
    "ocrd-anybaseocr-dewarp": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Dewarps the input image with anyBaseOCR and outputs it as an AlternativeImage",
        "executable": "ocrd-anybaseocr-dewarp",
        "input_file_grp": [
            "OCR-D-IMG-CROP"
        ],
        "output_file_grp": [
            "OCR-D-IMG-DEWARP"
        ],
        "parameters": {
            "gpu_id": {
                "default": -1,
                "description": "device ID of CUDA GPU to use. Set -1 to use CPU only.",
                "format": "integer",
                "type": "number"
            },
            "imgresize": {
                "default": "resize_and_crop",
                "description": "run on original size image",
                "type": "string"
            },
            "model_path": {
                "cacheable": true,
                "content-type": "application/vnd.pytorch",
                "default": "models/latest_net_G.pth",
                "description": "Path to the trained pix2pixHD model (Download from https://cloud.dfki.de/owncloud/index.php/s/3zKza5sRfQB3ygy/download)",
                "type": "string"
            },
            "operation_level": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on (should match what model was trained on!)",
                "enum": [
                    "page",
                    "region"
                ],
                "type": "string"
            },
            "resizeHeight": {
                "default": 1024,
                "description": "resized image height",
                "format": "integer",
                "type": "number"
            },
            "resizeWidth": {
                "default": 1024,
                "description": "resized image width",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/dewarping"
        ]
    },
    "ocrd-anybaseocr-layout-analysis": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Generates a table-of-content like document structure of the whole document.",
        "executable": "ocrd-anybaseocr-layout-analysis",
        "input_file_grp": [
            "OCR-D-IMG-CROP"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LAYOUT"
        ],
        "parameters": {
            "batch_size": {
                "default": 4,
                "description": "Batch size for generating test images",
                "format": "integer",
                "type": "number"
            },
            "class_mapping_path": {
                "default": "models/mapping_densenet.pickle",
                "description": "Path to Layout Structure Classes",
                "required": false,
                "type": "string"
            },
            "model_path": {
                "default": "models/structure_analysis.h5",
                "description": "Path to Layout Structure Classification Model",
                "required": false,
                "type": "string"
            }
        },
        "steps": [
            "layout/segmentation/text-image"
        ]
    },
    "ocrd-anybaseocr-textline": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Finds region polygons for each text line in the input image.",
        "executable": "ocrd-anybaseocr-textline",
        "input_file_grp": [
            "OCR-D-SEG-TISEG"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE-ANY"
        ],
        "parameters": {
            "blackseps": {
                "default": false,
                "description": "also check for black column separators",
                "type": "boolean"
            },
            "csminaspect": {
                "default": 1.1,
                "description": "minimum aspect ratio for column separators",
                "format": "float",
                "type": "number"
            },
            "csminheight": {
                "default": 6.5,
                "description": "minimum column height (units=scale)",
                "format": "float",
                "type": "number"
            },
            "expand": {
                "default": 3,
                "description": "expand mask for grayscale extraction",
                "format": "integer",
                "type": "number"
            },
            "hscale": {
                "default": 1.0,
                "description": "non-standard scaling of horizontal parameters",
                "format": "float",
                "type": "number"
            },
            "libpath": {
                "default": ".",
                "description": "Library Path for C Executables",
                "type": "string"
            },
            "maxcolseps": {
                "default": 2,
                "description": "maximum # whitespace column separators",
                "format": "integer",
                "type": "number"
            },
            "maxlines": {
                "default": 300,
                "description": "non-standard scaling of horizontal parameters",
                "format": "float",
                "type": "number"
            },
            "maxseps": {
                "default": 2,
                "description": "maximum black column separators",
                "format": "integer",
                "type": "number"
            },
            "minscale": {
                "default": 12.0,
                "description": "minimum scale permitted",
                "format": "float",
                "type": "number"
            },
            "noise": {
                "default": 8,
                "description": "noise threshold for removing small components from lines",
                "format": "integer",
                "type": "number"
            },
            "operation_level": {
                "default": "region",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region"
                ],
                "type": "string"
            },
            "overwrite": {
                "default": false,
                "description": "check whether to overwrite existing text lines",
                "type": "boolean"
            },
            "pad": {
                "default": 3,
                "description": "padding for extracted lines",
                "format": "integer",
                "type": "number"
            },
            "parallel": {
                "default": 0,
                "description": "number of CPUs to use",
                "format": "integer",
                "type": "number"
            },
            "scale": {
                "default": 0.0,
                "description": "the basic scale of the document (roughly, xheight) 0=automatic",
                "format": "float",
                "type": "number"
            },
            "sepwiden": {
                "default": 10,
                "description": "widen black separators (to account for warping)",
                "format": "integer",
                "type": "number"
            },
            "threshold": {
                "default": 0.2,
                "description": "baseline threshold",
                "format": "float",
                "type": "number"
            },
            "usegauss": {
                "default": false,
                "description": "use gaussian instead of uniform",
                "type": "boolean"
            },
            "vscale": {
                "default": 1.7,
                "description": "non-standard scaling of vertical parameters",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "layout/segmentation/line"
        ]
    },
    "ocrd-anybaseocr-tiseg": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Separates the text and non-text elements with anyBaseOCR. Outputs clipped versions of the input image as AlternativeImage containing either only text or non-text elements.",
        "executable": "ocrd-anybaseocr-tiseg",
        "input_file_grp": [
            "OCR-D-IMG-CROP"
        ],
        "output_file_grp": [
            "OCR-D-SEG-TISEG"
        ],
        "parameters": {
            "classes": {
                "default": 3,
                "description": "number of classes",
                "type": "integer"
            },
            "height": {
                "default": 800,
                "description": "input image width",
                "type": "integer"
            },
            "operation_level": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "seg_weights": {
                "default": "models/seg_model.hdf5",
                "description": "path to weights file",
                "required": false,
                "type": "string"
            },
            "use_deeplr": {
                "default": true,
                "description": "use deep learning model",
                "type": "boolean"
            },
            "width": {
                "default": 1024,
                "description": "input image height",
                "type": "integer"
            }
        },
        "steps": [
            "layout/segmentation/text-image"
        ]
    },
    "ocrd-calamari-recognize": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Recognize lines with Calamari",
        "executable": "ocrd-calamari-recognize",
        "input_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-OCR-CALAMARI"
        ],
        "parameters": {
            "checkpoint": {
                "cacheable": true,
                "description": "The calamari model files (*.ckpt.json)",
                "format": "file",
                "type": "string"
            },
            "glyph_conf_cutoff": {
                "default": 0.001,
                "description": "Only include glyph alternatives with confidences above this threshold",
                "format": "float",
                "type": "number"
            },
            "textequiv_level": {
                "default": "line",
                "description": "Deepest PAGE XML hierarchy level to include TextEquiv results for",
                "enum": [
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "voter": {
                "default": "confidence_voter_default_ctc",
                "description": "The voting algorithm to use",
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-cis-align": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Align multiple OCRs and/or GTs",
        "executable": "ocrd-cis-align",
        "input_file_grp": [
            "OCR-D-OCR-1",
            "OCR-D-OCR-2",
            "OCR-D-OCR-N"
        ],
        "output_file_grp": [
            "OCR-D-ALIGNED"
        ],
        "steps": [
            "recognition/post-correction"
        ]
    },
    "ocrd-cis-ocropy-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Binarize (and optionally deskew/despeckle) pages / regions / lines with ocropy",
        "executable": "ocrd-cis-ocropy-binarize",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-BIN",
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative",
                "format": "float",
                "type": "number"
            },
            "grayscale": {
                "default": false,
                "description": "for the 'ocropy' method, produce grayscale-normalized instead of thresholded image",
                "type": "boolean"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level granularity to annotate images for",
                "enum": [
                    "page",
                    "table",
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "maxskew": {
                "default": 0.0,
                "description": "modulus of maximum skewing angle (in degrees) to detect (larger will be slower, 0 will deactivate deskewing)",
                "format": "float",
                "type": "number"
            },
            "method": {
                "default": "ocropy",
                "description": "binarization method to use (only 'ocropy' will include deskewing and denoising)",
                "enum": [
                    "none",
                    "global",
                    "otsu",
                    "gauss-otsu",
                    "ocropy"
                ],
                "type": "string"
            },
            "noise_maxsize": {
                "default": 0,
                "description": "maximum pixel number for connected components to regard as noise (0 will deactivate denoising)",
                "format": "int",
                "type": "number"
            },
            "threshold": {
                "default": 0.5,
                "description": "for the 'ocropy' and ' global' method, black/white threshold to apply on the whitelevel normalized image (the larger the more/heavier foreground)",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization",
            "preprocessing/optimization/grayscale_normalization",
            "preprocessing/optimization/deskewing"
        ]
    },
    "ocrd-cis-ocropy-clip": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Clip text regions / lines at intersections with neighbours",
        "executable": "ocrd-cis-ocropy-clip",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "region",
                "description": "PAGE XML hierarchy level granularity to annotate images for",
                "enum": [
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "min_fraction": {
                "default": 0.7,
                "description": "share of foreground pixels that must be retained by the largest label",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "layout/segmentation/region",
            "layout/segmentation/line"
        ]
    },
    "ocrd-cis-ocropy-denoise": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Despeckle pages / regions / lines with ocropy",
        "executable": "ocrd-cis-ocropy-denoise",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-DESPECK",
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level granularity to annotate images for",
                "enum": [
                    "page",
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "noise_maxsize": {
                "default": 3.0,
                "description": "maximum size in points (pt) for connected components to regard as noise (0 will deactivate denoising)",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/despeckling"
        ]
    },
    "ocrd-cis-ocropy-deskew": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Deskew regions with ocropy (by annotating orientation angle and adding AlternativeImage)",
        "executable": "ocrd-cis-ocropy-deskew",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "level-of-operation": {
                "default": "region",
                "description": "PAGE XML hierarchy level granularity to annotate images for",
                "enum": [
                    "page",
                    "table",
                    "region"
                ],
                "type": "string"
            },
            "maxskew": {
                "default": 5.0,
                "description": "modulus of maximum skewing angle to detect (larger will be slower, 0 will deactivate deskewing)",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/deskewing"
        ]
    },
    "ocrd-cis-ocropy-dewarp": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Dewarp line images with ocropy",
        "executable": "ocrd-cis-ocropy-dewarp",
        "input_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative",
                "format": "float",
                "type": "number"
            },
            "max_neighbour": {
                "default": 0.05,
                "description": "maximum rate of foreground pixels intruding from neighbouring lines (line will not be processed above that)",
                "format": "float",
                "type": "number"
            },
            "range": {
                "default": 4.0,
                "description": "maximum vertical disposition or maximum margin (will be multiplied by mean centerline deltas to yield pixels); also the mean vertical padding",
                "format": "float",
                "type": "number"
            },
            "smoothness": {
                "default": 1.0,
                "description": "kernel size (relative to image height) of horizontal blur applied to foreground to find the center line; the smaller the more dynamic (0.1 would be a better default)",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/dewarping"
        ]
    },
    "ocrd-cis-ocropy-rec": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Recognize text snippets",
        "executable": "ocrd-cis-ocropy-rec",
        "input_file_grp": [
            "OCR-D-GT-SEG-BLOCK",
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "model": {
                "description": "ocropy model to apply (e.g. fraktur.pyrnn)",
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-cis-ocropy-recognize": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Recognize text in (binarized+deskewed+dewarped) lines with ocropy",
        "executable": "ocrd-cis-ocropy-recognize",
        "input_file_grp": [
            "OCR-D-SEG-LINE",
            "OCR-D-SEG-WORD",
            "OCR-D-SEG-GLYPH"
        ],
        "output_file_grp": [
            "OCR-D-OCR-OCRO"
        ],
        "parameters": {
            "model": {
                "description": "ocropy model to apply (e.g. fraktur.pyrnn)",
                "type": "string"
            },
            "textequiv_level": {
                "default": "line",
                "description": "PAGE XML hierarchy level granularity to add the TextEquiv results to",
                "enum": [
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-cis-ocropy-resegment": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Resegment lines with ocropy (by shrinking annotated polygons)",
        "executable": "ocrd-cis-ocropy-resegment",
        "input_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative",
                "format": "float",
                "type": "number"
            },
            "extend_margins": {
                "default": 3,
                "description": "number of pixels to extend the input polygons horizontally and vertically before intersecting",
                "format": "integer",
                "type": "number"
            },
            "min_fraction": {
                "default": 0.8,
                "description": "share of foreground pixels that must be retained by the largest label",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "layout/segmentation/line"
        ]
    },
    "ocrd-cis-ocropy-segment": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment pages into regions and lines, tables into cells and lines, or regions into lines with ocropy",
        "executable": "ocrd-cis-ocropy-segment",
        "input_file_grp": [
            "OCR-D-GT-SEG-BLOCK",
            "OCR-D-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "csminheight": {
                "default": 4,
                "description": "(when operating on the page/table level) minimum height of white/background or black/foreground column separators in multiples of scale/capheight, counted piece-wise",
                "format": "integer",
                "type": "number"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative; when disabled and no meta-data is found, 300 is assumed",
                "format": "float",
                "type": "number"
            },
            "gap_height": {
                "default": 0.01,
                "description": "(when operating on the page/table level) largest minimum pixel average in the horizontal or vertical profiles (across the binarized image) to still be regarded as a gap during recursive X-Y cut from lines to regions; needs to be larger when more foreground noise is present, reduce to avoid mistaking text for noise",
                "format": "float",
                "type": "number"
            },
            "gap_width": {
                "default": 1.5,
                "description": "(when operating on the page/table level) smallest width in multiples of scale/capheight of a valley in the horizontal or vertical profiles (across the binarized image) to still be regarded as a gap during recursive X-Y cut from lines to regions; needs to be smaller when more foreground noise is present, increase to avoid mistaking inter-line as paragraph gaps and inter-word as inter-column gaps",
                "format": "float",
                "type": "number"
            },
            "hlminwidth": {
                "default": 10,
                "description": "(when operating on the page/table level) minimum width of black/foreground horizontal separators in multiples of scale/capheight, counted piece-wise",
                "format": "integer",
                "type": "number"
            },
            "level-of-operation": {
                "default": "region",
                "description": "PAGE XML hierarchy level to read images from and add elements to",
                "enum": [
                    "page",
                    "table",
                    "region"
                ],
                "type": "string"
            },
            "maxcolseps": {
                "default": 20,
                "description": "(when operating on the page/table level) maximum number of white/background column separators to detect, counted piece-wise",
                "format": "integer",
                "type": "number"
            },
            "maximages": {
                "default": 10,
                "description": "(when operating on the page level) maximum number of black/foreground very large components to detect (and suppress), counted piece-wise",
                "format": "integer",
                "type": "number"
            },
            "maxseps": {
                "default": 20,
                "description": "(when operating on the page/table level) number of black/foreground column separators to detect (and suppress), counted piece-wise",
                "format": "integer",
                "type": "number"
            },
            "overwrite_lines": {
                "default": true,
                "description": "(when operating on the region level) remove any existing TextLine elements; otherwise append",
                "type": "boolean"
            },
            "overwrite_order": {
                "default": true,
                "description": "(when operating on the page/table level) remove any references for existing TextRegion elements within the top (page/table) reading order; otherwise append",
                "type": "boolean"
            },
            "overwrite_regions": {
                "default": true,
                "description": "(when operating on the page/table level) remove any existing TextRegion elements; otherwise append",
                "type": "boolean"
            },
            "overwrite_separators": {
                "default": true,
                "description": "(when operating on the page/table level) remove any existing SeparatorRegion elements; otherwise append",
                "type": "boolean"
            },
            "spread": {
                "default": 2.4,
                "description": "distance in points (pt) from the foreground to project text line (or text region) labels into the background for polygonal contours; if zero, project half a scale/capheight",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "layout/segmentation/region",
            "layout/segmentation/line"
        ]
    },
    "ocrd-cis-ocropy-train": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "train model with ground truth from mets data",
        "executable": "ocrd-cis-ocropy-train",
        "input_file_grp": [
            "OCR-D-GT-SEG-BLOCK",
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "model": {
                "description": "load model or crate new one (e.g. fraktur.pyrnn)",
                "type": "string"
            },
            "ntrain": {
                "default": 1000000,
                "description": "lines to train before stopping",
                "format": "integer",
                "type": "number"
            },
            "outputpath": {
                "description": "(existing) path for the trained model",
                "type": "string"
            },
            "textequiv_level": {
                "default": "line",
                "description": "PAGE XML hierarchy level granularity",
                "enum": [
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-cis-postcorrect": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Post correct OCR results",
        "executable": "ocrd-cis-postcorrect",
        "input_file_grp": [
            "OCR-D-LINE-ALIGNED"
        ],
        "output_file_grp": [
            "OCR-D-POST-CORRECTED"
        ],
        "parameters": {
            "maxCandidates": {
                "default": 10,
                "description": "Maximum number of considered correction candidates per suspicious token",
                "format": "integer",
                "type": "number"
            },
            "model": {
                "description": "Path to the post correction model file",
                "required": true,
                "type": "string"
            },
            "nOCR": {
                "default": 1,
                "description": "Number of parallel OCR's to use for the post correction",
                "format": "integer",
                "type": "number"
            },
            "profilerConfig": {
                "description": "Path to the profiler's language config file",
                "required": true,
                "type": "string"
            },
            "profilerPath": {
                "description": "Path to the profiler executable",
                "required": true,
                "type": "string"
            },
            "runLE": {
                "default": false,
                "description": "Do run the lexicon extension step for the post correction",
                "type": "boolean"
            }
        },
        "steps": [
            "recognition/post-correction"
        ]
    },
    "ocrd-cor-asv-ann-evaluate": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Align different textline annotations and compute distance",
        "executable": "ocrd-cor-asv-ann-evaluate",
        "input_file_grp": [
            "OCR-D-GT-SEG-LINE",
            "OCR-D-OCR-TESS",
            "OCR-D-OCR-KRAK",
            "OCR-D-OCR-OCRO",
            "OCR-D-OCR-CALA",
            "OCR-D-OCR-ANY",
            "OCR-D-COR-ASV"
        ],
        "output_file_grp": [
            "OCR-D-EVAL-CER"
        ],
        "parameters": {
            "confusion": {
                "default": 0,
                "description": "Count edits and show that number of most frequent confusions (non-identity) in the end.",
                "format": "integer",
                "minimum": 0,
                "type": "number"
            },
            "metric": {
                "default": "Levenshtein",
                "description": "Distance metric to calculate and aggregate: historic_latin for GT level 1, NFKC for GT level 2 (except \u017f-s), Levenshtein for GT level 3",
                "enum": [
                    "Levenshtein",
                    "NFC",
                    "NFKC",
                    "historic_latin"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/evaluation"
        ]
    },
    "ocrd-cor-asv-ann-process": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Improve text annotation by character-level encoder-attention-decoder ANN model",
        "executable": "ocrd-cor-asv-ann-process",
        "input_file_grp": [
            "OCR-D-OCR-TESS",
            "OCR-D-OCR-KRAK",
            "OCR-D-OCR-OCRO",
            "OCR-D-OCR-CALA",
            "OCR-D-OCR-ANY"
        ],
        "output_file_grp": [
            "OCR-D-COR-ASV"
        ],
        "parameters": {
            "fast_mode": {
                "default": false,
                "description": "decode greedy instead of beamed, with batches of parallel lines instead of parallel alternatives; also disables rejection and beam parameters; enable if performance is far more important than quality",
                "type": "boolean"
            },
            "fixed_beam_width": {
                "default": 15,
                "description": "maximum number of candidates allowed to enter the beam in each hypothesis; controls the quality/performance trade-off",
                "format": "integer",
                "type": "number"
            },
            "model_file": {
                "cacheable": true,
                "content-type": "application/x-hdf;subtype=bag",
                "description": "path of h5py weight/config file for model trained with cor-asv-ann-train",
                "format": "uri",
                "required": true,
                "type": "string"
            },
            "rejection_threshold": {
                "default": 0.5,
                "description": "minimum probability of the candidate corresponding to the input character in each hypothesis during beam search, helps balance precision/recall trade-off; set to 0 to disable rejection (max recall) or 1 to disable correction (max precision)",
                "format": "float",
                "type": "number"
            },
            "relative_beam_width": {
                "default": 0.2,
                "description": "minimum fraction of the best candidate's probability required to enter the beam in each hypothesis; controls the quality/performance trade-off",
                "format": "float",
                "type": "number"
            },
            "textequiv_level": {
                "default": "glyph",
                "description": "PAGE XML hierarchy level to read/write TextEquiv input/output on",
                "enum": [
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/post-correction"
        ]
    },
    "ocrd-cor-asv-fst-process": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Improve text annotation by FST error and lexicon model with character-level LSTM language model",
        "executable": "ocrd-cor-asv-fst-process",
        "input_file_grp": [
            "OCR-D-OCR-TESS",
            "OCR-D-OCR-KRAK",
            "OCR-D-OCR-OCRO",
            "OCR-D-OCR-CALA",
            "OCR-D-OCR-ANY"
        ],
        "output_file_grp": [
            "OCR-D-COR-ASV"
        ],
        "parameters": {
            "beam_width": {
                "default": 100,
                "description": "maximum number of best partial paths to consider during beam search in language modelling",
                "format": "integer",
                "type": "number"
            },
            "errorfst_file": {
                "cacheable": true,
                "content-type": "application/vnd.openfst",
                "description": "path of FST file for error model",
                "format": "uri",
                "required": true,
                "type": "string"
            },
            "keraslm_file": {
                "cacheable": true,
                "content-type": "application/x-hdf;subtype=bag",
                "description": "path of h5py weight/config file for language model trained with keraslm",
                "format": "uri",
                "required": true,
                "type": "string"
            },
            "lexiconfst_file": {
                "cacheable": true,
                "content-type": "application/vnd.openfst",
                "description": "path of FST file for lexicon model",
                "format": "uri",
                "required": true,
                "type": "string"
            },
            "lm_weight": {
                "default": 0.5,
                "description": "share of the LM scores over the FST output confidences",
                "format": "float",
                "type": "number"
            },
            "pruning_weight": {
                "default": 5.0,
                "description": "transition weight for pruning the hypotheses in each word window FST",
                "format": "float",
                "type": "number"
            },
            "rejection_weight": {
                "default": 1.5,
                "description": "transition weight (per character) for unchanged input in each word window FST",
                "format": "float",
                "type": "number"
            },
            "textequiv_level": {
                "default": "word",
                "description": "PAGE XML hierarchy level to read TextEquiv input on (output will always be word level)",
                "enum": [
                    "word"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/post-correction"
        ]
    },
    "ocrd-dinglehopper": {
        "categories": [
            "Quality assurance"
        ],
        "description": "Evaluate OCR text against ground truth with dinglehopper",
        "executable": "ocrd-dinglehopper",
        "input_file_grp": [
            "OCR-D-GT-PAGE",
            "OCR-D-OCR"
        ],
        "output_file_grp": [
            "OCR-D-OCR-EVAL"
        ],
        "parameters": {
            "metrics": {
                "default": true,
                "description": "Enable/disable metrics and green/red",
                "type": "boolean"
            },
            "textequiv_level": {
                "default": "region",
                "description": "PAGE XML hierarchy level to extract the text from",
                "enum": [
                    "region",
                    "line"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-fileformat-transform": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Convert between OCR file formats",
        "executable": "ocrd-fileformat-transform",
        "input_file_grp": [
            "OCR-D-OCR-PAGE",
            "OCR-D-OCR-ALTO",
            "OCR-D-OCR-HOCR"
        ],
        "output_file_grp": [
            "OCR-D-OCR-PAGE",
            "OCR-D-OCR-ALTO",
            "OCR-D-OCR-HOCR"
        ],
        "parameters": {
            "ext": {
                "default": "",
                "description": "Output extension. Set to empty string to derive extension from the media type.",
                "type": "string"
            },
            "from-to": {
                "default": "page alto",
                "description": "Transformation scenario, see ocr-fileformat -L",
                "enum": [
                    "alto2.0 alto3.0",
                    "alto2.0 alto3.1",
                    "alto2.0 hocr",
                    "alto2.1 alto3.0",
                    "alto2.1 alto3.1",
                    "alto2.1 hocr",
                    "alto page",
                    "alto text",
                    "gcv hocr",
                    "hocr alto2.0",
                    "hocr alto2.1",
                    "hocr text",
                    "page alto",
                    "page hocr",
                    "page text"
                ],
                "type": "string"
            },
            "script-args": {
                "default": "",
                "description": "Arguments to Saxon (for XSLT transformations) or to transformation script",
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization"
        ]
    },
    "ocrd-im6convert": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Convert and transform images",
        "executable": "ocrd-im6convert",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-IMG"
        ],
        "parameters": {
            "input-options": {
                "default": "",
                "description": "e.g. -density 600x600 -wavelet-denoise 1%x0.1",
                "type": "string"
            },
            "output-format": {
                "description": "Desired media type of output",
                "enum": [
                    "image/tiff",
                    "image/jp2",
                    "image/png"
                ],
                "required": true,
                "type": "string"
            },
            "output-options": {
                "default": "",
                "description": "e.g. -resample 300x300 -alpha deactivate -normalize -despeckle -noise 2 -negate -morphology close diamond",
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization"
        ]
    },
    "ocrd-keraslm-rate": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Rate elements of the text with a character-level LSTM language model in Keras",
        "executable": "ocrd-keraslm-rate",
        "input_file_grp": [
            "OCR-D-OCR-TESS",
            "OCR-D-OCR-KRAK",
            "OCR-D-OCR-OCRO",
            "OCR-D-OCR-CALA",
            "OCR-D-OCR-ANY",
            "OCR-D-COR-CIS",
            "OCR-D-COR-ASV"
        ],
        "output_file_grp": [
            "OCR-D-COR-LM"
        ],
        "parameters": {
            "alternative_decoding": {
                "default": true,
                "description": "whether to process all TextEquiv alternatives, finding the best path via beam search, and delete each non-best alternative",
                "type": "boolean"
            },
            "beam_width": {
                "default": 10,
                "description": "maximum number of best partial paths to consider during search with alternative_decoding",
                "format": "integer",
                "type": "number"
            },
            "lm_weight": {
                "default": 0.5,
                "description": "share of the LM scores over the input confidences",
                "format": "float",
                "type": "number"
            },
            "model_file": {
                "cacheable": true,
                "content-type": "application/x-hdf;subtype=bag",
                "description": "path of h5py weight/config file for model trained with keraslm",
                "format": "uri",
                "required": true,
                "type": "string"
            },
            "textequiv_level": {
                "default": "glyph",
                "description": "PAGE XML hierarchy level to evaluate TextEquiv sequences on",
                "enum": [
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-kraken-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Binarize images with kraken",
        "executable": "ocrd-kraken-binarize",
        "input_file_grp": "OCR-D-IMG",
        "output_file_grp": "OCR-D-IMG-BIN",
        "parameters": {
            "level-of-operation": {
                "default": "page",
                "enum": [
                    "page",
                    "block",
                    "line"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-kraken-ocr": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "OCR with kraken",
        "executable": "ocrd-kraken-ocr",
        "parameters": {
            "lines-json": {
                "description": "URL to line segmentation in JSON",
                "format": "url",
                "required": "true",
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-kraken-segment": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Block segmentation with kraken",
        "executable": "ocrd-kraken-segment",
        "parameters": {
            "black_colseps": {
                "default": false,
                "type": "boolean"
            },
            "level-of-operation": {
                "default": "page",
                "enum": [
                    "page",
                    "block",
                    "line"
                ],
                "type": "string"
            },
            "maxcolseps": {
                "default": 2,
                "format": "integer",
                "type": "number"
            },
            "scale": {
                "default": 0,
                "format": "float",
                "type": "number"
            },
            "script_detect": {
                "default": false,
                "description": "Enable script detection on segmenter output",
                "type": "boolean"
            },
            "text_direction": {
                "default": "horizontal-lr",
                "description": "Sets principal text direction",
                "enum": [
                    "horizontal-lr",
                    "horizontal-rl",
                    "vertical-lr",
                    "vertical-rl"
                ],
                "type": "string"
            },
            "white_colseps": {
                "default": false,
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-ocropy-segment": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Segment page",
        "executable": "ocrd-ocropy-segment",
        "input_file_grp": [
            "OCR-D-IMG-BIN"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "csminaspect": {
                "default": 1.1,
                "description": "has an effect",
                "type": "number"
            },
            "csminheight": {
                "default": 10,
                "description": "has an effect",
                "type": "number"
            },
            "expand": {
                "default": 3,
                "description": "has an effect",
                "type": "number"
            },
            "hscale": {
                "default": 1.0,
                "description": "has an effect",
                "type": "number"
            },
            "maxcolseps": {
                "default": 3,
                "description": "has an effect",
                "type": "number"
            },
            "maxseps": {
                "default": 0,
                "description": "has an effect",
                "type": "number"
            },
            "noise": {
                "default": 8,
                "description": "has an effect",
                "type": "number"
            },
            "pad": {
                "default": 3,
                "description": "has an effect",
                "type": "number"
            },
            "scale": {
                "default": 0.0,
                "description": "has an effect",
                "type": "number"
            },
            "sepwiden": {
                "default": 10,
                "description": "has an effect",
                "type": "number"
            },
            "threshold": {
                "default": 0.2,
                "description": "has an effect",
                "type": "number"
            },
            "usegauss": {
                "default": false,
                "description": "has an effect",
                "type": "boolean"
            },
            "vscale": {
                "default": 1.0,
                "description": "has an effect",
                "type": "number"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-olena-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "popular binarization algorithms implemented by Olena/SCRIBO, wrapped for OCR-D (on page level only)",
        "executable": "ocrd-olena-binarize",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE",
            "OCR-D-SEG-WORD",
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE",
            "OCR-D-SEG-WORD"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero",
                "format": "float",
                "type": "number"
            },
            "impl": {
                "default": "sauvola-ms-split",
                "description": "The name of the actual binarization algorithm",
                "enum": [
                    "sauvola",
                    "sauvola-ms",
                    "sauvola-ms-fg",
                    "sauvola-ms-split",
                    "kim",
                    "wolf",
                    "niblack",
                    "singh",
                    "otsu"
                ],
                "type": "string"
            },
            "k": {
                "default": 0.34,
                "description": "Sauvola's formulae parameter (foreground weight decreases with k); for Multiscale, multiplied to yield default 0.2/0.3/0.5; for Singh, multiplied to yield default 0.06; for Niblack, multiplied to yield default -0.2; for Wolf/Kim, used directly; for Otsu, does not apply",
                "format": "float",
                "type": "number"
            },
            "win-size": {
                "default": 0,
                "description": "The (odd) window size in pixels; when zero (default), set to DPI (or 301); for Otsu, does not apply",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-pagetopdf": {
        "categories": [
            "Long-term preservation"
        ],
        "description": "Convert text and layout annotations to PDF format (overlaying original image with text layer and polygon outlines)",
        "executable": "ocrd-pagetopdf",
        "input_file_grp": [
            "OCR-D-OCR-PAGE"
        ],
        "output_file_grp": [
            "OCR-D-OCR-PDF"
        ],
        "parameters": {
            "ext": {
                "default": ".pdf",
                "description": "Output filename extension",
                "type": "string"
            },
            "font": {
                "content-type": "application/x-font-ttf",
                "default": "",
                "description": "Font file to be used in PDF file. If unset, AletheiaSans.ttf is used. (Make sure to pick a font which covers all glyphs!)",
                "format": "uri",
                "type": "string"
            },
            "multipage": {
                "default": "",
                "description": "Merge all PDFs into one mulitpage file. The value is used as filename for the pdf.",
                "type": "string"
            },
            "negative2zero": {
                "default": false,
                "description": "Set all negative box values to 0",
                "type": "boolean"
            },
            "outlines": {
                "default": "",
                "description": "What segment hierarchy to draw coordinate outlines for. If unset, no outlines are drawn.",
                "enum": [
                    "",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "pagelabel": {
                "default": "pageId",
                "description": "Parameter for 'multipage': Set the page information, which will be used as pagelabel. Default is 'pageId', e.g. the option 'pagenumber' will create numbered pagelabel consecutively",
                "enum": [
                    "pagenumber",
                    "pageId",
                    "basename",
                    "basename_without_extension",
                    "local_filename",
                    "ID",
                    "url"
                ],
                "type": "string"
            },
            "script-args": {
                "default": "",
                "description": "Extra arguments to PageToPdf (see https://github.com/PRImA-Research-Lab/prima-page-to-pdf)",
                "type": "string"
            },
            "textequiv_level": {
                "default": "",
                "description": "What segment hierarchy level to render text output from. If unset, no text is rendered.",
                "enum": [
                    "",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            }
        },
        "steps": [
            "postprocessing/format-conversion"
        ]
    },
    "ocrd-pixelclassifier-segmentation": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment page into regions using a pixel classifier based on a Fully Convolutional Network (FCN)",
        "executable": "ocrd-pc-segmentation",
        "input_file_grp": [
            "OCR-D-IMG-BIN"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "gpu_allow_growth": {
                "default": false,
                "description": "required for GPU use with some graphic cards (set to true, if you get CUDNN_INTERNAL_ERROR)",
                "type": "boolean"
            },
            "model": {
                "default": "__DEFAULT__",
                "description": "trained model for pixel classifier",
                "type": "string"
            },
            "overwrite_regions": {
                "default": true,
                "description": "remove existing layout and text annotation below the Page level",
                "type": "boolean"
            },
            "resize_height": {
                "default": 300,
                "description": "scale down pixelclassifier output to this height for postprocessing (performance/quality tradeoff). Independent of training.",
                "type": "integer"
            },
            "xheight": {
                "default": 8,
                "description": "height of character x in pixels used during training",
                "type": "integer"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-preprocess-image": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Convert or enhance images",
        "executable": "ocrd-preprocess-image",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "command": {
                "description": "shell command to operate on image files, with @INFILE as place-holder for the input file path, and @OUTFILE as place-holder for the output file path",
                "required": true,
                "type": "string"
            },
            "input_feature_filter": {
                "default": "",
                "description": "comma-separated list of forbidden image features (e.g. binarized,despeckled)",
                "type": "string"
            },
            "input_feature_selector": {
                "default": "",
                "description": "comma-separated list of required image features (e.g. binarized,despeckled)",
                "type": "string"
            },
            "input_mimetype": {
                "default": "image/png",
                "description": "File format to save input images to (tool's expected input)",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "output_feature_added": {
                "description": "image feature(s) to be added after this operation (if multiple, separate by comma)",
                "required": true,
                "type": "string"
            },
            "output_mimetype": {
                "default": "image/png",
                "description": "File format to load output images from (tool's expected output)",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization"
        ]
    },
    "ocrd-repair-inconsistencies": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Re-order glyphs/words/lines top-down-left-right when textually inconsistent with their parents",
        "executable": "ocrd-repair-inconsistencies",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK-FIXED"
        ],
        "steps": [
            "layout/segmentation/line",
            "layout/segmentation/word",
            "layout/segmentation/glyph"
        ]
    },
    "ocrd-sbb-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Pixelwise binarization with selectional auto-encoders in Keras",
        "executable": "ocrd-sbb-binarize",
        "input_file_grp": [],
        "output_file_grp": [],
        "parameters": {
            "model": {
                "description": "Directory containing HDF5 models. Can be an absolute path or a path relative to the current working directory or $SBB_BINARIZE_DATA environment variable (if set)",
                "required": true,
                "type": "string"
            },
            "operation_level": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-sbb-textline-detector": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Printspace, region and textline detection",
        "executable": "ocrd-sbb-textline-detector",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-SBB-SEG-LINE"
        ],
        "parameters": {
            "model": {
                "cacheable": true,
                "description": "Path to directory containing models to be used (See https://qurator-data.de/sbb_textline_detector/)",
                "format": "file",
                "type": "string"
            }
        },
        "steps": [
            "layout/segmentation/region",
            "layout/segmentation/line"
        ]
    },
    "ocrd-segment-evaluate": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Compare region segmentations",
        "executable": "ocrd-segment-evaluate",
        "input_file_grp": [
            "OCR-D-GT-SEG-BLOCK",
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {},
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-extract-lines": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Extract line segmentation as line images (deskewed according to `*/@orientation` and cropped+masked along `*/Coords` polygon and dewarped as in `*/AlternativeImage`) + text file (according to `*/TextEquiv`) + JSON (including line coordinates and meta-data).",
        "executable": "ocrd-segment-extract-lines",
        "input_file_grp": [
            "OCR-D-SEG-LINE",
            "OCR-D-GT-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-CROP"
        ],
        "parameters": {
            "mimetype": {
                "default": "image/png",
                "description": "File format to save extracted images in.",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            },
            "transparency": {
                "default": true,
                "description": "Add alpha channels with segment masks to the images",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-extract-pages": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Extract page segmentation as page images (deskewed according to `/Page/@orientation` and cropped+masked along `/Page/Border`) + JSON (including region coordinates/classes and meta-data), as binarized images, and as mask images (segments filled with colors encoding classes) + COCO detection format JSON (for all pages). Output fileGrp format is `raw[,binarized[,mask]]` (i.e. fall back to first group).",
        "executable": "ocrd-segment-extract-pages",
        "input_file_grp": [
            "OCR-D-SEG-PAGE",
            "OCR-D-GT-SEG-PAGE",
            "OCR-D-SEG-BLOCK",
            "OCR-D-GT-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-IMG-CROP"
        ],
        "parameters": {
            "mimetype": {
                "default": "image/png",
                "description": "File format to save extracted images in.",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            },
            "transparency": {
                "default": true,
                "description": "Add alpha channels with segment masks to the images",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-extract-regions": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Extract region segmentation as region images (deskewed according to `*/@orientation` and cropped+masked along `*/Coords` polygon) + JSON (including region coordinates/classes and meta-data).",
        "executable": "ocrd-segment-extract-regions",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-GT-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-IMG-CROP"
        ],
        "parameters": {
            "mimetype": {
                "default": "image/png",
                "description": "File format to save extracted images in.",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            },
            "transparency": {
                "default": true,
                "description": "Add alpha channels with segment masks to the images",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-from-coco": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Import region segmentation from COCO detection format JSON (for all pages). Input fileGrp format is `base,COCO` (i.e. PAGE or original image files first, COCO file second).",
        "executable": "ocrd-segment-from-coco",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {},
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-segment-from-masks": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Import region segmentation from mask images (segments filled with colors encoding classes). Input fileGrp format is `base,mask` (i.e. PAGE or original image files first, mask image files second).",
        "executable": "ocrd-segment-from-masks",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "colordict": {
                "default": {},
                "description": "Mapping from color values in the input masks to region types to annotate; color must be encoded hexadecimal (e.g. '#00FF00'); region type equals the element name in PAGE-XML, optionally followed by a colon and a subtype (e.g. 'TextRegion:paragraph'; unmapped colors will be ignored (i.e. treated as background)). Cf. output of ocrd-segment-extract-pages for an example (this is also the default).",
                "type": "object"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-segment-repair": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Analyse and repair region segmentation; at least ensure validity and consistency of coordinates.",
        "executable": "ocrd-segment-repair",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-EVAL-BLOCK"
        ],
        "parameters": {
            "plausibilize": {
                "default": false,
                "description": "Remove redundant (almost equal or almost contained) regions, and merge overlapping regions",
                "type": "boolean"
            },
            "plausibilize_merge_min_overlap": {
                "default": 0.9,
                "description": "When merging a region almost contained in another, require at least this ratio of area is shared with the other",
                "format": "float",
                "type": "number"
            },
            "sanitize": {
                "default": false,
                "description": "Shrink and/or expand a region in such a way that it coordinates include those of all its lines",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-segment-replace-original": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Extract page image (deskewed according to `/Page/@orientation` and cropped+masked along `/Page/Border`) and use it as @imageFilename, adjusting all coordinates",
        "executable": "ocrd-segment-replace-original",
        "input_file_grp": [
            "OCR-D-SEG-LINE",
            "OCR-D-GT-SEG-LINE",
            "OCR-D-OCR"
        ],
        "output_file_grp": [
            "OCR-D-SEG-CROP",
            "OCR-D-IMG-CROP"
        ],
        "parameters": {
            "feature_filter": {
                "default": "",
                "description": "comma-separated list of forbidden image features (e.g. binarized,despeckled)",
                "type": "string"
            },
            "feature_selector": {
                "default": "",
                "description": "comma-separated list of required image features (e.g. binarized,despeckled)",
                "type": "string"
            },
            "transform_coordinates": {
                "default": true,
                "description": "re-calculate coordinates for all segments of the structural hierarchy to be consistent with the coordinate system of the chosen image again (vital after cropping, deskewing etc; disable only if input coordinates must be assumed to be inconsistent with the original)",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-replace-page": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Replace everything below page level with another annotation, adjusting all coordinates",
        "executable": "ocrd-segment-replace-page",
        "input_file_grp": [
            "OCR-D-SEG-LINE",
            "OCR-D-GT-SEG-LINE",
            "OCR-D-OCR"
        ],
        "output_file_grp": [
            "OCR-D-SEG-CROP",
            "OCR-D-IMG-CROP"
        ],
        "parameters": {
            "transform_coordinates": {
                "default": true,
                "description": "re-calculate coordinates for all segments of the structural hierarchy to be consistent with the coordinate system of the first input file group (vital after cropping, deskewing etc; disable only if input coordinates can be assumed to be consistent with the second input file group)",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-skimage-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Binarize images with Scikit-image",
        "executable": "ocrd-skimage-binarize",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-BIN",
            "OCR-D-SEG-PAGE-BIN",
            "OCR-D-SEG-REGION-BIN",
            "OCR-D-SEG-LINE-BIN"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero",
                "format": "float",
                "type": "number"
            },
            "k": {
                "default": 0.34,
                "description": "For Sauvola/Niblack, formula parameter influencing the threshold bias; larger is lighter foreground",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "method": {
                "default": "sauvola",
                "description": "Thresholding algorithm to use",
                "enum": [
                    "sauvola",
                    "niblack",
                    "otsu",
                    "gauss",
                    "yen",
                    "li"
                ],
                "type": "string"
            },
            "window_size": {
                "default": 0,
                "description": "For Sauvola/Niblack/Gauss, the (odd) window size in pixels; when zero (default), set to DPI",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-skimage-denoise": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Denoise binarized images with Scikit-image",
        "executable": "ocrd-skimage-denoise",
        "input_file_grp": [
            "OCR-D-IMG-BIN",
            "OCR-D-SEG-PAGE-BIN",
            "OCR-D-SEG-REGION-BIN",
            "OCR-D-SEG-LINE-BIN"
        ],
        "output_file_grp": [
            "OCR-D-IMG-DEN",
            "OCR-D-SEG-PAGE-DEN",
            "OCR-D-SEG-REGION-DEN",
            "OCR-D-SEG-LINE-DEN"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "maxsize": {
                "default": 3,
                "description": "maximum component size of (bg holes or fg specks) noise in pt",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/despeckling"
        ]
    },
    "ocrd-skimage-denoise-raw": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Denoise raw images with Scikit-image",
        "executable": "ocrd-skimage-denoise-raw",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-DEN",
            "OCR-D-SEG-PAGE-DEN",
            "OCR-D-SEG-REGION-DEN",
            "OCR-D-SEG-LINE-DEN"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "method": {
                "default": "VisuShrink",
                "description": "Wavelet filtering scheme to use",
                "enum": [
                    "BayesShrink",
                    "VisuShrink"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization/despeckling"
        ]
    },
    "ocrd-skimage-normalize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Equalize contrast/exposure of images with Scikit-image; stretches the color value/tone to the full dynamic range",
        "executable": "ocrd-skimage-normalize",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-NRM",
            "OCR-D-SEG-PAGE-NRM",
            "OCR-D-SEG-REGION-NRM",
            "OCR-D-SEG-LINE-NRM"
        ],
        "parameters": {
            "black-point": {
                "default": 1.0,
                "description": "black point point in percent of luminance/value/tone histogram; up to ``black-point`` darkest pixels will be clipped to black when stretching",
                "format": "float",
                "type": "number"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "method": {
                "default": "stretch",
                "description": "contrast-enhancing transformation to use after clipping; ``stretch`` uses ``skimage.exposure.rescale_intensity`` (globally linearly stretching to full dynamic range) and ``adapthist`` uses ``skimage.exposure.equalize_adapthist`` (applying over tiles with context from 1/8th of the image's width)",
                "enum": [
                    "stretch",
                    "adapthist"
                ],
                "type": "string"
            },
            "white-point": {
                "default": 7.0,
                "description": "white point in percent of luminance/value/tone histogram; up to ``white-point`` brightest pixels will be clipped to white when stretching",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization"
        ]
    },
    "ocrd-tesserocr-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Binarize regions or lines with Tesseract's global Otsu",
        "executable": "ocrd-tesserocr-binarize",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-BIN-BLOCK",
            "OCR-D-BIN-LINE"
        ],
        "parameters": {
            "operation_level": {
                "default": "region",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "region",
                    "line"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-tesserocr-crop": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Poor man's cropping via region segmentation",
        "executable": "ocrd-tesserocr-crop",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-SEG-PAGE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "padding": {
                "default": 4,
                "description": "extend detected border by this many (true) pixels on every side",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/cropping"
        ]
    },
    "ocrd-tesserocr-deskew": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Detect script, orientation and skew angle for pages or regions",
        "executable": "ocrd-tesserocr-deskew",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-DESKEW-BLOCK"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "min_orientation_confidence": {
                "default": 1.5,
                "description": "Minimum confidence score to apply orientation as detected by OSD",
                "format": "float",
                "type": "number"
            },
            "operation_level": {
                "default": "region",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization/deskewing"
        ]
    },
    "ocrd-tesserocr-fontshape": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Recognize font shapes (family/monospace/bold/italic) and size in segmented words with Tesseract (using annotated derived images, or masking and cropping images from coordinate polygons), annotating TextStyle",
        "executable": "ocrd-tesserocr-fontshape",
        "input_file_grp": [
            "OCR-D-SEG-WORD",
            "OCR-D-OCR"
        ],
        "output_file_grp": [
            "OCR-D-OCR-FONTSTYLE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "model": {
                "default": "osd",
                "description": "tessdata model to apply (an ISO 639-3 language specification or some other basename, e.g. deu-frak or osd); must be an old (pre-LSTM) model",
                "type": "string"
            },
            "padding": {
                "default": 0,
                "description": "Number of background-filled pixels to add around the word image (i.e. the annotated AlternativeImage if it exists or the higher-level image cropped to the bounding box and masked by the polygon otherwise) on each side before recognition.",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "recognition/font-identification"
        ]
    },
    "ocrd-tesserocr-recognize": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Segment and/or recognize text with Tesseract (using annotated derived images, or masking and cropping images from coordinate polygons) on any level of the PAGE hierarchy.",
        "executable": "ocrd-tesserocr-recognize",
        "input_file_grp": [
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-TABLE",
            "OCR-D-SEG-LINE",
            "OCR-D-SEG-WORD"
        ],
        "output_file_grp": [
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-TABLE",
            "OCR-D-SEG-LINE",
            "OCR-D-SEG-WORD",
            "OCR-D-SEG-GLYPH",
            "OCR-D-OCR-TESS"
        ],
        "parameters": {
            "block_polygons": {
                "default": false,
                "description": "When detecting regions, annotate polygon coordinates instead of bounding box rectangles.",
                "type": "boolean"
            },
            "char_blacklist": {
                "default": "",
                "description": "When recognizing text, enumeration of character hypotheses (from the model) to suppress; overruled by unblacklist if set.",
                "type": "string"
            },
            "char_unblacklist": {
                "default": "",
                "description": "When recognizing text, enumeration of character hypotheses (from the model) to allow inclusively.",
                "type": "string"
            },
            "char_whitelist": {
                "default": "",
                "description": "When recognizing text, enumeration of character hypotheses (from the model) to allow exclusively; overruled by blacklist if set.",
                "type": "string"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "find_tables": {
                "default": true,
                "description": "When detecting regions, recognise tables as table regions (Tesseract's ``textord_tabfind_find_tables=1``).",
                "type": "boolean"
            },
            "model": {
                "description": "The tessdata text recognition model to apply (an ISO 639-3 language specification or some other basename, e.g. deu-frak or Fraktur).",
                "type": "string"
            },
            "overwrite_segments": {
                "default": false,
                "description": "If ``segmentation_level`` is not none, but an element already contains segments, remove them and segment again. Otherwise use the existing segments of that element.",
                "type": "boolean"
            },
            "overwrite_text": {
                "default": true,
                "description": "If ``textequiv_level`` is not none, but a segment already contains TextEquivs, remove them and replace with recognised text. Otherwise add new text as alternative. (Only the first entry is projected upwards.)",
                "type": "boolean"
            },
            "padding": {
                "default": 0,
                "description": "Extend detected region/cell/line/word rectangles by this many (true) pixels, or extend existing region/line/word images (i.e. the annotated AlternativeImage if it exists or the higher-level image cropped to the bounding box and masked by the polygon otherwise) by this many (background/white) pixels on each side before recognition.",
                "format": "integer",
                "type": "number"
            },
            "raw_lines": {
                "default": false,
                "description": "When detecting lines, do not attempt additional segmentation (baseline+xheight+ascenders/descenders prediction) on line images. Can increase accuracy for certain workflows. Disable when line segments/images may contain components of more than 1 line, or larger gaps/white-spaces.",
                "type": "boolean"
            },
            "segmentation_level": {
                "default": "word",
                "description": "Highest PAGE XML hierarchy level to remove existing annotation from and detect segments for (before iterating downwards); if ``none``, does not attempt any new segmentation; if ``cell``, starts at table regions, detecting text regions (cells). Ineffective when lower than ``textequiv_level``.",
                "enum": [
                    "region",
                    "cell",
                    "line",
                    "word",
                    "glyph",
                    "none"
                ],
                "type": "string"
            },
            "sparse_text": {
                "default": false,
                "description": "When detecting regions, use 'sparse text' page segmentation mode (finding as much text as possible in no particular order): only text regions, single lines without vertical or horizontal space.",
                "type": "boolean"
            },
            "textequiv_level": {
                "default": "word",
                "description": "Lowest PAGE XML hierarchy level to re-use or detect segments for and add the TextEquiv results to (before projecting upwards); if ``none``, adds segmentation down to the glyph level, but does not attempt recognition at all; if ``cell``, stops short before text lines, adding text of text regions inside tables (cells) or on page level only.",
                "enum": [
                    "region",
                    "cell",
                    "line",
                    "word",
                    "glyph",
                    "none"
                ],
                "type": "string"
            }
        },
        "steps": [
            "layout/segmentation/region",
            "layout/segmentation/line",
            "recognition/text-recognition"
        ]
    },
    "ocrd-tesserocr-segment": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment page into regions and lines with Tesseract",
        "executable": "ocrd-tesserocr-segment",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-GT-SEG-PAGE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "block_polygons": {
                "default": false,
                "description": "annotate polygon coordinates instead of bounding box rectangles",
                "type": "boolean"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "find_tables": {
                "default": true,
                "description": "recognise tables as table regions (textord_tabfind_find_tables)",
                "type": "boolean"
            },
            "padding": {
                "default": 4,
                "description": "extend detected region rectangles by this many (true) pixels",
                "format": "integer",
                "type": "number"
            },
            "sparse_text": {
                "default": false,
                "description": "use 'sparse text' page segmentation mode (find as much text as possible in no particular order): only text regions, single lines without vertical or horizontal space",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/region",
            "layout/segmentation/line"
        ]
    },
    "ocrd-tesserocr-segment-line": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment regions into lines with Tesseract",
        "executable": "ocrd-tesserocr-segment-line",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-GT-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "overwrite_lines": {
                "default": true,
                "description": "Remove existing layout and text annotation below the TextRegion level (otherwise skip region; no incremental annotation yet).",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/line"
        ]
    },
    "ocrd-tesserocr-segment-region": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment page into regions with Tesseract",
        "executable": "ocrd-tesserocr-segment-region",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-GT-SEG-PAGE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "crop_polygons": {
                "default": false,
                "description": "annotate polygon coordinates instead of bounding box rectangles",
                "type": "boolean"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "find_tables": {
                "default": true,
                "description": "recognise tables as table regions (textord_tabfind_find_tables)",
                "type": "boolean"
            },
            "overwrite_regions": {
                "default": true,
                "description": "Remove existing layout and text annotation below the Page level (otherwise skip page; no incremental annotation yet).",
                "type": "boolean"
            },
            "padding": {
                "default": 0,
                "description": "extend detected region rectangles by this many (true) pixels",
                "format": "integer",
                "type": "number"
            },
            "sparse_text": {
                "default": false,
                "description": "use 'sparse text' page segmentation mode (find as much text as possible in no particular order): only text regions, single lines without vertical or horizontal space",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-tesserocr-segment-table": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment table regions into cell text regions with Tesseract",
        "executable": "ocrd-tesserocr-segment-table",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-GT-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "overwrite_cells": {
                "default": true,
                "description": "Remove existing layout and text annotation below the TableRegion level (otherwise skip table; no incremental annotation yet).",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-tesserocr-segment-word": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment lines into words with Tesseract",
        "executable": "ocrd-tesserocr-segment-word",
        "input_file_grp": [
            "OCR-D-SEG-LINE",
            "OCR-D-GT-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-WORD"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "overwrite_words": {
                "default": true,
                "description": "Remove existing layout and text annotation below the TextLine level (otherwise skip line; no incremental annotation yet).",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/word"
        ]
    },
    "ocrd-typegroups-classifier": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Classification of 15th century type groups",
        "executable": "ocrd-typegroups-classifier",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "parameters": {
            "network": {
                "description": "The file name of the neural network to use, including sufficient path information",
                "required": true,
                "type": "string"
            },
            "stride": {
                "default": 112,
                "description": "Stride applied to the CNN on the image. Should be between 1 and 224. Smaller values increase the computation time.",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "recognition/font-identification"
        ]
    }
}
