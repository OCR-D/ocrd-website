{
    "ocrd-anybaseocr-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Binarizes images with the algorithm from ocropy and outputs it as an AlternativeImage.",
        "executable": "ocrd-anybaseocr-binarize",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-IMG-BIN"
        ],
        "parameters": {
            "bignore": {
                "default": 0.1,
                "description": "ignore this much of the border for threshold estimation",
                "format": "float",
                "type": "number"
            },
            "debug": {
                "default": 0,
                "description": "display intermediate results",
                "format": "integer",
                "type": "number"
            },
            "escale": {
                "default": 1.0,
                "description": "scale for estimating a mask over the text region",
                "format": "float",
                "type": "number"
            },
            "gray": {
                "default": false,
                "description": "force grayscale processing even if image seems binary",
                "type": "boolean"
            },
            "hi": {
                "default": 90,
                "description": "percentile for white estimation",
                "format": "float",
                "type": "number"
            },
            "lo": {
                "default": 5,
                "description": "percentile for black estimation",
                "format": "float",
                "type": "number"
            },
            "nocheck": {
                "default": false,
                "description": "disable error checking on inputs",
                "type": "boolean"
            },
            "operation_level": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "perc": {
                "default": 80,
                "description": "percentage for filters",
                "format": "float",
                "type": "number"
            },
            "range": {
                "default": 20,
                "description": "range for filters",
                "format": "integer",
                "type": "number"
            },
            "raw_copy": {
                "default": false,
                "description": "also copy the raw image",
                "type": "boolean"
            },
            "show": {
                "default": false,
                "description": "display final results",
                "type": "boolean"
            },
            "threshold": {
                "default": 0.5,
                "description": "threshold, determines lightness",
                "format": "float",
                "type": "number"
            },
            "zoom": {
                "default": 0.5,
                "description": "zoom for page background estimation, smaller=faster",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-anybaseocr-block-segmentation": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segments and classifies regions in each single page and annotates the the region polygons and classes.",
        "executable": "ocrd-anybaseocr-block-segmentation",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "active_classes": {
                "default": [
                    "page-number",
                    "paragraph",
                    "catch-word",
                    "heading",
                    "drop-capital",
                    "signature-mark",
                    "marginalia",
                    "caption"
                ],
                "description": "Restrict types of regions to be detected.",
                "items": {
                    "enum": [
                        "page-number",
                        "paragraph",
                        "catch-word",
                        "heading",
                        "drop-capital",
                        "signature-mark",
                        "header",
                        "marginalia",
                        "footnote",
                        "footnote-continued",
                        "caption",
                        "endnote",
                        "footer",
                        "keynote",
                        "image",
                        "table",
                        "graphics"
                    ],
                    "type": "string"
                },
                "type": "array"
            },
            "block_segmentation_weights": {
                "cacheable": true,
                "content-type": "application/x-hdf;subtype=bag",
                "default": "block_segmentation_weights.h5",
                "description": "Path to model weights",
                "format": "uri",
                "type": "string"
            },
            "min_confidence": {
                "default": 0.9,
                "description": "Confidence threshold for region detections",
                "format": "float",
                "type": "number"
            },
            "min_iou_drop": {
                "default": 0.8,
                "description": "Minimum required overlap (intersection over union) of mask-derived contour area between neighbours to suppress prediction scoring worse",
                "format": "float",
                "type": "number"
            },
            "min_iou_merge": {
                "default": 0.2,
                "description": "Minimum required overlap (intersection over union) of mask-derived contour area between neighbours to merge prediction scoring worse",
                "format": "float",
                "type": "number"
            },
            "min_share_drop": {
                "default": 0.9,
                "description": "Minimum required overlap (intersection over single) of mask-derived contour area between neighbours to suppress smaller prediction",
                "format": "float",
                "type": "number"
            },
            "min_share_merge": {
                "default": 0.8,
                "description": "Minimum required overlap (intersection over single) of mask-derived contour area between neighbours to merge smaller prediction",
                "format": "float",
                "type": "number"
            },
            "overwrite": {
                "default": false,
                "description": "whether to delete existing text lines prior to segmentation",
                "type": "boolean"
            },
            "post_process": {
                "default": true,
                "description": "whether to apply non-maximum suppression (across classes) on the detections",
                "type": "boolean"
            },
            "th": {
                "default": 15,
                "description": "num of pixels to include in the area region (when applying text/non-text mask from tiseg)",
                "type": "integer"
            },
            "use_masks": {
                "default": true,
                "description": "whether to segment from the mask as polygon instead of just the bbox",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-anybaseocr-crop": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Detect the input images' page frame, annotate it as border polygon and add a cropped derived image.",
        "executable": "ocrd-anybaseocr-crop",
        "input_file_grp": [
            "OCR-D-IMG-DESKEW"
        ],
        "output_file_grp": [
            "OCR-D-IMG-CROP"
        ],
        "parameters": {
            "columnAreaMin": {
                "default": 0.05,
                "description": "text block detection: minimum area of individual columns (as ratio of total image pixels)",
                "format": "float",
                "type": "number"
            },
            "columnSepWidthMax": {
                "default": 0.04,
                "description": "text block detection: maximum width between individual columns (as ratio of total image width)",
                "format": "float",
                "type": "number"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (used to zoom/scale during processing; overrides any meta-data in the images); disabled when zero or negative",
                "format": "float",
                "type": "number"
            },
            "marginBottom": {
                "default": 0.75,
                "description": "ruler / edge / text detection: minimum y position to crop from below (as ratio of total image height)",
                "format": "float",
                "type": "number"
            },
            "marginLeft": {
                "default": 0.3,
                "description": "ruler / edge / text detection: maximum x position to crop from left (as ratio of total image width)",
                "format": "float",
                "type": "number"
            },
            "marginRight": {
                "default": 0.7,
                "description": "ruler / edge / text detection: minimum x position to crop from right (as ratio of total image width)",
                "format": "float",
                "type": "number"
            },
            "marginTop": {
                "default": 0.25,
                "description": "ruler / edge / text detection: maximum y position to crop from above (as ratio of total image height)",
                "format": "float",
                "type": "number"
            },
            "padding": {
                "default": 10,
                "description": "extend / shrink border resulting from edge detection / text detection by this many px in each direction",
                "format": "integer",
                "type": "number"
            },
            "rulerAreaMax": {
                "default": 0.3,
                "description": "ruler detection and suppression: maximum area of bbox (as ratio of total image pixels)",
                "format": "float",
                "type": "number"
            },
            "rulerAreaMin": {
                "default": 0.01,
                "description": "ruler detection and suppression: minimum area of bbox (as ratio of total image pixels)",
                "format": "float",
                "type": "number"
            },
            "rulerRatioMax": {
                "default": 50.0,
                "description": "ruler detection and suppression: maximum aspect ratio of bbox",
                "format": "float",
                "type": "number"
            },
            "rulerRatioMin": {
                "default": 3.0,
                "description": "ruler detection and suppression: minimum aspect ratio of bbox",
                "format": "float",
                "type": "number"
            },
            "rulerWidthMax": {
                "default": 0.95,
                "description": "ruler detection and suppression: maximum width of bbox (as ratio of total image width)",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/cropping"
        ]
    },
    "ocrd-anybaseocr-deskew": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Deskews images with the algorithm from ocropy and outputs a deskew angle.",
        "executable": "ocrd-anybaseocr-deskew",
        "input_file_grp": [
            "OCR-D-IMG-BIN"
        ],
        "output_file_grp": [
            "OCR-D-IMG-DESKEW"
        ],
        "parameters": {
            "bignore": {
                "default": 0.1,
                "description": "ignore this much of the border for threshold estimation",
                "format": "float",
                "type": "number"
            },
            "debug": {
                "default": 0,
                "description": "display intermediate results",
                "format": "integer",
                "type": "number"
            },
            "escale": {
                "default": 1.0,
                "description": "scale for estimating a mask over the text region",
                "format": "float",
                "type": "number"
            },
            "hi": {
                "default": 90,
                "description": "percentile for white estimation",
                "format": "integer",
                "type": "number"
            },
            "lo": {
                "default": 5,
                "description": "percentile for black estimation",
                "format": "integer",
                "type": "number"
            },
            "maxskew": {
                "default": 1.0,
                "description": "skew angle estimation parameters (degrees)",
                "format": "float",
                "type": "number"
            },
            "operation_level": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "parallel": {
                "default": 0,
                "description": "???",
                "format": "integer",
                "type": "number"
            },
            "skewsteps": {
                "default": 8,
                "description": "steps for skew angle estimation (per degree)",
                "format": "integer",
                "type": "number"
            },
            "threshold": {
                "default": 0.5,
                "description": "threshold, determines lightness",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/deskewing"
        ]
    },
    "ocrd-anybaseocr-dewarp": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Dewarps the input image with anyBaseOCR and outputs it as an AlternativeImage",
        "executable": "ocrd-anybaseocr-dewarp",
        "input_file_grp": [
            "OCR-D-IMG-CROP"
        ],
        "output_file_grp": [
            "OCR-D-IMG-DEWARP"
        ],
        "parameters": {
            "gpu_id": {
                "default": -1,
                "description": "CUDA device ID of GPU to use, or -1 for CPU only",
                "format": "integer",
                "type": "number"
            },
            "model_path": {
                "cacheable": true,
                "content-type": "application/vnd.pytorch",
                "default": "latest_net_G.pth",
                "description": "Path to the trained pix2pixHD model",
                "format": "uri",
                "type": "string"
            },
            "operation_level": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on (should match what model was trained on!)",
                "enum": [
                    "page",
                    "region"
                ],
                "type": "string"
            },
            "resize_height": {
                "default": 1024,
                "description": "target image height before input to the network",
                "format": "integer",
                "type": "number"
            },
            "resize_mode": {
                "default": "resize_and_crop",
                "description": "transformation to apply to the original image before input to the network",
                "enum": [
                    "resize_and_crop",
                    "crop",
                    "scale_width",
                    "scale_width_and_crop",
                    "none"
                ],
                "type": "string"
            },
            "resize_width": {
                "default": 1024,
                "description": "target image width before input to the network",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/dewarping"
        ]
    },
    "ocrd-anybaseocr-layout-analysis": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Generates a table-of-content like document structure of the whole document.",
        "executable": "ocrd-anybaseocr-layout-analysis",
        "input_file_grp": [
            "OCR-D-IMG-CROP"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LAYOUT"
        ],
        "parameters": {
            "batch_size": {
                "default": 4,
                "description": "Batch size for generating test images",
                "format": "integer",
                "type": "number"
            },
            "class_mapping_path": {
                "cacheable": true,
                "content-type": "application/python-pickle",
                "default": "mapping_densenet.pickle",
                "description": "File path to layout structure classes",
                "format": "uri",
                "type": "string"
            },
            "model_path": {
                "cacheable": true,
                "content-type": "text/directory",
                "default": "structure_analysis",
                "description": "Directory path to layout structure classification model",
                "format": "uri",
                "type": "string"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-anybaseocr-textline": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Finds region polygons for each text line in the input image.",
        "executable": "ocrd-anybaseocr-textline",
        "input_file_grp": [
            "OCR-D-SEG-TISEG"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE-ANY"
        ],
        "parameters": {
            "blackseps": {
                "default": false,
                "description": "also check for black column separators",
                "type": "boolean"
            },
            "csminaspect": {
                "default": 1.1,
                "description": "minimum aspect ratio for column separators",
                "format": "float",
                "type": "number"
            },
            "csminheight": {
                "default": 6.5,
                "description": "minimum column height (units=scale)",
                "format": "float",
                "type": "number"
            },
            "expand": {
                "default": 3,
                "description": "expand mask for grayscale extraction",
                "format": "integer",
                "type": "number"
            },
            "hscale": {
                "default": 1.0,
                "description": "non-standard scaling of horizontal parameters",
                "format": "float",
                "type": "number"
            },
            "libpath": {
                "default": ".",
                "description": "Library Path for C Executables",
                "type": "string"
            },
            "maxcolseps": {
                "default": 2,
                "description": "maximum # whitespace column separators",
                "format": "integer",
                "type": "number"
            },
            "maxlines": {
                "default": 300,
                "description": "non-standard scaling of horizontal parameters",
                "format": "float",
                "type": "number"
            },
            "maxseps": {
                "default": 2,
                "description": "maximum black column separators",
                "format": "integer",
                "type": "number"
            },
            "minscale": {
                "default": 12.0,
                "description": "minimum scale permitted",
                "format": "float",
                "type": "number"
            },
            "noise": {
                "default": 8,
                "description": "noise threshold for removing small components from lines",
                "format": "integer",
                "type": "number"
            },
            "operation_level": {
                "default": "region",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region"
                ],
                "type": "string"
            },
            "overwrite": {
                "default": false,
                "description": "check whether to overwrite existing text lines",
                "type": "boolean"
            },
            "pad": {
                "default": 3,
                "description": "padding for extracted lines",
                "format": "integer",
                "type": "number"
            },
            "parallel": {
                "default": 0,
                "description": "number of CPUs to use",
                "format": "integer",
                "type": "number"
            },
            "scale": {
                "default": 0.0,
                "description": "the basic scale of the document (roughly, xheight) 0=automatic",
                "format": "float",
                "type": "number"
            },
            "sepwiden": {
                "default": 10,
                "description": "widen black separators (to account for warping)",
                "format": "integer",
                "type": "number"
            },
            "threshold": {
                "default": 0.2,
                "description": "baseline threshold",
                "format": "float",
                "type": "number"
            },
            "usegauss": {
                "default": false,
                "description": "use gaussian instead of uniform",
                "type": "boolean"
            },
            "vscale": {
                "default": 1.7,
                "description": "non-standard scaling of vertical parameters",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "layout/segmentation/line"
        ]
    },
    "ocrd-anybaseocr-tiseg": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Separates the text and non-text elements with anyBaseOCR. Outputs clipped versions of the input image as AlternativeImage containing either only text or non-text elements.",
        "executable": "ocrd-anybaseocr-tiseg",
        "input_file_grp": [
            "OCR-D-IMG-CROP"
        ],
        "output_file_grp": [
            "OCR-D-SEG-TISEG"
        ],
        "parameters": {
            "seg_weights": {
                "cacheable": true,
                "content-type": "text/directory",
                "default": "seg_model",
                "description": "Directory path to deep learning model when use_deeplr is true.",
                "format": "uri",
                "type": "string"
            },
            "use_deeplr": {
                "default": true,
                "description": "Whether to use deep learning model (UNet pixel classifier) instead of rule-based implementation (multi-resolution morphology).",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/text-nontext"
        ]
    },
    "ocrd-calamari-recognize": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Recognize lines with Calamari",
        "executable": "ocrd-calamari-recognize",
        "input_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-OCR-CALAMARI"
        ],
        "parameters": {
            "checkpoint_dir": {
                "cacheable": true,
                "content-type": "text/directory",
                "default": "qurator-gt4histocr-1.0",
                "description": "The directory containing calamari model files (*.ckpt.json). Uses all checkpoints in that directory",
                "format": "uri",
                "type": "string"
            },
            "glyph_conf_cutoff": {
                "default": 0.001,
                "description": "Only include glyph alternatives with confidences above this threshold",
                "format": "float",
                "type": "number"
            },
            "textequiv_level": {
                "default": "line",
                "description": "Deepest PAGE XML hierarchy level to include TextEquiv results for",
                "enum": [
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "voter": {
                "default": "confidence_voter_default_ctc",
                "description": "The voting algorithm to use",
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-cis-align": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Align multiple OCRs and/or GTs",
        "executable": "ocrd-cis-align",
        "input_file_grp": [
            "OCR-D-OCR-1",
            "OCR-D-OCR-2",
            "OCR-D-OCR-N"
        ],
        "output_file_grp": [
            "OCR-D-ALIGNED"
        ],
        "steps": [
            "recognition/post-correction"
        ]
    },
    "ocrd-cis-ocropy-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Binarize (and optionally deskew/despeckle) pages / regions / lines with ocropy",
        "executable": "ocrd-cis-ocropy-binarize",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-BIN",
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative",
                "format": "float",
                "type": "number"
            },
            "grayscale": {
                "default": false,
                "description": "for the 'ocropy' method, produce grayscale-normalized instead of thresholded image",
                "type": "boolean"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level granularity to annotate images for",
                "enum": [
                    "page",
                    "table",
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "maxskew": {
                "default": 0.0,
                "description": "modulus of maximum skewing angle (in degrees) to detect (larger will be slower, 0 will deactivate deskewing)",
                "format": "float",
                "type": "number"
            },
            "method": {
                "default": "ocropy",
                "description": "binarization method to use (only 'ocropy' will include deskewing and denoising)",
                "enum": [
                    "none",
                    "global",
                    "otsu",
                    "gauss-otsu",
                    "ocropy"
                ],
                "type": "string"
            },
            "noise_maxsize": {
                "default": 0,
                "description": "maximum pixel number for connected components to regard as noise (0 will deactivate denoising)",
                "format": "int",
                "type": "number"
            },
            "threshold": {
                "default": 0.5,
                "description": "for the 'ocropy' and ' global' method, black/white threshold to apply on the whitelevel normalized image (the larger the more/heavier foreground)",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization",
            "preprocessing/optimization/grayscale_normalization",
            "preprocessing/optimization/deskewing"
        ]
    },
    "ocrd-cis-ocropy-clip": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Clip text regions / lines at intersections with neighbours",
        "executable": "ocrd-cis-ocropy-clip",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "region",
                "description": "PAGE XML hierarchy level granularity to annotate images for",
                "enum": [
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "min_fraction": {
                "default": 0.7,
                "description": "share of foreground pixels that must be retained by the largest label",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "layout/segmentation/region",
            "layout/segmentation/line"
        ]
    },
    "ocrd-cis-ocropy-denoise": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Despeckle pages / regions / lines with ocropy",
        "executable": "ocrd-cis-ocropy-denoise",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-DESPECK",
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level granularity to annotate images for",
                "enum": [
                    "page",
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "noise_maxsize": {
                "default": 3.0,
                "description": "maximum size in points (pt) for connected components to regard as noise (0 will deactivate denoising)",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/despeckling"
        ]
    },
    "ocrd-cis-ocropy-deskew": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Deskew regions with ocropy (by annotating orientation angle and adding AlternativeImage)",
        "executable": "ocrd-cis-ocropy-deskew",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "level-of-operation": {
                "default": "region",
                "description": "PAGE XML hierarchy level granularity to annotate images for",
                "enum": [
                    "page",
                    "table",
                    "region"
                ],
                "type": "string"
            },
            "maxskew": {
                "default": 5.0,
                "description": "modulus of maximum skewing angle to detect (larger will be slower, 0 will deactivate deskewing)",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/deskewing"
        ]
    },
    "ocrd-cis-ocropy-dewarp": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Dewarp line images with ocropy",
        "executable": "ocrd-cis-ocropy-dewarp",
        "input_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative",
                "format": "float",
                "type": "number"
            },
            "max_neighbour": {
                "default": 0.05,
                "description": "maximum rate of foreground pixels intruding from neighbouring lines (line will not be processed above that)",
                "format": "float",
                "type": "number"
            },
            "range": {
                "default": 4.0,
                "description": "maximum vertical disposition or maximum margin (will be multiplied by mean centerline deltas to yield pixels); also the mean vertical padding",
                "format": "float",
                "type": "number"
            },
            "smoothness": {
                "default": 1.0,
                "description": "kernel size (relative to image height) of horizontal blur applied to foreground to find the center line; the smaller the more dynamic (0.1 would be a better default)",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/dewarping"
        ]
    },
    "ocrd-cis-ocropy-rec": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Recognize text snippets",
        "executable": "ocrd-cis-ocropy-rec",
        "input_file_grp": [
            "OCR-D-GT-SEG-BLOCK",
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "model": {
                "description": "ocropy model to apply (e.g. fraktur.pyrnn)",
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-cis-ocropy-recognize": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Recognize text in (binarized+deskewed+dewarped) lines with ocropy",
        "executable": "ocrd-cis-ocropy-recognize",
        "input_file_grp": [
            "OCR-D-SEG-LINE",
            "OCR-D-SEG-WORD",
            "OCR-D-SEG-GLYPH"
        ],
        "output_file_grp": [
            "OCR-D-OCR-OCRO"
        ],
        "parameters": {
            "model": {
                "description": "ocropy model to apply (e.g. fraktur.pyrnn)",
                "type": "string"
            },
            "textequiv_level": {
                "default": "line",
                "description": "PAGE XML hierarchy level granularity to add the TextEquiv results to",
                "enum": [
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-cis-ocropy-resegment": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Resegment text lines",
        "executable": "ocrd-cis-ocropy-resegment",
        "input_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative",
                "format": "float",
                "type": "number"
            },
            "extend_margins": {
                "default": 3,
                "description": "number of pixels to extend the input polygons in all directions",
                "format": "integer",
                "type": "number"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level to segment textlines in ('region' abides by existing text region boundaries, 'page' optimises lines in the whole page once",
                "enum": [
                    "page",
                    "region"
                ],
                "type": "string"
            },
            "method": {
                "default": "lineest",
                "description": "source for new line polygon candidates ('lineest' for line estimation, i.e. how Ocropy would have segmented text lines; 'baseline' tries to re-polygonize from the baseline annotation; 'ccomps' avoids crossing connected components by majority rule)",
                "enum": [
                    "lineest",
                    "baseline",
                    "ccomps"
                ],
                "type": "string"
            },
            "min_fraction": {
                "default": 0.75,
                "description": "share of foreground pixels that must be retained by the output polygons",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "layout/segmentation/line"
        ]
    },
    "ocrd-cis-ocropy-segment": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment pages into regions and lines, tables into cells and lines, or regions into lines with ocropy",
        "executable": "ocrd-cis-ocropy-segment",
        "input_file_grp": [
            "OCR-D-GT-SEG-BLOCK",
            "OCR-D-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "csminheight": {
                "default": 4,
                "description": "(when operating on the page/table level) minimum height of white/background or black/foreground column separators in multiples of scale/capheight, counted piece-wise",
                "format": "integer",
                "type": "number"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero or negative; when disabled and no meta-data is found, 300 is assumed",
                "format": "float",
                "type": "number"
            },
            "gap_height": {
                "default": 0.01,
                "description": "(when operating on the page/table level) largest minimum pixel average in the horizontal or vertical profiles (across the binarized image) to still be regarded as a gap during recursive X-Y cut from lines to regions; needs to be larger when more foreground noise is present, reduce to avoid mistaking text for noise",
                "format": "float",
                "type": "number"
            },
            "gap_width": {
                "default": 1.5,
                "description": "(when operating on the page/table level) smallest width in multiples of scale/capheight of a valley in the horizontal or vertical profiles (across the binarized image) to still be regarded as a gap during recursive X-Y cut from lines to regions; needs to be smaller when more foreground noise is present, increase to avoid mistaking inter-line as paragraph gaps and inter-word as inter-column gaps",
                "format": "float",
                "type": "number"
            },
            "hlminwidth": {
                "default": 10,
                "description": "(when operating on the page/table level) minimum width of black/foreground horizontal separators in multiples of scale/capheight, counted piece-wise",
                "format": "integer",
                "type": "number"
            },
            "level-of-operation": {
                "default": "region",
                "description": "PAGE XML hierarchy level to read images from and add elements to",
                "enum": [
                    "page",
                    "table",
                    "region"
                ],
                "type": "string"
            },
            "maxcolseps": {
                "default": 20,
                "description": "(when operating on the page/table level) maximum number of white/background column separators to detect, counted piece-wise",
                "format": "integer",
                "type": "number"
            },
            "maximages": {
                "default": 10,
                "description": "(when operating on the page level) maximum number of black/foreground very large components to detect (and suppress), counted piece-wise",
                "format": "integer",
                "type": "number"
            },
            "maxseps": {
                "default": 20,
                "description": "(when operating on the page/table level) number of black/foreground column separators to detect (and suppress), counted piece-wise",
                "format": "integer",
                "type": "number"
            },
            "overwrite_lines": {
                "default": true,
                "description": "(when operating on the region level) remove any existing TextLine elements; otherwise append",
                "type": "boolean"
            },
            "overwrite_order": {
                "default": true,
                "description": "(when operating on the page/table level) remove any references for existing TextRegion elements within the top (page/table) reading order; otherwise append",
                "type": "boolean"
            },
            "overwrite_regions": {
                "default": true,
                "description": "(when operating on the page/table level) remove any existing TextRegion elements; otherwise append",
                "type": "boolean"
            },
            "overwrite_separators": {
                "default": true,
                "description": "(when operating on the page/table level) remove any existing SeparatorRegion elements; otherwise append",
                "type": "boolean"
            },
            "spread": {
                "default": 2.4,
                "description": "distance in points (pt) from the foreground to project text line (or text region) labels into the background for polygonal contours; if zero, project half a scale/capheight",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "layout/segmentation/region",
            "layout/segmentation/line"
        ]
    },
    "ocrd-cis-ocropy-train": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "train model with ground truth from mets data",
        "executable": "ocrd-cis-ocropy-train",
        "input_file_grp": [
            "OCR-D-GT-SEG-BLOCK",
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "model": {
                "description": "load model or create new one (e.g. fraktur.pyrnn)",
                "type": "string"
            },
            "ntrain": {
                "default": 1000000,
                "description": "lines to train before stopping",
                "format": "integer",
                "type": "number"
            },
            "outputpath": {
                "description": "(existing) path for the trained model",
                "type": "string"
            },
            "textequiv_level": {
                "default": "line",
                "description": "PAGE XML hierarchy level granularity",
                "enum": [
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-cis-postcorrect": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Post correct OCR results",
        "executable": "ocrd-cis-postcorrect",
        "input_file_grp": [
            "OCR-D-LINE-ALIGNED"
        ],
        "output_file_grp": [
            "OCR-D-POST-CORRECTED"
        ],
        "parameters": {
            "maxCandidates": {
                "default": 10,
                "description": "Maximum number of considered correction candidates per suspicious token",
                "format": "integer",
                "type": "number"
            },
            "model": {
                "description": "Path to the post correction model file",
                "required": true,
                "type": "string"
            },
            "nOCR": {
                "default": 1,
                "description": "Number of parallel OCR's to use for the post correction",
                "format": "integer",
                "type": "number"
            },
            "profilerConfig": {
                "description": "Path to the profiler's language config file",
                "required": true,
                "type": "string"
            },
            "profilerPath": {
                "description": "Path to the profiler executable",
                "required": true,
                "type": "string"
            },
            "runLE": {
                "default": false,
                "description": "Do run the lexicon extension step for the post correction",
                "type": "boolean"
            }
        },
        "steps": [
            "recognition/post-correction"
        ]
    },
    "ocrd-cor-asv-ann-align": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Align different textline annotations and pick best",
        "executable": "ocrd-cor-asv-ann-align",
        "input_file_grp": [
            "OCR-D-GT-SEG-LINE",
            "OCR-D-OCR-TESS",
            "OCR-D-OCR-KRAK",
            "OCR-D-OCR-OCRO",
            "OCR-D-OCR-CALA",
            "OCR-D-OCR-ANY",
            "OCR-D-COR-ASV"
        ],
        "output_file_grp": [
            "OCR-D-OCR-MULTI"
        ],
        "parameters": {
            "method": {
                "default": "majority",
                "description": "decide by majority of OCR hypotheses, by highest confidence of OCRs or by a combination thereof",
                "enum": [
                    "majority",
                    "confidence",
                    "combined"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/post-correction"
        ]
    },
    "ocrd-cor-asv-ann-evaluate": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Align different textline annotations and compute distance",
        "executable": "ocrd-cor-asv-ann-evaluate",
        "input_file_grp": [
            "OCR-D-GT-SEG-LINE",
            "OCR-D-OCR-TESS",
            "OCR-D-OCR-KRAK",
            "OCR-D-OCR-OCRO",
            "OCR-D-OCR-CALA",
            "OCR-D-OCR-ANY",
            "OCR-D-COR-ASV"
        ],
        "output_file_grp": [
            "OCR-D-EVAL-CER"
        ],
        "parameters": {
            "confusion": {
                "default": 0,
                "description": "Count edits and show that number of most frequent confusions (non-identity) in the end.",
                "format": "integer",
                "minimum": 0,
                "type": "number"
            },
            "gt_level": {
                "default": 1,
                "description": "When `metric=historic_latin`, normalize and equate at this GT transcription level.",
                "enum": [
                    1,
                    2,
                    3
                ],
                "type": "number"
            },
            "histogram": {
                "default": false,
                "description": "Aggregate and show mutual character histograms.",
                "type": "boolean"
            },
            "metric": {
                "default": "Levenshtein-fast",
                "description": "Distance metric to calculate and aggregate: `historic_latin` for GT level 1-3, `NFKC` for roughly GT level 2 (but including reduction of `\u017f/s` and superscript numerals etc), `Levenshtein` for GT level 3 (or `Levenshtein-fast` for faster alignment - but using maximum sequence length instead of path length as CER denominator, and without confusion statistics).",
                "enum": [
                    "Levenshtein-fast",
                    "Levenshtein",
                    "NFC",
                    "NFKC",
                    "historic_latin"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/evaluation"
        ]
    },
    "ocrd-cor-asv-ann-process": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Improve text annotation by character-level encoder-attention-decoder ANN model",
        "executable": "ocrd-cor-asv-ann-process",
        "input_file_grp": [
            "OCR-D-OCR-TESS",
            "OCR-D-OCR-KRAK",
            "OCR-D-OCR-OCRO",
            "OCR-D-OCR-CALA",
            "OCR-D-OCR-ANY"
        ],
        "output_file_grp": [
            "OCR-D-COR-ASV"
        ],
        "parameters": {
            "charmap": {
                "default": {},
                "description": "mapping for input characters before passing to correction; can be used to adapt to character set mismatch between input and model (without relying on underspecification alone)",
                "type": "object"
            },
            "fast_mode": {
                "default": false,
                "description": "decode greedy instead of beamed, with batches of parallel lines instead of parallel alternatives; also disables rejection and beam parameters; enable if performance is far more important than quality",
                "type": "boolean"
            },
            "fixed_beam_width": {
                "default": 15,
                "description": "maximum number of candidates allowed to enter the beam in each hypothesis; controls the quality/performance trade-off",
                "format": "integer",
                "type": "number"
            },
            "model_file": {
                "cacheable": true,
                "content-type": "application/x-hdf;subtype=bag",
                "description": "path of h5py weight/config file for model trained with cor-asv-ann-train",
                "format": "uri",
                "required": true,
                "type": "string"
            },
            "rejection_threshold": {
                "default": 0.5,
                "description": "minimum probability of the candidate corresponding to the input character in each hypothesis during beam search, helps balance precision/recall trade-off; set to 0 to disable rejection (max recall) or 1 to disable correction (max precision)",
                "format": "float",
                "type": "number"
            },
            "relative_beam_width": {
                "default": 0.2,
                "description": "minimum fraction of the best candidate's probability required to enter the beam in each hypothesis; controls the quality/performance trade-off",
                "format": "float",
                "type": "number"
            },
            "textequiv_level": {
                "default": "glyph",
                "description": "PAGE XML hierarchy level to read/write TextEquiv input/output on",
                "enum": [
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/post-correction"
        ]
    },
    "ocrd-cor-asv-fst-process": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Improve text annotation by FST error and lexicon model with character-level LSTM language model",
        "executable": "ocrd-cor-asv-fst-process",
        "input_file_grp": [
            "OCR-D-OCR-TESS",
            "OCR-D-OCR-KRAK",
            "OCR-D-OCR-OCRO",
            "OCR-D-OCR-CALA",
            "OCR-D-OCR-ANY"
        ],
        "output_file_grp": [
            "OCR-D-COR-ASV"
        ],
        "parameters": {
            "beam_width": {
                "default": 100,
                "description": "maximum number of best partial paths to consider during beam search in language modelling",
                "format": "integer",
                "type": "number"
            },
            "errorfst_file": {
                "cacheable": true,
                "content-type": "application/vnd.openfst",
                "description": "path of FST file for error model",
                "format": "uri",
                "required": true,
                "type": "string"
            },
            "keraslm_file": {
                "cacheable": true,
                "content-type": "application/x-hdf;subtype=bag",
                "description": "path of h5py weight/config file for language model trained with keraslm",
                "format": "uri",
                "required": true,
                "type": "string"
            },
            "lexiconfst_file": {
                "cacheable": true,
                "content-type": "application/vnd.openfst",
                "description": "path of FST file for lexicon model",
                "format": "uri",
                "required": true,
                "type": "string"
            },
            "lm_weight": {
                "default": 0.5,
                "description": "share of the LM scores over the FST output confidences",
                "format": "float",
                "type": "number"
            },
            "pruning_weight": {
                "default": 5.0,
                "description": "transition weight for pruning the hypotheses in each word window FST",
                "format": "float",
                "type": "number"
            },
            "rejection_weight": {
                "default": 1.5,
                "description": "transition weight (per character) for unchanged input in each word window FST",
                "format": "float",
                "type": "number"
            },
            "textequiv_level": {
                "default": "word",
                "description": "PAGE XML hierarchy level to read TextEquiv input on (output will always be word level)",
                "enum": [
                    "word"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/post-correction"
        ]
    },
    "ocrd-detectron2-segment": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Detect regions with Detectron2 models",
        "executable": "ocrd-detectron2-segment",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-SEG-REGION"
        ],
        "parameters": {
            "categories": {
                "description": "maps each region category (position) of the model to a PAGE region type (and @type or @custom if separated by colon), e.g. ['TextRegion:paragraph', 'TextRegion:heading', 'TextRegion:floating', 'TableRegion', 'ImageRegion'] for PubLayNet; categories with an empty string will be skipped during prediction",
                "required": true,
                "type": "array"
            },
            "device": {
                "default": "cuda",
                "description": "select computing device for Torch (e.g. cpu or cuda:0); will fall back to CPU if no GPU is available",
                "type": "string"
            },
            "min_confidence": {
                "default": 0.5,
                "description": "confidence threshold for detections",
                "format": "float",
                "type": "number"
            },
            "model_config": {
                "content-type": "text/yaml",
                "description": "path name of model config",
                "format": "uri",
                "required": true,
                "type": "string"
            },
            "model_weights": {
                "content-type": "application/octet-stream",
                "description": "path name of model weights",
                "format": "uri",
                "required": true,
                "type": "string"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-dinglehopper": {
        "categories": [
            "Quality assurance"
        ],
        "description": "Evaluate OCR text against ground truth with dinglehopper",
        "executable": "ocrd-dinglehopper",
        "input_file_grp": [
            "OCR-D-GT-PAGE",
            "OCR-D-OCR"
        ],
        "output_file_grp": [
            "OCR-D-OCR-EVAL"
        ],
        "parameters": {
            "metrics": {
                "default": true,
                "description": "Enable/disable metrics and green/red",
                "type": "boolean"
            },
            "textequiv_level": {
                "default": "region",
                "description": "PAGE XML hierarchy level to extract the text from",
                "enum": [
                    "region",
                    "line"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-eynollah-segment": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment page into regions and lines and do reading order detection with eynollah",
        "executable": "ocrd-eynollah-segment",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-GT-SEG-PAGE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "allow_scaling": {
                "default": false,
                "description": "check the resolution against the number of detected columns and if needed, scale the image up or down during layout detection (heuristic to improve quality and performance)",
                "type": "boolean"
            },
            "curved_line": {
                "default": false,
                "description": "try to return contour of textlines instead of just rectangle bounding box. Needs more processing time",
                "type": "boolean"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); ignored if <= 0 (with fall-back 230)",
                "format": "float",
                "type": "number"
            },
            "full_layout": {
                "default": true,
                "description": "Try to detect all element subtypes, including drop-caps and headings",
                "type": "boolean"
            },
            "headers_off": {
                "default": false,
                "description": "ignore the special role of headings during reading order detection",
                "type": "boolean"
            },
            "models": {
                "cacheable": true,
                "content-type": "text/directory",
                "description": "Path to directory containing models to be used (See https://qurator-data.de/eynollah)",
                "format": "file",
                "required": true,
                "type": "string"
            }
        },
        "steps": [
            "layout/segmentation/region",
            "layout/segmentation/line"
        ]
    },
    "ocrd-fileformat-transform": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Convert between OCR file formats",
        "executable": "ocrd-fileformat-transform",
        "input_file_grp": [
            "OCR-D-OCR-PAGE",
            "OCR-D-OCR-ALTO",
            "OCR-D-OCR-HOCR"
        ],
        "output_file_grp": [
            "OCR-D-OCR-PAGE",
            "OCR-D-OCR-ALTO",
            "OCR-D-OCR-HOCR"
        ],
        "parameters": {
            "ext": {
                "default": "",
                "description": "Output extension. Set to empty string to derive extension from the media type.",
                "type": "string"
            },
            "from-to": {
                "default": "page alto",
                "description": "Transformation scenario, see ocr-fileformat -L",
                "enum": [
                    "alto2.0 alto3.0",
                    "alto2.0 alto3.1",
                    "alto2.0 hocr",
                    "alto2.1 alto3.0",
                    "alto2.1 alto3.1",
                    "alto2.1 hocr",
                    "alto page",
                    "alto text",
                    "gcv hocr",
                    "hocr alto2.0",
                    "hocr alto2.1",
                    "hocr text",
                    "page alto",
                    "page hocr",
                    "page text"
                ],
                "type": "string"
            },
            "script-args": {
                "default": "",
                "description": "Arguments to Saxon (for XSLT transformations) or to transformation script",
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization"
        ]
    },
    "ocrd-im6convert": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Convert and transform images",
        "executable": "ocrd-im6convert",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-IMG"
        ],
        "parameters": {
            "input-options": {
                "default": "",
                "description": "e.g. -density 600x600 -wavelet-denoise 1%x0.1",
                "type": "string"
            },
            "output-format": {
                "description": "Desired media type of output",
                "enum": [
                    "image/tiff",
                    "image/jp2",
                    "image/png"
                ],
                "required": true,
                "type": "string"
            },
            "output-options": {
                "default": "",
                "description": "e.g. -resample 300x300 -alpha deactivate -normalize -despeckle -noise 2 -negate -morphology close diamond",
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization"
        ]
    },
    "ocrd-keraslm-rate": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Rate elements of the text with a character-level LSTM language model in Keras",
        "executable": "ocrd-keraslm-rate",
        "input_file_grp": [
            "OCR-D-OCR-TESS",
            "OCR-D-OCR-KRAK",
            "OCR-D-OCR-OCRO",
            "OCR-D-OCR-CALA",
            "OCR-D-OCR-ANY",
            "OCR-D-COR-CIS",
            "OCR-D-COR-ASV"
        ],
        "output_file_grp": [
            "OCR-D-COR-LM"
        ],
        "parameters": {
            "alternative_decoding": {
                "default": true,
                "description": "whether to process all TextEquiv alternatives, finding the best path via beam search, and delete each non-best alternative",
                "type": "boolean"
            },
            "beam_width": {
                "default": 10,
                "description": "maximum number of best partial paths to consider during search with alternative_decoding",
                "format": "integer",
                "type": "number"
            },
            "lm_weight": {
                "default": 0.5,
                "description": "share of the LM scores over the input confidences",
                "format": "float",
                "type": "number"
            },
            "model_file": {
                "cacheable": true,
                "content-type": "application/x-hdf;subtype=bag",
                "description": "path of h5py weight/config file for model trained with keraslm",
                "format": "uri",
                "required": true,
                "type": "string"
            },
            "textequiv_level": {
                "default": "glyph",
                "description": "PAGE XML hierarchy level to evaluate TextEquiv sequences on",
                "enum": [
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-kraken-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Binarize images with kraken",
        "executable": "ocrd-kraken-binarize",
        "input_file_grp": "OCR-D-IMG",
        "output_file_grp": "OCR-D-IMG-BIN",
        "parameters": {
            "level-of-operation": {
                "default": "page",
                "description": "level-of-operation",
                "enum": [
                    "page",
                    "block",
                    "line"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-kraken-recognize": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "OCR with kraken",
        "executable": "ocrd-kraken-recognize",
        "parameters": {
            "bidi_reordering": {
                "default": true,
                "description": "Reorder classes in the ocr_record according to  the Unicode bidirectional algorithm for correct display.",
                "type": "boolean"
            },
            "device": {
                "default": "cpu",
                "description": "CUDA ID (e.g. 'cuda:0') for computation on GPU, or 'cpu' to run on CPU only",
                "type": "string"
            },
            "model": {
                "cacheable": true,
                "content-type": "application/python-cpickle",
                "default": "en_best.mlmodel",
                "description": "OCR model to recognize with",
                "format": "uri",
                "type": "string"
            },
            "pad": {
                "default": 16,
                "description": "Extra blank padding to the left and right of text line.",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "recognition/text-recognition"
        ]
    },
    "ocrd-kraken-segment": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Block segmentation with kraken",
        "executable": "ocrd-kraken-segment",
        "parameters": {
            "black_colseps": {
                "default": false,
                "description": "Whether column separators are assumed to be vertical black lines or not",
                "type": "boolean"
            },
            "blla_model": {
                "cacheable": true,
                "content-type": "application/python-cpickle",
                "default": "blla.mlmodel",
                "description": "Model used for baseline detection. Use kraken-provided model if not give. Ignored if use_legacy.",
                "format": "uri",
                "type": "string"
            },
            "device": {
                "default": "cpu",
                "description": "GPU ID or 'cpu' to run on CPU only",
                "type": "string"
            },
            "maxcolseps": {
                "default": 2,
                "description": "Maximum number of column separators. Set to 0 for single-column text to avoid unnecessary computation.",
                "format": "integer",
                "type": "number"
            },
            "remove_hlines": {
                "default": true,
                "description": "Remove horizontal colseps before segmentation",
                "type": "boolean"
            },
            "scale": {
                "default": 0,
                "description": "mean xheight size of glyphs (guessed if zero)",
                "format": "float",
                "type": "number"
            },
            "text_direction": {
                "default": "horizontal-lr",
                "description": "Sets principal text direction",
                "enum": [
                    "horizontal-lr",
                    "horizontal-rl",
                    "vertical-lr",
                    "vertical-rl"
                ],
                "type": "string"
            },
            "use_legacy": {
                "default": false,
                "description": "Use legacy box segmenter as opposed to neural net baseline segmenter",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-ocropy-segment": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Segment page",
        "executable": "ocrd-ocropy-segment",
        "input_file_grp": [
            "OCR-D-IMG-BIN"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "csminaspect": {
                "default": 1.1,
                "description": "has an effect",
                "type": "number"
            },
            "csminheight": {
                "default": 10,
                "description": "has an effect",
                "type": "number"
            },
            "expand": {
                "default": 3,
                "description": "has an effect",
                "type": "number"
            },
            "hscale": {
                "default": 1.0,
                "description": "has an effect",
                "type": "number"
            },
            "maxcolseps": {
                "default": 3,
                "description": "has an effect",
                "type": "number"
            },
            "maxseps": {
                "default": 0,
                "description": "has an effect",
                "type": "number"
            },
            "noise": {
                "default": 8,
                "description": "has an effect",
                "type": "number"
            },
            "pad": {
                "default": 3,
                "description": "has an effect",
                "type": "number"
            },
            "scale": {
                "default": 0.0,
                "description": "has an effect",
                "type": "number"
            },
            "sepwiden": {
                "default": 10,
                "description": "has an effect",
                "type": "number"
            },
            "threshold": {
                "default": 0.2,
                "description": "has an effect",
                "type": "number"
            },
            "usegauss": {
                "default": false,
                "description": "has an effect",
                "type": "boolean"
            },
            "vscale": {
                "default": 1.0,
                "description": "has an effect",
                "type": "number"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-olena-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "popular binarization algorithms implemented by Olena/SCRIBO, wrapped for OCR-D (on page level only)",
        "executable": "ocrd-olena-binarize",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE",
            "OCR-D-SEG-WORD",
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE",
            "OCR-D-SEG-WORD"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero",
                "format": "float",
                "type": "number"
            },
            "impl": {
                "default": "sauvola-ms-split",
                "description": "The name of the actual binarization algorithm",
                "enum": [
                    "sauvola",
                    "sauvola-ms",
                    "sauvola-ms-fg",
                    "sauvola-ms-split",
                    "kim",
                    "wolf",
                    "niblack",
                    "singh",
                    "otsu"
                ],
                "type": "string"
            },
            "k": {
                "default": 0.34,
                "description": "Sauvola's formulae parameter (foreground weight decreases with k); for Multiscale, multiplied to yield default 0.2/0.3/0.5; for Singh, multiplied to yield default 0.06; for Niblack, multiplied to yield default -0.2; for Wolf/Kim, used directly; for Otsu, does not apply",
                "format": "float",
                "type": "number"
            },
            "win-size": {
                "default": 0,
                "description": "The (odd) window size in pixels; when zero (default), set to DPI (or 301); for Otsu, does not apply",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-page2tei": {
        "description": "Convert PAGE-XML to TEI-C",
        "executable": "ocrd-page2tei",
        "parameters": {}
    },
    "ocrd-pagetopdf": {
        "categories": [
            "Long-term preservation"
        ],
        "description": "Convert text and layout annotations to PDF format (overlaying original image with text layer and polygon outlines)",
        "executable": "ocrd-pagetopdf",
        "input_file_grp": [
            "OCR-D-OCR-PAGE"
        ],
        "output_file_grp": [
            "OCR-D-OCR-PDF"
        ],
        "parameters": {
            "ext": {
                "default": ".pdf",
                "description": "Output filename extension",
                "type": "string"
            },
            "font": {
                "content-type": "application/x-font-ttf",
                "default": "",
                "description": "Font file to be used in PDF file. If unset, AletheiaSans.ttf is used. (Make sure to pick a font which covers all glyphs!)",
                "format": "uri",
                "type": "string"
            },
            "multipage": {
                "default": "",
                "description": "Merge all PDFs into one mulitpage file. The value is used as filename for the pdf.",
                "type": "string"
            },
            "negative2zero": {
                "default": false,
                "description": "Set all negative box values to 0",
                "type": "boolean"
            },
            "outlines": {
                "default": "",
                "description": "What segment hierarchy to draw coordinate outlines for. If unset, no outlines are drawn.",
                "enum": [
                    "",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "pagelabel": {
                "default": "pageId",
                "description": "Parameter for 'multipage': Set the page information, which will be used as pagelabel. Default is 'pageId', e.g. the option 'pagenumber' will create numbered pagelabel consecutively",
                "enum": [
                    "pagenumber",
                    "pageId",
                    "basename",
                    "basename_without_extension",
                    "local_filename",
                    "ID",
                    "url"
                ],
                "type": "string"
            },
            "script-args": {
                "default": "",
                "description": "Extra arguments to PageToPdf (see https://github.com/PRImA-Research-Lab/prima-page-to-pdf)",
                "type": "string"
            },
            "textequiv_level": {
                "default": "",
                "description": "What segment hierarchy level to render text output from. If unset, no text is rendered.",
                "enum": [
                    "",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            }
        },
        "steps": [
            "postprocessing/format-conversion"
        ]
    },
    "ocrd-pc-segmentation": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment page into regions using a pixel classifier based on a Fully Convolutional Network (FCN)",
        "executable": "ocrd-pc-segmentation",
        "input_file_grp": [
            "OCR-D-IMG-BIN"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "gpu_allow_growth": {
                "default": false,
                "description": "required for GPU use with some graphic cards (set to true, if you get CUDNN_INTERNAL_ERROR)",
                "type": "boolean"
            },
            "model": {
                "default": "__DEFAULT__",
                "description": "trained model for pixel classifier",
                "type": "string"
            },
            "overwrite_regions": {
                "default": true,
                "description": "remove existing layout and text annotation below the Page level",
                "type": "boolean"
            },
            "resize_height": {
                "default": 300,
                "description": "scale down pixelclassifier output to this height for postprocessing (performance/quality tradeoff). Independent of training.",
                "type": "integer"
            },
            "xheight": {
                "default": 8,
                "description": "height of character x in pixels used during training",
                "type": "integer"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-preprocess-image": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Convert or enhance images",
        "executable": "ocrd-preprocess-image",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "command": {
                "description": "shell command to operate on image files, with @INFILE as place-holder for the input file path, and @OUTFILE as place-holder for the output file path",
                "required": true,
                "type": "string"
            },
            "input_feature_filter": {
                "default": "",
                "description": "comma-separated list of forbidden image features (e.g. binarized,despeckled)",
                "type": "string"
            },
            "input_feature_selector": {
                "default": "",
                "description": "comma-separated list of required image features (e.g. binarized,despeckled)",
                "type": "string"
            },
            "input_mimetype": {
                "default": "image/png",
                "description": "File format to save input images to (tool's expected input)",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "output_feature_added": {
                "description": "image feature(s) to be added after this operation (if multiple, separate by comma)",
                "required": true,
                "type": "string"
            },
            "output_mimetype": {
                "default": "image/png",
                "description": "File format to load output images from (tool's expected output)",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization"
        ]
    },
    "ocrd-repair-inconsistencies": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Re-order glyphs/words/lines top-down-left-right when textually inconsistent with their parents",
        "executable": "ocrd-repair-inconsistencies",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK-FIXED"
        ],
        "steps": [
            "layout/segmentation/line",
            "layout/segmentation/word",
            "layout/segmentation/glyph"
        ]
    },
    "ocrd-sbb-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Pixelwise binarization with selectional auto-encoders in Keras",
        "executable": "ocrd-sbb-binarize",
        "input_file_grp": [],
        "output_file_grp": [],
        "parameters": {
            "model": {
                "description": "Directory containing HDF5 models. Can be an absolute path or a path relative to the current working directory or $SBB_BINARIZE_DATA environment variable (if set)",
                "required": true,
                "type": "string"
            },
            "operation_level": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-sbb-textline-detector": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Printspace, region and textline detection",
        "executable": "ocrd-sbb-textline-detector",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-SBB-SEG-LINE"
        ],
        "parameters": {
            "model": {
                "cacheable": true,
                "description": "Path to directory containing models to be used (See https://qurator-data.de/sbb_textline_detector/)",
                "format": "file",
                "type": "string"
            }
        },
        "steps": [
            "layout/segmentation/region",
            "layout/segmentation/line"
        ]
    },
    "ocrd-segment-evaluate": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Compare segmentations",
        "executable": "ocrd-segment-evaluate",
        "input_file_grp": [
            "OCR-D-GT-SEG-BLOCK",
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "for-categories": {
                "default": "",
                "description": "on region level, only compare these region types (comma-separated list; unless `ignore-subtype` is given, append subtypes via `.`; e.g. `TextRegion.page-number,TextRegion.marginalia`)",
                "type": "string"
            },
            "ignore-subtype": {
                "default": false,
                "description": "on region level, ignore @type differentiation (where applicable)",
                "type": "boolean"
            },
            "level-of-operation": {
                "default": "region",
                "description": "segment hierarchy level to compare GT and predictions at",
                "enum": [
                    "region",
                    "line"
                ],
                "type": "string"
            },
            "only-fg": {
                "default": false,
                "description": "only overlap and compare the foregrounds in the binarized image",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-extract-glyphs": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Extract glyph segmentation as glyph images (deskewed according to `*/@orientation` and cropped+masked along `*/Coords` polygon and dewarped as in `*/AlternativeImage`) + text file (according to `*/TextEquiv`) + JSON (including line coordinates and meta-data).",
        "executable": "ocrd-segment-extract-glyphs",
        "input_file_grp": [
            "OCR-D-SEG-GLYPH",
            "OCR-D-GT-SEG-GLYPH"
        ],
        "output_file_grp": [
            "OCR-D-IMG-GLYPH"
        ],
        "parameters": {
            "feature_filter": {
                "default": "",
                "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`).",
                "type": "string"
            },
            "library-convention": {
                "default": "none",
                "description": "For xlsx extraction, to make line images hyperlinked, use this scheme in reconstructing presentation URLs of original pages. Libraries have different conventions in their METS files. Set to none to disable.",
                "enum": [
                    "slub",
                    "sbb",
                    "none"
                ],
                "type": "string"
            },
            "mimetype": {
                "default": "image/png",
                "description": "File format to save extracted images in.",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            },
            "min-line-height": {
                "default": 30,
                "description": "Only extract lines that are at least this high (in px).",
                "type": "number"
            },
            "min-line-length": {
                "default": 5,
                "description": "Only extract lines with at least this many characters.",
                "type": "number"
            },
            "min-line-width": {
                "default": 200,
                "description": "Only extract lines that are at least this wide (in px).",
                "type": "number"
            },
            "output-types": {
                "default": [
                    "text",
                    "json",
                    "xslx"
                ],
                "description": "What kind of files to extract besides the line image itself (text/json files for  each line, xlsx per page).",
                "items": {
                    "enum": [
                        "text",
                        "json",
                        "xslx"
                    ],
                    "type": "string"
                },
                "type": "array"
            },
            "transparency": {
                "default": true,
                "description": "Add alpha channels with segment masks to the images",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-extract-lines": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Extract line segmentation as line images + text file + JSON.",
        "executable": "ocrd-segment-extract-lines",
        "input_file_grp": [
            "OCR-D-SEG-LINE",
            "OCR-D-GT-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-LINE"
        ],
        "parameters": {
            "feature_filter": {
                "default": "",
                "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`).",
                "type": "string"
            },
            "mimetype": {
                "default": "image/png",
                "description": "File format to save extracted images in.",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            },
            "transparency": {
                "default": true,
                "description": "Add alpha channels with segment masks to the images",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-extract-pages": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Extract page segmentation as page images (deskewed according to `/Page/@orientation` and cropped+masked along `/Page/Border`) + JSON (including region coordinates/classes and meta-data), as binarized images, and as mask images (segments filled with colors encoding classes) + COCO detection format JSON (for all pages). Output fileGrp format is `raw[,binarized[,mask]]` (i.e. fall back to first group).",
        "executable": "ocrd-segment-extract-pages",
        "input_file_grp": [
            "OCR-D-SEG-PAGE",
            "OCR-D-GT-SEG-PAGE",
            "OCR-D-SEG-BLOCK",
            "OCR-D-GT-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-IMG-PAGE"
        ],
        "parameters": {
            "colordict": {
                "default": {
                    "": "FFFFFF00",
                    "AdvertRegion": "4682B4FF",
                    "Border": "FFFFFFFF",
                    "ChartRegion": "800080FF",
                    "ChartRegion:bar": "800080FA",
                    "ChartRegion:line": "800080F5",
                    "ChartRegion:other": "800080E1",
                    "ChartRegion:pie": "800080F0",
                    "ChartRegion:scatter": "800080EB",
                    "ChartRegion:surface": "800080E6",
                    "ChemRegion": "FF8C00FF",
                    "CustomRegion": "637C81FF",
                    "Glyph": "2E8B08FF",
                    "GraphicRegion": "008000FF",
                    "GraphicRegion:barcode": "008000D2",
                    "GraphicRegion:decoration": "008000EB",
                    "GraphicRegion:frame": "008000E6",
                    "GraphicRegion:handwritten-annotation": "008000E1",
                    "GraphicRegion:letterhead": "008000F0",
                    "GraphicRegion:logo": "008000FA",
                    "GraphicRegion:other": "008000C3",
                    "GraphicRegion:paper-grow": "008000CD",
                    "GraphicRegion:punch-hole": "008000C8",
                    "GraphicRegion:signature": "008000D7",
                    "GraphicRegion:stamp": "008000DC",
                    "ImageRegion": "00CED1FF",
                    "LineDrawingRegion": "B8860BFF",
                    "MapRegion": "9ACDD2FF",
                    "MathsRegion": "00BFFFFF",
                    "MusicRegion": "9400D3FF",
                    "NoiseRegion": "FF0000FF",
                    "ReadingOrderLevel0": "DC143CFF",
                    "ReadingOrderLevel1": "9400D3FF",
                    "ReadingOrderLevelN": "8B0000FF",
                    "SeparatorRegion": "FF00FFFF",
                    "TableRegion": "8B4513FF",
                    "TextLine": "32CD32FF",
                    "TextRegion": "0000FFFF",
                    "TextRegion:TOC-entry": "0000FFAF",
                    "TextRegion:caption": "0000FFF0",
                    "TextRegion:catch-word": "0000FFC8",
                    "TextRegion:credit": "0000FFD7",
                    "TextRegion:drop-capital": "0000FFDC",
                    "TextRegion:endnote": "0000FFB4",
                    "TextRegion:floating": "0000FFD2",
                    "TextRegion:footer": "0000FFE6",
                    "TextRegion:footnote": "0000FFBE",
                    "TextRegion:footnote-continued": "0000FFB9",
                    "TextRegion:header": "0000FFEB",
                    "TextRegion:heading": "0000FFF5",
                    "TextRegion:list-label": "0000FFA5",
                    "TextRegion:marginalia": "0000FFC3",
                    "TextRegion:other": "0000FFA0",
                    "TextRegion:page-number": "0000FFE1",
                    "TextRegion:paragraph": "0000FFFA",
                    "TextRegion:signature-mark": "0000FFCD",
                    "UnknownRegion": "646464FF",
                    "Word": "B22222FF"
                },
                "description": "Mapping from segment types to extract to color values in the output mask images and COCO; color must be encoded hexadecimal (e.g. '00FF00'); region type equals the element name in PAGE-XML, optionally followed by a colon and a subtype (e.g. 'TextRegion:paragraph'; unmapped region types will be ignored (i.e. treated as background)). Default is PageViewer color scheme. Cf. colordict parameter of ocrd-segment-from-masks.",
                "type": "object"
            },
            "feature_filter": {
                "default": "",
                "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`).",
                "type": "string"
            },
            "mimetype": {
                "default": "image/png",
                "description": "File format to save extracted images in.",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            },
            "plot_overlay": {
                "default": false,
                "description": "When generating mask images with `plot_segmasks`, instead of starting with a blank image and having layers and segments replace each other, start with the raw image and superimpose (alpha-composite) layers and segments.",
                "type": "boolean"
            },
            "plot_segmasks": {
                "default": [
                    "region"
                ],
                "description": "Generate mask images of the page segmentation in the last output fileGrp. Draw filled polygons for each specified PAGE hierarchy level in the list (in that order), where 'page' denotes the Border polygon, 'region' denotes Region types, 'line' denotes TextLine, 'word' denotes Word and 'glyph' denotes Glyph. Each type must be mapped in `colordict`. Where neighbors of the same type intersect, show a warning (unless `plot_overlay` is true). If 'order' is present, then draw arrows for reading order, too.",
                "items": {
                    "enum": [
                        "order",
                        "page",
                        "region",
                        "line",
                        "word",
                        "glyph"
                    ],
                    "type": "string"
                },
                "type": "array"
            },
            "transparency": {
                "default": true,
                "description": "Add alpha channels with segment masks to the images",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-extract-regions": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Extract region segmentation as region images (deskewed according to `*/@orientation` and cropped+masked along `*/Coords` polygon) + JSON (including region coordinates/classes and meta-data).",
        "executable": "ocrd-segment-extract-regions",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-GT-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-IMG-REGION"
        ],
        "parameters": {
            "feature_filter": {
                "default": "",
                "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`).",
                "type": "string"
            },
            "mimetype": {
                "default": "image/png",
                "description": "File format to save extracted images in.",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            },
            "transparency": {
                "default": true,
                "description": "Add alpha channels with segment masks to the images",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-extract-words": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Extract word segmentation as word images (deskewed according to `*/@orientation` and cropped+masked along `*/Coords` polygon and dewarped as in `*/AlternativeImage`) + text file (according to `*/TextEquiv`) + JSON (including line coordinates and meta-data).",
        "executable": "ocrd-segment-extract-words",
        "input_file_grp": [
            "OCR-D-SEG-WORD",
            "OCR-D-GT-SEG-WORD"
        ],
        "output_file_grp": [
            "OCR-D-IMG-WORD"
        ],
        "parameters": {
            "feature_filter": {
                "default": "",
                "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`).",
                "type": "string"
            },
            "library-convention": {
                "default": "none",
                "description": "For xlsx extraction, to make line images hyperlinked, use this scheme in reconstructing presentation URLs of original pages. Libraries have different conventions in their METS files. Set to none to disable.",
                "enum": [
                    "slub",
                    "sbb",
                    "none"
                ],
                "type": "string"
            },
            "mimetype": {
                "default": "image/png",
                "description": "File format to save extracted images in.",
                "enum": [
                    "image/bmp",
                    "application/postscript",
                    "image/gif",
                    "image/jpeg",
                    "image/jp2",
                    "image/png",
                    "image/x-portable-pixmap",
                    "image/tiff"
                ],
                "type": "string"
            },
            "min-line-height": {
                "default": 30,
                "description": "Only extract lines that are at least this high (in px).",
                "type": "number"
            },
            "min-line-length": {
                "default": 5,
                "description": "Only extract lines with at least this many characters.",
                "type": "number"
            },
            "min-line-width": {
                "default": 200,
                "description": "Only extract lines that are at least this wide (in px).",
                "type": "number"
            },
            "output-types": {
                "default": [
                    "text",
                    "json",
                    "xslx"
                ],
                "description": "What kind of files to extract besides the line image itself (text/json files for  each line, xlsx per page).",
                "items": {
                    "enum": [
                        "text",
                        "json",
                        "xslx"
                    ],
                    "type": "string"
                },
                "type": "array"
            },
            "transparency": {
                "default": true,
                "description": "Add alpha channels with segment masks to the images",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-from-coco": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Import region segmentation from COCO detection format JSON (for all pages). Input fileGrp format is `base,COCO` (i.e. PAGE or original image files first, COCO file second).",
        "executable": "ocrd-segment-from-coco",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {},
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-segment-from-masks": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Import region segmentation from mask images (segments filled with colors encoding classes). Input fileGrp format is `base,mask` (i.e. PAGE or original image files first, mask image files second).",
        "executable": "ocrd-segment-from-masks",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "colordict": {
                "default": {
                    "0000FFA0": "TextRegion:other",
                    "0000FFA5": "TextRegion:list-label",
                    "0000FFAF": "TextRegion:TOC-entry",
                    "0000FFB4": "TextRegion:endnote",
                    "0000FFB9": "TextRegion:footnote-continued",
                    "0000FFBE": "TextRegion:footnote",
                    "0000FFC3": "TextRegion:marginalia",
                    "0000FFC8": "TextRegion:catch-word",
                    "0000FFCD": "TextRegion:signature-mark",
                    "0000FFD2": "TextRegion:floating",
                    "0000FFD7": "TextRegion:credit",
                    "0000FFDC": "TextRegion:drop-capital",
                    "0000FFE1": "TextRegion:page-number",
                    "0000FFE6": "TextRegion:footer",
                    "0000FFEB": "TextRegion:header",
                    "0000FFF0": "TextRegion:caption",
                    "0000FFF5": "TextRegion:heading",
                    "0000FFFA": "TextRegion:paragraph",
                    "0000FFFF": "TextRegion",
                    "008000C3": "GraphicRegion:other",
                    "008000C8": "GraphicRegion:punch-hole",
                    "008000CD": "GraphicRegion:paper-grow",
                    "008000D2": "GraphicRegion:barcode",
                    "008000D7": "GraphicRegion:signature",
                    "008000DC": "GraphicRegion:stamp",
                    "008000E1": "GraphicRegion:handwritten-annotation",
                    "008000E6": "GraphicRegion:frame",
                    "008000EB": "GraphicRegion:decoration",
                    "008000F0": "GraphicRegion:letterhead",
                    "008000FA": "GraphicRegion:logo",
                    "008000FF": "GraphicRegion",
                    "00BFFFFF": "MathsRegion",
                    "00CED1FF": "ImageRegion",
                    "4682B4FF": "AdvertRegion",
                    "637C81FF": "CustomRegion",
                    "646464FF": "UnknownRegion",
                    "800080E1": "ChartRegion:other",
                    "800080E6": "ChartRegion:surface",
                    "800080EB": "ChartRegion:scatter",
                    "800080F0": "ChartRegion:pie",
                    "800080F5": "ChartRegion:line",
                    "800080FA": "ChartRegion:bar",
                    "800080FF": "ChartRegion",
                    "8B4513FF": "TableRegion",
                    "9400D3FF": "MusicRegion",
                    "9ACDD2FF": "MapRegion",
                    "B8860BFF": "LineDrawingRegion",
                    "FF0000FF": "NoiseRegion",
                    "FF00FFFF": "SeparatorRegion",
                    "FF8C00FF": "ChemRegion",
                    "FFFFFF00": "",
                    "FFFFFFFF": "Border"
                },
                "description": "Mapping from color values in the input masks to region types to annotate; color must be encoded hexadecimal (e.g. '00FF00'); region type equals the element name in PAGE-XML, optionally followed by a colon and a subtype (e.g. 'TextRegion:paragraph'; unmapped colors will be ignored (i.e. treated as background)). Default is PageViewer color scheme. Cf. colordict.json output and colordict parameter of ocrd-segment-extract-pages.",
                "type": "object"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-segment-project": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Project segment coordinates to their structural parents",
        "executable": "ocrd-segment-project",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "level-of-operation": {
                "default": "page",
                "description": "hierarchy level which to assign new coordinates to",
                "enum": [
                    "page",
                    "region",
                    "line",
                    "word"
                ],
                "type": "string"
            },
            "padding": {
                "default": 10,
                "description": "margin (in px) to extend the hull in every direction",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "layout/segmentation"
        ]
    },
    "ocrd-segment-repair": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Analyse and repair region segmentation; at least ensure validity and consistency of coordinates.",
        "executable": "ocrd-segment-repair",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "plausibilize": {
                "default": false,
                "description": "Identify and remove redundancies on text regions and text lines (deleting/merging/shrinking where overlaps occur).",
                "type": "boolean"
            },
            "plausibilize_merge_min_overlap": {
                "default": 0.9,
                "description": "When merging a region or line almost contained in another, require at least this ratio of area is shared with the other.",
                "format": "float",
                "type": "number"
            },
            "sanitize": {
                "default": false,
                "description": "Shrink/expand each text region such that its coordinates become the convex hull of its constituent text lines.",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-segment-replace-original": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Extract page image (deskewed according to `/Page/@orientation` and cropped+masked along `/Page/Border`) and use it as @imageFilename, adjusting all coordinates",
        "executable": "ocrd-segment-replace-original",
        "input_file_grp": [
            "OCR-D-SEG-LINE",
            "OCR-D-GT-SEG-LINE",
            "OCR-D-OCR"
        ],
        "output_file_grp": [
            "OCR-D-SEG-CROP"
        ],
        "parameters": {
            "feature_filter": {
                "default": "",
                "description": "Comma-separated list of forbidden image features (e.g. `binarized,despeckled`)",
                "type": "string"
            },
            "feature_selector": {
                "default": "",
                "description": "Comma-separated list of required image features (e.g. `binarized,despeckled`)",
                "type": "string"
            },
            "transform_coordinates": {
                "default": true,
                "description": "re-calculate coordinates for all segments of the structural hierarchy to be consistent with the coordinate system of the chosen image again (vital after cropping, deskewing etc; disable only if input coordinates must be assumed to be inconsistent with the original)",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-segment-replace-page": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Replace everything below page level with another annotation, adjusting all coordinates",
        "executable": "ocrd-segment-replace-page",
        "input_file_grp": [
            "OCR-D-SEG-LINE",
            "OCR-D-GT-SEG-LINE",
            "OCR-D-OCR"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE",
            "OCR-D-OCR"
        ],
        "parameters": {
            "transform_coordinates": {
                "default": true,
                "description": "re-calculate coordinates for all segments of the structural hierarchy to be consistent with the coordinate system of the first input file group (vital after cropping, deskewing etc; disable only if input coordinates can be assumed to be consistent with the second input file group)",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/analysis"
        ]
    },
    "ocrd-skimage-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Binarize images with Scikit-image",
        "executable": "ocrd-skimage-binarize",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-BIN",
            "OCR-D-SEG-PAGE-BIN",
            "OCR-D-SEG-REGION-BIN",
            "OCR-D-SEG-LINE-BIN"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero",
                "format": "float",
                "type": "number"
            },
            "k": {
                "default": 0.34,
                "description": "For Sauvola/Niblack, formula parameter influencing the threshold bias; larger is lighter foreground",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "method": {
                "default": "sauvola",
                "description": "Thresholding algorithm to use",
                "enum": [
                    "sauvola",
                    "niblack",
                    "otsu",
                    "gauss",
                    "yen",
                    "li"
                ],
                "type": "string"
            },
            "window_size": {
                "default": 0,
                "description": "For Sauvola/Niblack/Gauss, the (odd) window size in pixels; when zero (default), set to DPI",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-skimage-denoise": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Denoise binarized images with Scikit-image",
        "executable": "ocrd-skimage-denoise",
        "input_file_grp": [
            "OCR-D-IMG-BIN",
            "OCR-D-SEG-PAGE-BIN",
            "OCR-D-SEG-REGION-BIN",
            "OCR-D-SEG-LINE-BIN"
        ],
        "output_file_grp": [
            "OCR-D-IMG-DEN",
            "OCR-D-SEG-PAGE-DEN",
            "OCR-D-SEG-REGION-DEN",
            "OCR-D-SEG-LINE-DEN"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "maxsize": {
                "default": 1.0,
                "description": "maximum component size of (bg holes or fg specks) noise in pt",
                "format": "float",
                "type": "number"
            },
            "protect": {
                "default": 0.0,
                "description": "avoid removing fg specks near larger fg components by up to this distance in pt",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/despeckling"
        ]
    },
    "ocrd-skimage-denoise-raw": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Denoise raw images with Scikit-image",
        "executable": "ocrd-skimage-denoise-raw",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-DEN",
            "OCR-D-SEG-PAGE-DEN",
            "OCR-D-SEG-REGION-DEN",
            "OCR-D-SEG-LINE-DEN"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "method": {
                "default": "VisuShrink",
                "description": "Wavelet filtering scheme to use",
                "enum": [
                    "BayesShrink",
                    "VisuShrink"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization/despeckling"
        ]
    },
    "ocrd-skimage-normalize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Equalize contrast/exposure of images with Scikit-image; stretches the color value/tone to the full dynamic range",
        "executable": "ocrd-skimage-normalize",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-IMG-NRM",
            "OCR-D-SEG-PAGE-NRM",
            "OCR-D-SEG-REGION-NRM",
            "OCR-D-SEG-LINE-NRM"
        ],
        "parameters": {
            "black-point": {
                "default": 1.0,
                "description": "black point point in percent of luminance/value/tone histogram; up to ``black-point`` darkest pixels will be clipped to black when stretching",
                "format": "float",
                "type": "number"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when zero",
                "format": "float",
                "type": "number"
            },
            "level-of-operation": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line",
                    "word",
                    "glyph"
                ],
                "type": "string"
            },
            "method": {
                "default": "stretch",
                "description": "contrast-enhancing transformation to use after clipping; ``stretch`` uses ``skimage.exposure.rescale_intensity`` (globally linearly stretching to full dynamic range) and ``adapthist`` uses ``skimage.exposure.equalize_adapthist`` (applying over tiles with context from 1/8th of the image's width)",
                "enum": [
                    "stretch",
                    "adapthist"
                ],
                "type": "string"
            },
            "white-point": {
                "default": 7.0,
                "description": "white point in percent of luminance/value/tone histogram; up to ``white-point`` brightest pixels will be clipped to white when stretching",
                "format": "float",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization"
        ]
    },
    "ocrd-tesserocr-binarize": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Binarize regions or lines with Tesseract's global Otsu",
        "executable": "ocrd-tesserocr-binarize",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-BLOCK",
            "OCR-D-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-BIN-BLOCK",
            "OCR-D-BIN-LINE"
        ],
        "parameters": {
            "operation_level": {
                "default": "page",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization/binarization"
        ]
    },
    "ocrd-tesserocr-crop": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Poor man's cropping via region segmentation",
        "executable": "ocrd-tesserocr-crop",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-SEG-PAGE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "padding": {
                "default": 4,
                "description": "extend detected border by this many (true) pixels on every side",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "preprocessing/optimization/cropping"
        ]
    },
    "ocrd-tesserocr-deskew": {
        "categories": [
            "Image preprocessing"
        ],
        "description": "Detect script, orientation and skew angle for pages or regions",
        "executable": "ocrd-tesserocr-deskew",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-DESKEW-BLOCK"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "min_orientation_confidence": {
                "default": 1.5,
                "description": "Minimum confidence score to apply orientation as detected by OSD",
                "format": "float",
                "type": "number"
            },
            "operation_level": {
                "default": "region",
                "description": "PAGE XML hierarchy level to operate on",
                "enum": [
                    "page",
                    "region",
                    "line"
                ],
                "type": "string"
            }
        },
        "steps": [
            "preprocessing/optimization/deskewing"
        ]
    },
    "ocrd-tesserocr-fontshape": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Recognize font shapes (family/monospace/bold/italic) and size in segmented words with Tesseract (using annotated derived images, or masking and cropping images from coordinate polygons), annotating TextStyle",
        "executable": "ocrd-tesserocr-fontshape",
        "input_file_grp": [
            "OCR-D-SEG-WORD",
            "OCR-D-OCR"
        ],
        "output_file_grp": [
            "OCR-D-OCR-FONTSTYLE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "model": {
                "default": "osd",
                "description": "tessdata model to apply (an ISO 639-3 language specification or some other basename, e.g. deu-frak or osd); must be an old (pre-LSTM) model",
                "type": "string"
            },
            "padding": {
                "default": 0,
                "description": "Number of background-filled pixels to add around the word image (i.e. the annotated AlternativeImage if it exists or the higher-level image cropped to the bounding box and masked by the polygon otherwise) on each side before recognition.",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "recognition/font-identification"
        ]
    },
    "ocrd-tesserocr-recognize": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Segment and/or recognize text with Tesseract (using annotated derived images, or masking and cropping images from coordinate polygons) on any level of the PAGE hierarchy.",
        "executable": "ocrd-tesserocr-recognize",
        "input_file_grp": [
            "OCR-D-SEG-PAGE",
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-TABLE",
            "OCR-D-SEG-LINE",
            "OCR-D-SEG-WORD"
        ],
        "output_file_grp": [
            "OCR-D-SEG-REGION",
            "OCR-D-SEG-TABLE",
            "OCR-D-SEG-LINE",
            "OCR-D-SEG-WORD",
            "OCR-D-SEG-GLYPH",
            "OCR-D-OCR-TESS"
        ],
        "parameters": {
            "auto_model": {
                "default": false,
                "description": "Prefer models performing best (by confidence) per segment (if multiple given in `model`). Repeats the OCR of the best model once (i.e. slower). (Use as a fallback to xpath_model if you do not trust script/language detection.)",
                "type": "boolean"
            },
            "block_polygons": {
                "default": false,
                "description": "When detecting regions, annotate polygon coordinates instead of bounding box rectangles by querying Tesseract accordingly.",
                "type": "boolean"
            },
            "char_blacklist": {
                "default": "",
                "description": "When recognizing text, enumeration of character hypotheses (from the model) to suppress; overruled by unblacklist if set.",
                "type": "string"
            },
            "char_unblacklist": {
                "default": "",
                "description": "When recognizing text, enumeration of character hypotheses (from the model) to allow inclusively.",
                "type": "string"
            },
            "char_whitelist": {
                "default": "",
                "description": "When recognizing text, enumeration of character hypotheses (from the model) to allow exclusively; overruled by blacklist if set.",
                "type": "string"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "find_staves": {
                "default": false,
                "description": "When detecting regions, recognize music staves as non-text, suppressing it in the binary image (Tesseract's ``pageseg_apply_music_mask``). Note that this might wrongly detect tables as staves.",
                "type": "boolean"
            },
            "find_tables": {
                "default": true,
                "description": "When detecting regions, recognise tables as table regions (Tesseract's ``textord_tabfind_find_tables=1``).",
                "type": "boolean"
            },
            "model": {
                "description": "The tessdata text recognition model to apply (an ISO 639-3 language specification or some other basename, e.g. deu-frak or Fraktur).",
                "type": "string"
            },
            "oem": {
                "default": "DEFAULT",
                "description": "Tesseract OCR engine mode to use:\n* Run Tesseract only - fastest,\n* Run just the LSTM line recognizer. (>=v4.00),\n*Run the LSTM recognizer, but allow fallback to Tesseract when things get difficult. (>=v4.00),\n*Run both and combine results - best accuracy.",
                "enum": [
                    "TESSERACT_ONLY",
                    "LSTM_ONLY",
                    "TESSERACT_LSTM_COMBINED",
                    "DEFAULT"
                ],
                "type": "string"
            },
            "overwrite_segments": {
                "default": false,
                "description": "If ``segmentation_level`` is not none, but an element already contains segments, remove them and segment again. Otherwise use the existing segments of that element.",
                "type": "boolean"
            },
            "overwrite_text": {
                "default": true,
                "description": "If ``textequiv_level`` is not none, but a segment already contains TextEquivs, remove them and replace with recognised text. Otherwise add new text as alternative. (Only the first entry is projected upwards.)",
                "type": "boolean"
            },
            "padding": {
                "default": 0,
                "description": "Extend detected region/cell/line/word rectangles by this many (true) pixels, or extend existing region/line/word images (i.e. the annotated AlternativeImage if it exists or the higher-level image cropped to the bounding box and masked by the polygon otherwise) by this many (background/white) pixels on each side before recognition.",
                "format": "integer",
                "type": "number"
            },
            "raw_lines": {
                "default": false,
                "description": "When detecting lines, do not attempt additional segmentation (baseline+xheight+ascenders/descenders prediction) on line images. Can increase accuracy for certain workflows. Disable when line segments/images may contain components of more than 1 line, or larger gaps/white-spaces.",
                "type": "boolean"
            },
            "segmentation_level": {
                "default": "word",
                "description": "Highest PAGE XML hierarchy level to remove existing annotation from and detect segments for (before iterating downwards); if ``none``, does not attempt any new segmentation; if ``cell``, starts at table regions, detecting text regions (cells). Ineffective when lower than ``textequiv_level``.",
                "enum": [
                    "region",
                    "cell",
                    "line",
                    "word",
                    "glyph",
                    "none"
                ],
                "type": "string"
            },
            "shrink_polygons": {
                "default": false,
                "description": "When detecting any segments, annotate polygon coordinates instead of bounding box rectangles by projecting the convex hull of all symbols.",
                "type": "boolean"
            },
            "sparse_text": {
                "default": false,
                "description": "When detecting regions, use 'sparse text' page segmentation mode (finding as much text as possible in no particular order): only text regions, single lines without vertical or horizontal space.",
                "type": "boolean"
            },
            "tesseract_parameters": {
                "default": {},
                "description": "Dictionary of additional Tesseract runtime variables (cf. tesseract --print-parameters), string values.",
                "type": "object"
            },
            "textequiv_level": {
                "default": "word",
                "description": "Lowest PAGE XML hierarchy level to re-use or detect segments for and add the TextEquiv results to (before projecting upwards); if ``none``, adds segmentation down to the glyph level, but does not attempt recognition at all; if ``cell``, stops short before text lines, adding text of text regions inside tables (cells) or on page level only.",
                "enum": [
                    "region",
                    "cell",
                    "line",
                    "word",
                    "glyph",
                    "none"
                ],
                "type": "string"
            },
            "xpath_model": {
                "default": {},
                "description": "Prefer models mapped according to results of XPath queries into the segment. (As a convenience, `@language` and `@script` also match their upwards `@primary*` and `@secondary*` variants where applicable.) If no queries / mappings match (or under the default empty parameter), then fall back to `model`. If there are multiple matches, combine their results. (Example: {'starts-with(@script,\"Latn\")': 'Latin', 'starts-with(@script,\"Grek\")': 'Greek', '@language=\"Latin\"': 'lat', '@language=\"Greek\"': 'grc+ell', 'ancestor::TextRegion/@type=\"page-number\"': 'eng'})",
                "type": "object"
            },
            "xpath_parameters": {
                "default": {},
                "description": "Set additional Tesseract runtime variables according to results of XPath queries into the segment. (As a convenience, `@language` and `@script` also match their upwards `@primary*` and `@secondary*` variants where applicable.) (Example: {'ancestor::TextRegion/@type=\"page-number\"': {'char_whitelist': '0123456789-'}, 'contains(@custom,\"ISBN\")': {'char_whitelist': '0123456789-'}})",
                "type": "object"
            }
        },
        "resource_locations": [
            "data",
            "system",
            "module"
        ],
        "resources": [
            {
                "description": "Tesseract LSTM model trained on GT4HistOCR",
                "name": "Fraktur_GT4HistOCR.traineddata",
                "parameter_usage": "without-extension",
                "size": 1058487,
                "url": "https://ub-backup.bib.uni-mannheim.de/~stweil/ocrd-train/data/Fraktur_5000000/tessdata_fast/Fraktur_50000000.334_450937.traineddata"
            },
            {
                "description": "Tesseract LSTM model based on Austrian National Library newspaper data",
                "name": "ONB.traineddata",
                "parameter_usage": "without-extension",
                "size": 4358948,
                "url": "https://ub-backup.bib.uni-mannheim.de/~stweil/ocrd-train/data/ONB/tessdata_best/ONB_1.195_300718_989100.traineddata"
            },
            {
                "description": "Tesseract equ model",
                "name": "equ.traineddata",
                "parameter_usage": "without-extension",
                "size": 2251950,
                "url": "https://github.com/tesseract-ocr/tessdata_fast/raw/main/equ.traineddata"
            },
            {
                "description": "Tesseract osd model",
                "name": "osd.traineddata",
                "parameter_usage": "without-extension",
                "size": 10562727,
                "url": "https://github.com/tesseract-ocr/tessdata_fast/raw/main/osd.traineddata"
            },
            {
                "description": "Tesseract eng model",
                "name": "eng.traineddata",
                "parameter_usage": "without-extension",
                "size": 4113088,
                "url": "https://github.com/tesseract-ocr/tessdata_fast/raw/main/eng.traineddata"
            },
            {
                "description": "Tesseract deu model",
                "name": "deu.traineddata",
                "parameter_usage": "without-extension",
                "size": 1525436,
                "url": "https://github.com/tesseract-ocr/tessdata_fast/raw/main/deu.traineddata"
            },
            {
                "description": "Tesseract frk model",
                "name": "frk.traineddata",
                "parameter_usage": "without-extension",
                "size": 6423052,
                "url": "https://github.com/tesseract-ocr/tessdata_fast/raw/main/frk.traineddata"
            },
            {
                "description": "Tesseract Fraktur model",
                "name": "Fraktur.traineddata",
                "parameter_usage": "without-extension",
                "size": 10915632,
                "url": "https://github.com/tesseract-ocr/tessdata_fast/raw/main/script/Fraktur.traineddata"
            },
            {
                "description": "Tesseract Latin model",
                "name": "Latin.traineddata",
                "parameter_usage": "without-extension",
                "size": 89384811,
                "url": "https://github.com/tesseract-ocr/tessdata_fast/raw/main/script/Latin.traineddata"
            },
            {
                "description": "Tesseract configs (parameter sets) for use with the standalone tesseract CLI",
                "name": "configs",
                "path_in_archive": "tesseract-main/tessdata/configs",
                "size": 1915529,
                "type": "archive",
                "url": "https://github.com/tesseract-ocr/tesseract/archive/main.tar.gz"
            }
        ],
        "steps": [
            "layout/segmentation/region",
            "layout/segmentation/line",
            "recognition/text-recognition"
        ]
    },
    "ocrd-tesserocr-segment": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment page into regions and lines with Tesseract",
        "executable": "ocrd-tesserocr-segment",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-GT-SEG-PAGE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "block_polygons": {
                "default": false,
                "description": "annotate polygon coordinates instead of bounding box rectangles",
                "type": "boolean"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "find_staves": {
                "default": false,
                "description": "When detecting regions, recognize music staves as non-text, suppressing it in the binary image (Tesseract's ``pageseg_apply_music_mask``). Note that this might wrongly detect tables as staves.",
                "type": "boolean"
            },
            "find_tables": {
                "default": true,
                "description": "recognise tables as table regions (textord_tabfind_find_tables)",
                "type": "boolean"
            },
            "padding": {
                "default": 4,
                "description": "extend detected region rectangles by this many (true) pixels",
                "format": "integer",
                "type": "number"
            },
            "shrink_polygons": {
                "default": false,
                "description": "annotate polygon coordinates instead of bounding box rectangles by projecting the convex hull of all symbols",
                "type": "boolean"
            },
            "sparse_text": {
                "default": false,
                "description": "use 'sparse text' page segmentation mode (find as much text as possible in no particular order): only text regions, single lines without vertical or horizontal space",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/region",
            "layout/segmentation/line"
        ]
    },
    "ocrd-tesserocr-segment-line": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment regions into lines with Tesseract",
        "executable": "ocrd-tesserocr-segment-line",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-GT-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-SEG-LINE"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "overwrite_lines": {
                "default": true,
                "description": "Remove existing layout and text annotation below the TextRegion level (otherwise skip region; no incremental annotation yet).",
                "type": "boolean"
            },
            "padding": {
                "default": 0,
                "description": "extend detected line rectangles by this many (true) pixels",
                "format": "integer",
                "type": "number"
            },
            "shrink_polygons": {
                "default": false,
                "description": "annotate polygon coordinates instead of bounding box rectangles by projecting the convex hull of all symbols",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/line"
        ]
    },
    "ocrd-tesserocr-segment-region": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment page into regions with Tesseract",
        "executable": "ocrd-tesserocr-segment-region",
        "input_file_grp": [
            "OCR-D-IMG",
            "OCR-D-SEG-PAGE",
            "OCR-D-GT-SEG-PAGE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "crop_polygons": {
                "default": false,
                "description": "annotate polygon coordinates instead of bounding box rectangles",
                "type": "boolean"
            },
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "find_staves": {
                "default": false,
                "description": "When detecting regions, recognize music staves as non-text, suppressing it in the binary image (Tesseract's ``pageseg_apply_music_mask``). Note that this might wrongly detect tables as staves.",
                "type": "boolean"
            },
            "find_tables": {
                "default": true,
                "description": "recognise tables as table regions (textord_tabfind_find_tables)",
                "type": "boolean"
            },
            "overwrite_regions": {
                "default": true,
                "description": "Remove existing layout and text annotation below the Page level (otherwise skip page; no incremental annotation yet).",
                "type": "boolean"
            },
            "padding": {
                "default": 0,
                "description": "extend detected region rectangles by this many (true) pixels",
                "format": "integer",
                "type": "number"
            },
            "shrink_polygons": {
                "default": false,
                "description": "annotate polygon coordinates instead of bounding box rectangles by projecting the convex hull of all symbols",
                "type": "boolean"
            },
            "sparse_text": {
                "default": false,
                "description": "use 'sparse text' page segmentation mode (find as much text as possible in no particular order): only text regions, single lines without vertical or horizontal space",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-tesserocr-segment-table": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment table regions into cell text regions with Tesseract",
        "executable": "ocrd-tesserocr-segment-table",
        "input_file_grp": [
            "OCR-D-SEG-BLOCK",
            "OCR-D-GT-SEG-BLOCK"
        ],
        "output_file_grp": [
            "OCR-D-SEG-BLOCK"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "overwrite_cells": {
                "default": true,
                "description": "Remove existing layout and text annotation below the TableRegion level (otherwise skip table; no incremental annotation yet).",
                "type": "boolean"
            },
            "padding": {
                "default": 0,
                "description": "extend detected cell rectangles by this many (true) pixels",
                "format": "integer",
                "type": "number"
            },
            "shrink_polygons": {
                "default": false,
                "description": "annotate polygon coordinates instead of bounding box rectangles by projecting the convex hull of all symbols",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/region"
        ]
    },
    "ocrd-tesserocr-segment-word": {
        "categories": [
            "Layout analysis"
        ],
        "description": "Segment lines into words with Tesseract",
        "executable": "ocrd-tesserocr-segment-word",
        "input_file_grp": [
            "OCR-D-SEG-LINE",
            "OCR-D-GT-SEG-LINE"
        ],
        "output_file_grp": [
            "OCR-D-SEG-WORD"
        ],
        "parameters": {
            "dpi": {
                "default": 0,
                "description": "pixel density in dots per inch (overrides any meta-data in the images); disabled when negative",
                "format": "float",
                "type": "number"
            },
            "overwrite_words": {
                "default": true,
                "description": "Remove existing layout and text annotation below the TextLine level (otherwise skip line; no incremental annotation yet).",
                "type": "boolean"
            },
            "padding": {
                "default": 0,
                "description": "extend detected cell rectangles by this many (true) pixels",
                "format": "integer",
                "type": "number"
            },
            "shrink_polygons": {
                "default": false,
                "description": "annotate polygon coordinates instead of bounding box rectangles by projecting the convex hull of all symbols",
                "type": "boolean"
            }
        },
        "steps": [
            "layout/segmentation/word"
        ]
    },
    "ocrd-typegroups-classifier": {
        "categories": [
            "Text recognition and optimization"
        ],
        "description": "Classification of 15th century type groups",
        "executable": "ocrd-typegroups-classifier",
        "input_file_grp": [
            "OCR-D-IMG"
        ],
        "output_file_grp": [
            "OCR-D-IMG-FONTS"
        ],
        "parameters": {
            "network": {
                "description": "The file name of the neural network to use, including sufficient path information",
                "required": false,
                "type": "string"
            },
            "stride": {
                "default": 112,
                "description": "Stride applied to the CNN on the image. Should be between 1 and 224. Smaller values increase the computation time.",
                "format": "integer",
                "type": "number"
            }
        },
        "steps": [
            "recognition/font-identification"
        ]
    }
}
