I"◊J<h1 id="modulprojekte-phase-ii">Modulprojekte Phase II</h1>

<p>Aus den Projektantr√§gen f√ºr die Modulprojektausschreibung der DFG im M√§rz 2017 wurden acht Projekte bewilligt:</p>

<h2 id="skalierbare-verfahren-der-text--und-strukturerkennung-f√ºr-die-volltextdigitalisierung-historischer-drucke-bildoptimierung">Skalierbare Verfahren der Text- und Strukturerkennung f√ºr die Volltextdigitalisierung historischer Drucke: Bildoptimierung</h2>

<p class="poster-image">
  <a href="/assets/poster/DFKI.pdf">
    <img src="/assets/poster/DFKI.png" style="height: 400px" title="Klicken f√ºr PDF-Version in Originalgr√∂√üe" />
  </a>
</p>

<p><em>Deutsches Forschungszentrum f√ºr K√ºnstliche Intelligenz (DFKI)</em></p>

<p>Das DFKI war als Projektpartner im OCR-D Projekt mit zwei Modulen vertreten:
Bildoptimierung und Layouterkennung. In beiden Modulen wurden mehrere
Prozessoren entwickelt und in das OCR-D-Softwaresystem integriert.</p>

<p>Das erste Modul-Projekt <em>Bildoptimierung</em> fokussierte sich auf die
Vorverarbeitung der Digitalisate mit dem Ziel, die Bildqualit√§t und somit auch
die Performanz der nachfolgenden OCR-Module zu verbessern. Daf√ºr wurden
Werkzeuge f√ºr die Binarisierung, das Deskewing, das Cropping und das Dewarping
implementiert.</p>

<p>Das auf Computer Vision basierte Cropping-Werkzeug ist als besonders performant
hervorzuheben. Es erzielt auf den gesamten Projektdaten vorwiegend sehr gute
Ergebnisse. Auch das Dewarping-Werkzeug ist aufgrund seiner neuartigen
Architektur interessant. Mit Hilfe generativer neuronaler Netze werden
entzerrte Varianten von Bildern generiert, anstatt explizite Transformationen
f√ºr die Entzerrung zu bestimmen.</p>

<h2 id="skalierbare-verfahren-der-text--und-strukturerkennung-f√ºr-die-volltextdigitalisierung-historischer-drucke-layouterkennung">Skalierbare Verfahren der Text- und Strukturerkennung f√ºr die Volltextdigitalisierung historischer Drucke: Layouterkennung</h2>

<p class="poster-image">
  <a href="/assets/poster/DFKI.pdf">
    <img src="/assets/poster/DFKI.png" style="height: 400px" title="Klicken f√ºr PDF-Version in Originalgr√∂√üe" />
  </a>
</p>

<p><em>DFKI</em></p>

<p>GitHub: <a href="https://github.com/mjenckel/OCR-D-LAYoutERkennung/tree/master">mjenckel/OCR-D-LAYoutERkennung/tree/master</a></p>

<p>Im zweiten Modul-Projekt des DFKI <em>Layouterkennung</em> galt es, die
Dokumentstruktur, sowohl einzelner Dokumentseiten als auch im Gesamtdokument,
zu extrahieren. Die dabei gewonnenen Metadaten helfen zum einen, das Dokument
als Ganzes zu digitalisieren, zum anderen ist das Extrahieren bestimmter
Dokumentstrukturen notwendig. Die meisten OCR-Methoden k√∂nnen z.B. nur einzelne
Textzeilen verarbeiten. Die entwickelten Werkzeuge dienen der
Text-Nicht-Text-Segmentierung, der Blocksegmentierung und -klassifizierung, der
Textzeilenerkennung sowie der Strukturanalyse.</p>

<p>Ein Entwicklungsschwerpunkt war die kombinierte Blocksegmentierung und
-klassifizierung, welche auf der, aus der Video- und Bildsegmentierung
bekannten, MaskRCNN-Architektur basiert. Dieses Werkzeug arbeitet mit den
unbearbeiteten Rohdaten, sodass einerseits keine Vorverarbeitung notwendig ist
und andererseits das volle Informationsspektrum ausgenutzt werden kann.</p>

<h2 id="weiterentwicklung-eines-semi-automatischen-open-source-tools-zur-layout-analyse-und-regionen-extraktion-und--klassifikation-larex-von-fr√ºhen-buchdrucken">Weiterentwicklung eines semi-automatischen Open-Source-Tools zur Layout-Analyse und Regionen-Extraktion und -Klassifikation (LAREX) von fr√ºhen Buchdrucken</h2>

<p class="poster-image">
  <a href="/assets/poster/Wuerzburg.pdf">
    <img src="/assets/poster/Wuerzburg.png" style="height: 400px" title="Klicken f√ºr PDF-Version in Originalgr√∂√üe" />
  </a>
</p>

<p><em>Julius-Maximilians-Universit√§t W√ºrzburg</em> <br />
<em>Institut f√ºr Informatik: Lehrstuhl f√ºr K√ºnstliche Intelligenz und angewandte Informatik</em></p>

<p>GitHub: <a href="https://github.com/ocr-d-modul-2-segmentierung">ocr-d-modul-2-segmentierung</a></p>

<p>Am Lehrstuhl f√ºr Informatik VI der Uni W√ºrzburg wurde in den Vorarbeiten LAREX
entwickelt, ein komfortabler Editor zur Annotation von Regionen und
Layout-Elementen auf Buchseiten. Bei der Weiterentwicklung im
OCR-D-Modulprojekt lag der Schwerpunkt neben der Verbesserung der effizienten
Bedienbarkeit vor allem auch in dem Ausbau der automatischen Verfahren.</p>

<p>Hierzu wurde ein Convolutional-Neural-Net (CNN) implementiert und trainiert,
welches jedem Pixel eines Seitenscans eine Einordnung in verschiedene Klassen
zuweist, um so Bild und Text zu trennen. Unter Betrachtung der Pixel je nur
einer Klasse wird anschlie√üend mit klassischen Verfahren eine Segmentierung der
Seite durchgef√ºhrt. Ein weiterer getesteter Ansatz nutzte zuerst klassische
Segmentierungsverfahren und ordnete die Segmente anschlie√üend ein.</p>

<p>Das auf der CNN-Ausgabe basierende Segmentierungsverfahren wurde an die
OCR-D-Schnittstellen angepasst. Auf reinen Textseiten oder Seiten mit deutlich
abgetrennten Bildern wurden gute Ergebnisse erzielt. Verbesserungspotential
besteht vor allem bei der Erkennung von Zierinitialen √§lterer Drucke und
weiteren nah am Text liegenden Bildern sowie mehrspaltigen Layouts.</p>

<div class="is-clearfix"></div>
<h2 id="nnfst--unsupervised-ocr-postcorrection-based-on-neural-networks-and-finite-state-transducers">NN/FST ‚Äì Unsupervised OCR-Postcorrection based on Neural Networks and Finite-state Transducers</h2>

<p class="poster-image">
  <a href="/assets/poster/Leipzig.pdf">
    <img src="/assets/poster/Leipzig.png" style="height: 400px" title="Klicken f√ºr PDF-Version in Originalgr√∂√üe" />
  </a>
</p>

<p><em>Universit√§t Leipzig</em>  <br />
¬†Institut f√ºr Informatik: Abteilung Automatische Sprachverarbeitung_</p>

<p>GitHub: <a href="https://github.com/ASVLeipzig/cor-asv-fst">ASVLeipzig/cor-asv-fst</a></p>

<p>Eine vollautomatische Nachkorrektur separat von der eigentlichen OCR ist immer
nur dann sinnvoll, wenn dabei statistisches Wissen √ºber ‚Äúrichtigen Text‚Äù und
√ºber typische OCR-Fehler <em>a priori</em> hinzukommt. Daf√ºr eignen sich neuronale
Netze (NN) ebenso wie gewichtete endliche Transduktoren (WFST), die auf
entsprechenden zus√§tzlichen Daten trainiert werden k√∂nnen.</p>

<p>F√ºr die Umsetzung einer kombinierten Architektur aus NN und FST wurde
entschieden, drei Module zu implementieren:</p>
<ol>
  <li>eine reine NN-L√∂sung mit durchgehend (<em>end-to-end</em>) trainiertem Modell
  allein auf Zeichenebene ‚Äì als tiefes (mehrschichtiges), bidirektionales
  rekurrentes Netzwerk nach dem Encoder-Decoder-Schema (f√ºr verschiedene
  Eingabe- und Ausgabel√§nge) mit Attention-Mechanismus und A*-Beamsearch mit
  einstellbarer R√ºckweisungsschwelle (gegen √úberkorrektur), d.h. die
  Nachkorrektur von Textzeilen wird wie maschinelle √úbersetzung behandelt,</li>
  <li>ein NN-Sprachmodell (LM) auf Zeichenebene ‚Äì als tiefes (mehrschichtiges),
  bidirektionales rekurrentes Netzwerk mit Schnittstelle f√ºr Graph-Eingabe
  und inkrementeller Dekodierung,</li>
  <li>eine WFST-Komponente mit explizit zu trainierendem Fehlermodell auf
  Zeichenebene und Wortmodell/Lexikon, sowie Anbindung an 2. ‚Äì per
  WFST-Komposition von Eingabegraph mit Fehler- und Wortmodell nach
  Sliding-Window-Prinzip, Konversion der Einzelfenster zu einem
  Hypothesengraph pro Textzeile, und Kombination der jeweiligen
  Ausgabegewichte mit LM-Bewertungen in einer effizienten Suche nach dem
  besten Pfad.</li>
</ol>

<p>Die Kombination von 3. mit 2. stellt also eine hybride L√∂sung dar. Aber auch 1.
kann von 2. profitieren (sofern die gleiche Netzwerk-Topologie benutzt wird),
indem die Gewichte aus einem auf gr√∂√üeren Mengen reinem Text trainierten
Sprachmodell initialisiert werden (Transfer-Learning).</p>

<p>Beide Ans√§tze profitieren von einer engen Anbindung an den OCR-Suchraum, d.h.
eine √úbergabe alternativer Zeichen-Hypothesen und ihrer Konfidenz (wie bisher
nur mit Tesseract m√∂glich und in Zusammenarbeit mit dem Modulprojekt der UB
Mannheim realisiert). Sie liefern aber auch auf reinem Volltext bereits gute
Ergebnisse (mit CER-Reduktion von bis zu 5%), sofern gen√ºgend passende
Trainingsdaten zur Verf√ºgung stehen und die OCR ihrerseits brauchbare
Ergebnisse (unterhalb 10% CER) liefert.</p>

<p>F√ºr alle Module stehen Kommandozeilen-Schnittstellen f√ºr Training und
Evaluierung, sowie volle OCR-D-Schnittstellen f√ºr Prozessierung und Evaluierung
zur Verf√ºgung.</p>

<div class="is-clearfix"></div>

<h2 id="optimierter-einsatz-von-ocr-verfahren--tesseract-als-komponente-im-ocr-d-workflow">Optimierter Einsatz von OCR-Verfahren ‚Äì Tesseract als Komponente im OCR-D-Workflow</h2>

<p class="poster-image">
  <a href="/assets/poster/Mannheim.pdf">
    <img src="/assets/poster/Mannheim.png" style="height: 400px" title="Klicken f√ºr PDF-Version in Originalgr√∂√üe" />
  </a>
</p>

<p><em>Universit√§t Mannheim</em><br />
<em>Universit√§tsbibliothek Mannheim</em></p>

<p>GitHub: <a href="http://github.com/tesseract-ocr/tesseract/" title="http://github.com/tesseract-ocr/tesseract/">tesseract-ocr/tesseract/</a></p>

<p>Im Fokus des Modulprojekts stand die OCR-Software Tesseract, die seit 1985 von
Ray Smith entwickelt wurde, seit 2005 als Open Source unter einer freien
Lizenz.</p>

<p>Das Projekt umfasste zwei Hauptziele: Die Einbindung von Tesseract in den
OCR-D-Workflow inklusive Unterst√ºtzung der anderen Modulprojekte durch die
Bereitstellung von Schnittstellen, sowie die allgemeine Verbesserung der
Stabilit√§t, Codequalit√§t und Performance von Tesseract.</p>

<p>Die Einbindung in den OCR-D-Workflow erforderte wesentlich weniger Aufwand als
urspr√ºnglich geplant; haupts√§chlich, weil die meiste Arbeit bereits au√üerhalb
des Modulprojekts geleistet war und dabei die schon vorhandene
Python-Schnittstelle tesserocr genutzt werden konnte.</p>

<p>F√ºr das OCR-D-Modulprojekt der Universit√§t Leipzig wurde Tesseract um die
Generierung von alternativen OCR-Ergebnissen f√ºr die Einzelzeichen erweitert.
Als Eingabedaten f√ºr ein OCR-Postkorrektur-Modell l√§sst sich damit die
Texterkennung weiter verbessern. Ein wertvoller Nebeneffekt des neuen Codes
sind genauere Zeichen- und Wortkoordinaten.</p>

<p>Mit mehreren hundert Korrekturen konnte die Codequalit√§t signifikant gesteigert
und ein deutlich stabilerer Programmfluss erreicht werden. Tesseract ist jetzt
wartbarer, braucht weniger Speicher und ist schneller als zuvor.</p>

<p>Eine wesentliche Verbesserung der Erkennungsgenauigkeit f√ºr die meisten der f√ºr
OCR-D relevanten Druckwerke konnte durch neue generische Modelle f√ºr Tesseract
erreicht werden. Diese wurden ab Septem-ber 2019 bis Januar 2020 auf Basis der
Datensammlung <a href="https://zenodo.org/record/1344132"><em>GT4HistOCR</em></a> trainiert.</p>

<div class="is-clearfix"></div>

<h2 id="automatische-nachkorrektur-historischer-ocr-erfasster-drucke-mit-integrierter-optionaler-interaktiver-korrektur">Automatische Nachkorrektur historischer OCR-erfasster Drucke mit integrierter optionaler interaktiver Korrektur</h2>

<p class="poster-image">
  <a href="/assets/poster/M√ºnchen.pdf">
    <img src="/assets/poster/M√ºnchen.png" style="height: 400px" title="Klicken f√ºr PDF-Version in Originalgr√∂√üe" />
  </a>
</p>

<p><em>Ludwig-Maximilians-Universit√§t M√ºnchen</em><br />
<em>Centrum f√ºr Informations- und Sprachverarbeitung (CIS)</em></p>

<p>GitHub: cisocrgroup/ocrd-postcorrection](https://github.com/cisocrgroup/ocrd-postcorrection), <a href="https://github.com/cisocrgroup/cis-ocrd-py">cisocrgroup/cis-ocrd-py</a></p>

<p>Das Ergebnis des Projekts ist ein in den OCR-D-Workflow integriertes System
<em>A-I-PoCoTo</em> zur vollautomati-schen Nachkorrektur OCR-erfasster historischer
Drucke. Das System beinhaltet zudem eine optional nachge-schaltete interaktive
Nachkorrektur (<em>I-PoCoTo</em>), die in das interaktive Nachkorrektursystem
<em>PoCoWeb</em> einge-bunden ist. Das System kann damit auch alternativ als
Stand-Alone-Tool zur gemeinschaftlichen webbasierten Nachkorrektur von
OCR-Dokumenten eingesetzt werden.</p>

<p>Die Grundlage der vollautomatischen Nachkorrektur ist ein flexibles,
featurebasiertes Machine-Learning (ML) Verfahren zur vollautomatischen
OCR-Nachkorrektur mit einem besonderen Fokus auf die Vermeidung der
Verschlimmbesserungsproblematik. Zur Erkennung von Fehlern und f√ºr die
Erzeugung von Korrekturkandida-ten verwendet das System die am CIS entwickelte
dokumentenabh√§ngige Profilierungstechnologie. Die Fea-tures des Systems
verwenden neben verschiedenen Konfidenzwerten insbesondere auch Informationen
aus zus√§tzlichen Hilfs-OCRs.</p>

<p>Das System protokolliert s√§mtliche Korrekturentscheidungen. √úber diesen
Protokollmechanismus kann die automatische Postkorrektur in <em>PoCoWeb</em>
interaktiv √ºberpr√ºft werden. Dabei k√∂nnen sowohl einzelne get√§tigte
Korrekturentscheidungen manuell r√ºckg√§ngig gemacht werden, als auch nicht
get√§tigte Korrekturentschei-dungen nachtr√§glich ausgef√ºhrt werden.</p>

<p>Das gesamte System ist in den OCR-D-Workflow eingebunden und folgt den dort
g√ºltigen Konventionen.</p>

<div class="is-clearfix"></div>

<h2 id="entwicklung-eines-modellrepositoriums-und-einer-automatischen-schriftarterkennung-f√ºr-ocr-d">Entwicklung eines Modellrepositoriums und einer Automatischen Schriftarterkennung f√ºr OCR-D</h2>

<p class="poster-image">
  <a href="/assets/poster/Mainz.pdf">
    <img src="/assets/poster/Mainz.png" style="height: 400px" title="Klicken f√ºr PDF-Version in Originalgr√∂√üe" />
  </a>
</p>

<p><em>Universit√§t Leipzig</em><br />
<em>Institut f√ºr Informatik: Lehrstuhl f√ºr Digital Humanities</em><br />
<em>Friedrich-Alexander-Universit√§t Erlangen-N√ºrnberg</em> <br />
<em>Department Informatik: Lehrstuhl f√ºr Informatik 5: Mustererkennung</em><br />
<em>Johannes Gutenberg-Universit√§t Mainz</em><br />
¬†Gutenberg-Institut f√ºr Weltliteratur und schriftorientierte Medien: Abteilung Buchwissenschaft_</p>

<p>GitHub: <a href="https://github.com/OCR-D/okralact">OCR-D/okralact</a>, <a href="https://github.com/seuretm/ocrd_typegroups_classifier">seuretm/ocrd_typegroups_classifier</a></p>

<p>Die Erkennungsquoten von OCR f√ºr Drucke, die vor 1800 produziert wurden,
variieren sehr stark, da die Diversit√§t historischer Schriftarten in den
Trainingsdaten entweder gar nicht oder nur unzureichend ber√ºcksichtigt wird.
Daher hat sich dieses Modulprojekt, bestehend aus Informatiker<em>innen und
Buchhistoriker</em>innen, drei Ziele gesteckt:</p>

<p>Zum einen haben wir ein Tool zur automatischen Erkennung von Schriftarten in
Bilddigitalisaten entwickelt. Hier haben wir uns besonders auf gebrochene
Schriften neben der Fraktur konzentriert, die bisher wenig Beachtung gefunden
haben, jedoch im 15. und 16. Jahrhundert weit verbreitet waren: Bastarda,
Rotunda, Textura und Schwabacher. Das Tool wurde mit 35.000 Bildern trainiert
und erreicht eine Genauigkeit von 98% bei der Bestimmung von Schriftarten.
Insgesamt kann es nicht nur zwischen den o.g. Schriftarten differenzieren,
sondern auch Hebr√§isch, Griechisch, Fraktur, Antiqua und Kursiv unterscheiden.</p>

<p>In einem zweiten Schritt wurde eine Online-Trainingsinfrastruktur geschaffen
(Okralact). Sie vereinfacht die Benutzung verschiedener OCR-engines (Tesseract,
Ocropus, Kraken, Calamari) und erm√∂glicht es zugleich, spezifische Modelle f√ºr
bestimmte Schriftarten zu trainieren.</p>

<p>Zum Abschluss wurde ein Modellrepositorium eingerichtet, das bereits
erarbeitete schriftartspezifische OCR-Modelle enth√§lt. Um hier einen Grundstock
zu legen, haben wir insgesamt ca. 2.500 Zeilen f√ºr Bastarda, Textura und
Schwabacher aus einer Vielzahl verschiedener B√ºcher transkribiert.</p>

<p>Die hohe Genauigkeit des Tools zur Erkennung der Schriftarten er√∂ffnet die
M√∂glichkeit, in Zukunft durch weitere Trainingsdaten das Tool sogar zwischen
den Schriften einzelner Drucker unterscheiden zu lassen, was mehrere Desiderate
der historischen Forschung adressieren w√ºrde.</p>

<div class="is-clearfix"></div>

<h2 id="ola-hd--ein-ocr-d-langzeitarchiv-f√ºr-historische-drucke">OLA-HD ‚Äì Ein OCR-D-Langzeitarchiv f√ºr historische Drucke</h2>

<p class="poster-image">
  <a href="/assets/poster/G√∂ttingen.pdf">
    <img src="/assets/poster/G√∂ttingen.png" style="height: 400px" title="Klicken f√ºr PDF-Version in Originalgr√∂√üe" />
  </a>
</p>

<p><em>Georg-August-Universit√§t G√∂ttingen</em>  <br />
<em>Nieders√§chsische Staats- und Universit√§tsbibliothek</em>   <br />
<em>Gesellschaft f√ºr Wissenschaftliche Datenverarbeitung mbH G√∂ttingen</em> <br /></p>

<p>GitHub: <a href="https://github.com/subugoe/OLA-HD-IMPL">subugoe/OLA-HD-IMPL</a></p>

<p>Im September 2018 starteten die Abteilung Digitale Bibliothek der
Nieders√§chsischen Staats- und Universi-t√§tsbibliothek und die Gesellschaft f√ºr
wissenschaftliche Datenverarbeitung G√∂ttingen das DFG-Projekt <a href="https://www.sub.uni-goettingen.de/projekte-forschung/projektdetails/projekt/ola-hd-ein-ocr-d-langzeitarchiv-fuer-historische-drucke/"><em>OLA-HD ‚Äì Ein
OCR-D Langzeitarchiv f√ºr historische
Drucke</em></a>.</p>

<p>Ziel von OLA-HD ist die Entwicklung eines integrierten Konzepts f√ºr die
Langzeitarchivierung und persistente Identifizierung von OCR-Objekten, sowie
eine prototypische Implementierung.</p>

<p>Im regelm√§√üigen Austausch mit den Projektpartnern wurden die
Basis-Anforderungen f√ºr die Langzeitarchivierung und persistente Identifikation
ermittelt und in Form einer Spezifikation zur technischen und
wirtschaftlich-organisatorischen Umsetzung festgehalten.</p>

<p>Mit dem Prototypen kann der Anwender OCR-Ergebnisse eines Werkes als OCRD-ZIP
in das System laden. Das System validiert die Zip-Datei, vergibt eine PID und
schickt die Datei an den Archiv-Manager <a href="https://cdstar.gwdg.de/">(CDSTAR ‚Äì GWDG Common Data Storage
Architecture)</a>. Dieser schreibt die Zip-Datei in das
Archiv (Bandspeicher). Abh√§ngig von der Konfiguration (Datei-Typ, Datei-Gr√∂√üe
etc.) werden Dateien zus√§tzlich in ein Online Storage geschrieben (Festplatte),
um einen schnellen Zugriff zu erm√∂glichen. Der Nutzer hat Zugriff auf alle
OCR-Versionen und kann Versionen als BagIt-Zip Dateien herunterladen. Alle
Werke und Versionen haben eigene PIDs. Die PIDs werden vom European Persistent
Identifier Consortium <a href="https://www.pidconsortium.net/">(ePIC)</a> Service
generiert. Die verschiedenen OCR-Versionen eines Werkes sind √ºber die PID
verkn√ºpft, sodass das System die Versionierung in einer Baumstruktur abbilden
kann.</p>

<p>Nicht angemeldete Anwender k√∂nnen den Bestand durchsuchen und in der
Dateistruktur eine Vorschau von Text und ‚Äì sofern vorhanden ‚Äì Bild erhalten
bzw. √ºber die verschiedenen Versionen navigieren. Die Anwender k√∂nnen sich √ºber
das GWDG-Portal registrieren und anmelden und k√∂nnen √ºber ein Dashboard ihre
Dateien verwalten.</p>

<p>Bis M√§rz 2020 werden kleinere Optimierungen am User-Interface vorgenommen und
das Konzept finalisiert. Im Konzept werden weitere Ausbaustufen beschrieben,
die sinnvoll sein k√∂nnen, um die prototypische Soft-ware in ein Produkt zu
√ºberf√ºhren.</p>
:ET